{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset, datasets_types\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import beta as beta_dist\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, recall_score, roc_auc_score\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './shared/data/CIC_2019/DrDoS_MSSQL.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m load_dataset:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# Preprocesar el dataset\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"      \"\"\"\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_data(\n\u001b[0;32m      7\u001b[0m         [\n\u001b[0;32m      8\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./shared/data/CIC_2019/DrDoS_MSSQL.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m         ],\n\u001b[0;32m     10\u001b[0m         seed\n\u001b[0;32m     11\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset cargado\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     df_preprocessed \u001b[38;5;241m=\u001b[39m preprocess_dataset(\n\u001b[0;32m     14\u001b[0m         df, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIC_2019\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39mseed, load\u001b[38;5;241m=\u001b[39mload_dataset, name_save\u001b[38;5;241m=\u001b[39mname, name_load\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[1;32m~\\Apollon\\apollon\\shared\\utils\\load.py:24\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(path, seed)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"load_data\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    This function loads the data from the path and returns a dataframe of the datasets\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m        df (pd.DataFrame): dataframe with all the data\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     23\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 24\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path[i])\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mD:\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './shared/data/CIC_2019/DrDoS_MSSQL.csv'"
     ]
    }
   ],
   "source": [
    "load_dataset = False\n",
    "name = \"CIC-IDS_2019_MAB\"\n",
    "if not load_dataset:\n",
    "    # Preprocesar el dataset\n",
    "    \"\"\"      \"\"\"\n",
    "    df = load_data(\n",
    "        [\n",
    "            \"./shared/data/CIC_2019/DrDoS_MSSQL.csv\"\n",
    "        ],\n",
    "        seed\n",
    "    )\n",
    "    print(\"Dataset cargado\")\n",
    "    df_preprocessed = preprocess_dataset(\n",
    "        df, save=True, dataset_type=\"CIC_2019\", seed=seed, load=load_dataset, name_save=name, name_load=name)\n",
    "    print(\"Dataset Preprocesado\")\n",
    "else:\n",
    "    df_preprocessed = preprocess_dataset(\n",
    "        pd.DataFrame(), save=True, dataset_type=\"CIC_2019\", seed=seed, load=load_dataset, name_save=name, name_load=name)\n",
    "    print(\"Dataset Preprocesado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiArmedBanditThompsonSampling:\n",
    "\n",
    "    def __init__(self, n_arms, n_clusters):\n",
    "        self.n_arms = n_arms\n",
    "        self.n_clusters = n_clusters\n",
    "        self.arms = [RandomForestClassifier(), DecisionTreeClassifier(),\n",
    "                     GaussianNB(), LogisticRegression(), mlp]\n",
    "        self.cluster_centers = None\n",
    "        self.cluster_assignments = None\n",
    "        self.reward_sums = {}\n",
    "        for cluster in range(n_clusters):\n",
    "            self.reward_sums[cluster] = np.zeros(n_arms)\n",
    "        self.alpha = np.ones(self.n_arms)\n",
    "        self.beta = np.ones(self.n_arms)\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters)\n",
    "        self.cluster_assignments = kmeans.fit_predict(X_train)\n",
    "        self.cluster_centers = kmeans.cluster_centers_\n",
    "        # Print the number of samples in each cluster\n",
    "\n",
    "        for i in range(self.n_clusters):\n",
    "            print('Cluster {}: {}'.format(\n",
    "                i, np.sum(self.cluster_assignments == i)))\n",
    "            cluster_mask = self.cluster_assignments == i\n",
    "            cluster_X_train = X_train[cluster_mask]\n",
    "            cluster_y_train = y_train[cluster_mask]\n",
    "            for arm in range(self.n_arms):\n",
    "                print('Training arm {} on cluster {}'.format(arm, i))\n",
    "                arm_mask = cluster_y_train == arm\n",
    "                arm_X_train = cluster_X_train[arm_mask]\n",
    "                arm_y_train = cluster_y_train[arm_mask]\n",
    "                if len(arm_X_train) > 0 and len(np.unique(arm_y_train)) > 1:\n",
    "                    self.arms[arm].fit(arm_X_train, arm_y_train)\n",
    "                else:\n",
    "                    self.arms[arm].fit(X_train, y_train)\n",
    "\n",
    "        # Set the arms rewards for each cluster\n",
    "        for i in range(self.n_clusters):\n",
    "            cluster_mask = self.cluster_assignments == i\n",
    "            cluster_X_test = X_train[cluster_mask]\n",
    "            cluster_y_test = y_train[cluster_mask]\n",
    "            for arm in range(self.n_arms):\n",
    "                print('Setting reward_sums arm {} on cluster {}'.format(arm, i))\n",
    "                arm_mask = cluster_y_test == arm\n",
    "                arm_X_test = cluster_X_test[arm_mask]\n",
    "                arm_y_test = cluster_y_test[arm_mask]\n",
    "                if len(arm_X_test) > 0:\n",
    "                    arm_y_pred = self.arms[arm].predict(arm_X_test)\n",
    "                    self.reward_sums[i][arm] = np.mean(\n",
    "                        arm_y_pred == arm_y_test)\n",
    "\n",
    "    def select_arm(self, cluster):\n",
    "        # Select the arm with the highest reward\n",
    "        theta = np.zeros(self.n_arms)\n",
    "        for arm in range(self.n_arms):\n",
    "            theta[arm] = np.random.beta(self.alpha[arm] + self.reward_sums[cluster]\n",
    "                                        [arm], self.beta[arm] + 1 - self.reward_sums[cluster][arm])\n",
    "        return np.argmax(theta)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Select the arm for each sample\n",
    "        arms = np.zeros(len(X_test))\n",
    "        for i in range(len(X_test)):\n",
    "            cluster = np.argmin(np.linalg.norm(\n",
    "                self.cluster_centers - X_test[i], axis=1))\n",
    "            arms[i] = self.select_arm(cluster)\n",
    "        # Predict using the selected arm\n",
    "        y_pred = np.zeros(len(X_test))\n",
    "        for arm in range(self.n_arms):\n",
    "            arm_mask = arms == arm\n",
    "            arm_X_test = X_test[arm_mask]\n",
    "            if len(arm_X_test) > 0:\n",
    "                y_pred[arm_mask] = self.arms[arm].predict(arm_X_test)\n",
    "        return y_pred, arms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 2789828\n",
      "Training arm 0 on cluster 0\n",
      "Training arm 1 on cluster 0\n",
      "Training arm 2 on cluster 0\n",
      "Cluster 1: 377320\n",
      "Training arm 0 on cluster 1\n",
      "Training arm 1 on cluster 1\n",
      "Training arm 2 on cluster 1\n",
      "Setting reward_sums arm 0 on cluster 0\n",
      "Setting reward_sums arm 1 on cluster 0\n",
      "Setting reward_sums arm 2 on cluster 0\n",
      "Setting reward_sums arm 0 on cluster 1\n",
      "Setting reward_sums arm 1 on cluster 1\n",
      "Setting reward_sums arm 2 on cluster 1\n"
     ]
    }
   ],
   "source": [
    "# Train the MAB\n",
    "mab = MultiArmedBanditThompsonSampling(n_arms=3, n_clusters=2)\n",
    "mab.train(df_preprocessed.x_train, df_preprocessed.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.94      0.70       602\n",
      "           1       1.00      1.00      1.00   1356748\n",
      "\n",
      "    accuracy                           1.00   1357350\n",
      "   macro avg       0.78      0.97      0.85   1357350\n",
      "weighted avg       1.00      1.00      1.00   1357350\n",
      "\n",
      "Accuracy: 0.9996507901425572\n",
      "Recall: 0.9691080561338743\n",
      "F1 Score: 0.852157034949286\n",
      "ROC AUC Score: 0.9691080561338742\n"
     ]
    }
   ],
   "source": [
    "# Test the MAB\n",
    "y_pred, selected_arms = mab.predict(df_preprocessed.x_test)\n",
    "# Transform the y_pred values to 0 and 1 strings\n",
    "y_test = np.array([int(y) for y in df_preprocessed.y_test])\n",
    "y_pred = np.array([int(y) for y in y_pred])\n",
    "\n",
    "# Print y_pred unique values\n",
    "print(np.unique(y_pred))\n",
    "# Print y_test unique values\n",
    "print(np.unique(y_test))\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
