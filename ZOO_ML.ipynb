{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b7b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset\n",
    "from intrusion_detection_systems.models import cnn_model, mlp_model, rnn_model\n",
    "from intrusion_detection_systems import train_dl_model, evaluate_dl_model\n",
    "from agent.DQN_ML_Pool import DQNModelSelector\n",
    "from agent.MAB_ML_Pool import MultiArmedBanditThompsonSampling\n",
    "\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnClassifier\n",
    "from art.utils import to_categorical\n",
    "from art.attacks.evasion import ZooAttack\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496a347",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"CIC-IDS_2017_2\"\n",
    "df = load_data(\n",
    "            [\n",
    "                \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "            ],\n",
    "            42\n",
    "        )\n",
    "print(\"Dataset loaded\")\n",
    "df_preprocessed = preprocess_dataset(\n",
    "    df, save=True, dataset_type=\"CIC_2017\", seed=42, load=False, name_save=name, name_load=name)\n",
    "print(\"Dataset preprocessed\")\n",
    "\n",
    "X_train_full, y_train_full = df_preprocessed.x_train, df_preprocessed.y_train\n",
    "X_test_full, y_test_full = df_preprocessed.x_test, df_preprocessed.y_test\n",
    "print(f\"Train full shape: {X_train_full.shape}, labels distribution: {np.unique(y_train_full, return_counts=True)}\")\n",
    "print(f\"Test full shape: {X_test_full.shape}, labels distribution: {np.unique(y_test_full, return_counts=True)}\")\n",
    "y_train_full = np.array([int(str(x).strip()) for x in y_train_full])\n",
    "y_test_full = np.array([int(str(x).strip()) for x in y_test_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a NB Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_full, y_train_full)\n",
    "# Train a RF Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_full, y_train_full)\n",
    "# Train a DT Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_full, y_train_full)\n",
    "# Train a LR Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7349b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_full.shape[1]\n",
    "#MLP Model\n",
    "mlp_model_pt = mlp_model(input_dim)\n",
    "criterion_mlp_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_pt = optim.Adam(mlp_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- MLP Model ---\")\n",
    "print(mlp_model_pt)\n",
    "print(f\"Criterion: {criterion_mlp_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_mlp_model_pt}\")\n",
    "# CNN Model\n",
    "cnn_model_pt = cnn_model(input_dim)\n",
    "criterion_cnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_pt = optim.Adam(cnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- CNN Model ---\")\n",
    "print(cnn_model_pt)\n",
    "print(f\"Criterion: {criterion_cnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_cnn_model_pt}\")\n",
    "# RNN Model\n",
    "rnn_model_pt = rnn_model(input_dim) \n",
    "criterion_rnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_pt = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- RNN Model (LSTM) ---\")\n",
    "print(rnn_model_pt)\n",
    "print(f\"Criterion: {criterion_rnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_rnn_model_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e962fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train DL models for attack\n",
    "# Chia t·∫≠p train -> train v√† validation\n",
    "X_small = X_train_full[:1000]\n",
    "y_small = y_train_full[:1000]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_small, y_small, test_size=0.2, random_state=42, stratify=y_small\n",
    ")\n",
    "\n",
    "# Chuy·ªÉn sang tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_full[:1000], dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_full[:1000], dtype=torch.long)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c9f404b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/50], Train Loss: 0.6914, Train Acc: 0.5825, Val Loss: 0.6807, Val Acc: 0.7350\n",
      "Epoch [2/50], Train Loss: 0.6781, Train Acc: 0.7025, Val Loss: 0.6661, Val Acc: 0.7600\n",
      "Epoch [3/50], Train Loss: 0.6632, Train Acc: 0.7275, Val Loss: 0.6463, Val Acc: 0.7700\n",
      "Epoch [4/50], Train Loss: 0.6430, Train Acc: 0.7338, Val Loss: 0.6165, Val Acc: 0.7750\n",
      "Epoch [5/50], Train Loss: 0.6138, Train Acc: 0.7388, Val Loss: 0.5760, Val Acc: 0.7750\n",
      "Epoch [6/50], Train Loss: 0.5760, Train Acc: 0.7388, Val Loss: 0.5251, Val Acc: 0.7850\n",
      "Epoch [7/50], Train Loss: 0.5288, Train Acc: 0.7512, Val Loss: 0.4677, Val Acc: 0.8100\n",
      "Epoch [8/50], Train Loss: 0.4782, Train Acc: 0.7738, Val Loss: 0.4099, Val Acc: 0.8300\n",
      "Epoch [9/50], Train Loss: 0.4257, Train Acc: 0.7837, Val Loss: 0.3548, Val Acc: 0.8400\n",
      "Epoch [10/50], Train Loss: 0.3743, Train Acc: 0.8512, Val Loss: 0.3025, Val Acc: 0.9550\n",
      "Epoch [11/50], Train Loss: 0.3207, Train Acc: 0.9413, Val Loss: 0.2508, Val Acc: 0.9600\n",
      "Epoch [12/50], Train Loss: 0.2721, Train Acc: 0.9500, Val Loss: 0.2066, Val Acc: 0.9700\n",
      "Epoch [13/50], Train Loss: 0.2293, Train Acc: 0.9537, Val Loss: 0.1688, Val Acc: 0.9750\n",
      "Epoch [14/50], Train Loss: 0.1937, Train Acc: 0.9600, Val Loss: 0.1367, Val Acc: 0.9750\n",
      "Epoch [15/50], Train Loss: 0.1679, Train Acc: 0.9587, Val Loss: 0.1145, Val Acc: 0.9800\n",
      "Epoch [16/50], Train Loss: 0.1499, Train Acc: 0.9650, Val Loss: 0.1010, Val Acc: 0.9800\n",
      "Epoch [17/50], Train Loss: 0.1340, Train Acc: 0.9637, Val Loss: 0.0853, Val Acc: 0.9850\n",
      "Epoch [18/50], Train Loss: 0.1222, Train Acc: 0.9637, Val Loss: 0.0841, Val Acc: 0.9850\n",
      "Epoch [19/50], Train Loss: 0.1147, Train Acc: 0.9650, Val Loss: 0.0709, Val Acc: 0.9900\n",
      "Epoch [20/50], Train Loss: 0.1068, Train Acc: 0.9650, Val Loss: 0.0664, Val Acc: 0.9900\n",
      "Epoch [21/50], Train Loss: 0.1017, Train Acc: 0.9688, Val Loss: 0.0627, Val Acc: 0.9900\n",
      "Epoch [22/50], Train Loss: 0.0981, Train Acc: 0.9688, Val Loss: 0.0597, Val Acc: 0.9900\n",
      "Epoch [23/50], Train Loss: 0.0933, Train Acc: 0.9712, Val Loss: 0.0619, Val Acc: 0.9900\n",
      "Epoch [24/50], Train Loss: 0.0902, Train Acc: 0.9712, Val Loss: 0.0556, Val Acc: 0.9900\n",
      "Epoch [25/50], Train Loss: 0.0867, Train Acc: 0.9688, Val Loss: 0.0527, Val Acc: 0.9900\n",
      "Epoch [26/50], Train Loss: 0.0853, Train Acc: 0.9700, Val Loss: 0.0521, Val Acc: 0.9900\n",
      "Epoch [27/50], Train Loss: 0.0861, Train Acc: 0.9712, Val Loss: 0.0562, Val Acc: 0.9900\n",
      "Epoch [28/50], Train Loss: 0.0842, Train Acc: 0.9688, Val Loss: 0.0523, Val Acc: 0.9900\n",
      "Epoch [29/50], Train Loss: 0.0789, Train Acc: 0.9700, Val Loss: 0.0524, Val Acc: 0.9900\n",
      "Epoch [30/50], Train Loss: 0.0766, Train Acc: 0.9712, Val Loss: 0.0495, Val Acc: 0.9900\n",
      "Epoch [31/50], Train Loss: 0.0739, Train Acc: 0.9712, Val Loss: 0.0508, Val Acc: 0.9900\n",
      "Epoch [32/50], Train Loss: 0.0735, Train Acc: 0.9712, Val Loss: 0.0520, Val Acc: 0.9900\n",
      "Epoch [33/50], Train Loss: 0.0714, Train Acc: 0.9712, Val Loss: 0.0487, Val Acc: 0.9900\n",
      "Epoch [34/50], Train Loss: 0.0699, Train Acc: 0.9712, Val Loss: 0.0485, Val Acc: 0.9900\n",
      "Epoch [35/50], Train Loss: 0.0688, Train Acc: 0.9712, Val Loss: 0.0480, Val Acc: 0.9900\n",
      "Epoch [36/50], Train Loss: 0.0685, Train Acc: 0.9712, Val Loss: 0.0462, Val Acc: 0.9900\n",
      "Epoch [37/50], Train Loss: 0.0673, Train Acc: 0.9712, Val Loss: 0.0468, Val Acc: 0.9900\n",
      "Epoch [38/50], Train Loss: 0.0662, Train Acc: 0.9712, Val Loss: 0.0447, Val Acc: 0.9900\n",
      "Epoch [39/50], Train Loss: 0.0655, Train Acc: 0.9712, Val Loss: 0.0447, Val Acc: 0.9900\n",
      "Epoch [40/50], Train Loss: 0.0641, Train Acc: 0.9725, Val Loss: 0.0436, Val Acc: 0.9900\n",
      "Epoch [41/50], Train Loss: 0.0641, Train Acc: 0.9725, Val Loss: 0.0421, Val Acc: 0.9900\n",
      "Epoch [42/50], Train Loss: 0.0635, Train Acc: 0.9738, Val Loss: 0.0450, Val Acc: 0.9900\n",
      "Epoch [43/50], Train Loss: 0.0635, Train Acc: 0.9738, Val Loss: 0.0458, Val Acc: 0.9900\n",
      "Epoch [44/50], Train Loss: 0.0620, Train Acc: 0.9750, Val Loss: 0.0418, Val Acc: 0.9900\n",
      "Epoch [45/50], Train Loss: 0.0619, Train Acc: 0.9750, Val Loss: 0.0406, Val Acc: 0.9900\n",
      "Epoch [46/50], Train Loss: 0.0612, Train Acc: 0.9738, Val Loss: 0.0397, Val Acc: 0.9900\n",
      "Epoch [47/50], Train Loss: 0.0609, Train Acc: 0.9738, Val Loss: 0.0409, Val Acc: 0.9900\n",
      "Epoch [48/50], Train Loss: 0.0594, Train Acc: 0.9738, Val Loss: 0.0409, Val Acc: 0.9900\n",
      "Epoch [49/50], Train Loss: 0.0607, Train Acc: 0.9762, Val Loss: 0.0416, Val Acc: 0.9900\n",
      "Epoch [50/50], Train Loss: 0.0599, Train Acc: 0.9762, Val Loss: 0.0419, Val Acc: 0.9900\n",
      "Finished Training MLPModel\n",
      "\n",
      "---------- Test data (MLPModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       428\n",
      "           1       0.94      1.00      0.97       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.97      0.96      0.96      1000\n",
      "weighted avg       0.97      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.965\n",
      "Detection Rate (Recall):  0.9982517482517482\n",
      "F1 Score:  0.9702633814783348\n",
      "ROC AUC Score:  0.9594062479576498\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6867, Train Acc: 0.5450, Val Loss: 0.6672, Val Acc: 0.7300\n",
      "Epoch [2/50], Train Loss: 0.6638, Train Acc: 0.7125, Val Loss: 0.6383, Val Acc: 0.7200\n",
      "Epoch [3/50], Train Loss: 0.6307, Train Acc: 0.6987, Val Loss: 0.6009, Val Acc: 0.7500\n",
      "Epoch [4/50], Train Loss: 0.5940, Train Acc: 0.7150, Val Loss: 0.5577, Val Acc: 0.7450\n",
      "Epoch [5/50], Train Loss: 0.5584, Train Acc: 0.7225, Val Loss: 0.5287, Val Acc: 0.7450\n",
      "Epoch [6/50], Train Loss: 0.5342, Train Acc: 0.7238, Val Loss: 0.5075, Val Acc: 0.7300\n",
      "Epoch [7/50], Train Loss: 0.5162, Train Acc: 0.7250, Val Loss: 0.4967, Val Acc: 0.7250\n",
      "Epoch [8/50], Train Loss: 0.5010, Train Acc: 0.8113, Val Loss: 0.4773, Val Acc: 0.7400\n",
      "Epoch [9/50], Train Loss: 0.4811, Train Acc: 0.7250, Val Loss: 0.4564, Val Acc: 0.8250\n",
      "Epoch [10/50], Train Loss: 0.4500, Train Acc: 0.8800, Val Loss: 0.4265, Val Acc: 0.8350\n",
      "Epoch [11/50], Train Loss: 0.4206, Train Acc: 0.8762, Val Loss: 0.4000, Val Acc: 0.8450\n",
      "Epoch [12/50], Train Loss: 0.3910, Train Acc: 0.8850, Val Loss: 0.3693, Val Acc: 0.8500\n",
      "Epoch [13/50], Train Loss: 0.3635, Train Acc: 0.8875, Val Loss: 0.3429, Val Acc: 0.8700\n",
      "Epoch [14/50], Train Loss: 0.3297, Train Acc: 0.8962, Val Loss: 0.3053, Val Acc: 0.9000\n",
      "Epoch [15/50], Train Loss: 0.2961, Train Acc: 0.9137, Val Loss: 0.2781, Val Acc: 0.8950\n",
      "Epoch [16/50], Train Loss: 0.2761, Train Acc: 0.9175, Val Loss: 0.2477, Val Acc: 0.9250\n",
      "Epoch [17/50], Train Loss: 0.2455, Train Acc: 0.9325, Val Loss: 0.2144, Val Acc: 0.9250\n",
      "Epoch [18/50], Train Loss: 0.2219, Train Acc: 0.9375, Val Loss: 0.1934, Val Acc: 0.9300\n",
      "Epoch [19/50], Train Loss: 0.2042, Train Acc: 0.9413, Val Loss: 0.1721, Val Acc: 0.9350\n",
      "Epoch [20/50], Train Loss: 0.1906, Train Acc: 0.9425, Val Loss: 0.1589, Val Acc: 0.9450\n",
      "Epoch [21/50], Train Loss: 0.1806, Train Acc: 0.9537, Val Loss: 0.1498, Val Acc: 0.9400\n",
      "Epoch [22/50], Train Loss: 0.1674, Train Acc: 0.9487, Val Loss: 0.1412, Val Acc: 0.9650\n",
      "Epoch [23/50], Train Loss: 0.1598, Train Acc: 0.9563, Val Loss: 0.1411, Val Acc: 0.9450\n",
      "Epoch [24/50], Train Loss: 0.1586, Train Acc: 0.9500, Val Loss: 0.1219, Val Acc: 0.9650\n",
      "Epoch [25/50], Train Loss: 0.1468, Train Acc: 0.9525, Val Loss: 0.1153, Val Acc: 0.9550\n",
      "Epoch [26/50], Train Loss: 0.1386, Train Acc: 0.9563, Val Loss: 0.1120, Val Acc: 0.9550\n",
      "Epoch [27/50], Train Loss: 0.1344, Train Acc: 0.9563, Val Loss: 0.1108, Val Acc: 0.9600\n",
      "Epoch [28/50], Train Loss: 0.1293, Train Acc: 0.9587, Val Loss: 0.1112, Val Acc: 0.9650\n",
      "Epoch [29/50], Train Loss: 0.1266, Train Acc: 0.9587, Val Loss: 0.1093, Val Acc: 0.9650\n",
      "Epoch [30/50], Train Loss: 0.1235, Train Acc: 0.9587, Val Loss: 0.1092, Val Acc: 0.9650\n",
      "Epoch [31/50], Train Loss: 0.1198, Train Acc: 0.9613, Val Loss: 0.1105, Val Acc: 0.9650\n",
      "Epoch [32/50], Train Loss: 0.1166, Train Acc: 0.9600, Val Loss: 0.1098, Val Acc: 0.9600\n",
      "Epoch [33/50], Train Loss: 0.1144, Train Acc: 0.9613, Val Loss: 0.1057, Val Acc: 0.9600\n",
      "Epoch [34/50], Train Loss: 0.1189, Train Acc: 0.9563, Val Loss: 0.1057, Val Acc: 0.9750\n",
      "Epoch [35/50], Train Loss: 0.1178, Train Acc: 0.9650, Val Loss: 0.1044, Val Acc: 0.9550\n",
      "Epoch [36/50], Train Loss: 0.1144, Train Acc: 0.9550, Val Loss: 0.1007, Val Acc: 0.9600\n",
      "Epoch [37/50], Train Loss: 0.1112, Train Acc: 0.9600, Val Loss: 0.1058, Val Acc: 0.9600\n",
      "Epoch [38/50], Train Loss: 0.1077, Train Acc: 0.9600, Val Loss: 0.1055, Val Acc: 0.9600\n",
      "Epoch [39/50], Train Loss: 0.1066, Train Acc: 0.9600, Val Loss: 0.1114, Val Acc: 0.9600\n",
      "Epoch [40/50], Train Loss: 0.1068, Train Acc: 0.9625, Val Loss: 0.1080, Val Acc: 0.9600\n",
      "Epoch [41/50], Train Loss: 0.1045, Train Acc: 0.9637, Val Loss: 0.1043, Val Acc: 0.9600\n",
      "Epoch [42/50], Train Loss: 0.1027, Train Acc: 0.9587, Val Loss: 0.1025, Val Acc: 0.9600\n",
      "Epoch [43/50], Train Loss: 0.1022, Train Acc: 0.9587, Val Loss: 0.1058, Val Acc: 0.9700\n",
      "Epoch [44/50], Train Loss: 0.1025, Train Acc: 0.9650, Val Loss: 0.0972, Val Acc: 0.9600\n",
      "Epoch [45/50], Train Loss: 0.0982, Train Acc: 0.9587, Val Loss: 0.0922, Val Acc: 0.9600\n",
      "Epoch [46/50], Train Loss: 0.0979, Train Acc: 0.9637, Val Loss: 0.0892, Val Acc: 0.9600\n",
      "Epoch [47/50], Train Loss: 0.0956, Train Acc: 0.9663, Val Loss: 0.0895, Val Acc: 0.9650\n",
      "Epoch [48/50], Train Loss: 0.0992, Train Acc: 0.9613, Val Loss: 0.0898, Val Acc: 0.9650\n",
      "Epoch [49/50], Train Loss: 0.0980, Train Acc: 0.9688, Val Loss: 0.0866, Val Acc: 0.9600\n",
      "Epoch [50/50], Train Loss: 0.0965, Train Acc: 0.9625, Val Loss: 0.0852, Val Acc: 0.9600\n",
      "Finished Training CNNModel\n",
      "\n",
      "---------- Test data (CNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.95       428\n",
      "           1       0.93      0.99      0.96       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.96      0.95      0.95      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.956\n",
      "Detection Rate (Recall):  0.9947552447552448\n",
      "F1 Score:  0.9627749576988155\n",
      "ROC AUC Score:  0.9494804261159401\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [3/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [4/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [5/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [6/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [7/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [8/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [9/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [10/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [11/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [12/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [13/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [14/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [15/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [16/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [17/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [18/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [19/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [20/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [21/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [22/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [23/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [24/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [25/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [26/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [27/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [28/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [29/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [30/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [31/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [32/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [33/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [34/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [35/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [36/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [37/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [38/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [39/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [40/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [41/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [42/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [43/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [44/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [45/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [46/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [47/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [48/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [49/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Epoch [50/50], Train Loss: 0.6870, Train Acc: 0.5775, Val Loss: 0.6873, Val Acc: 0.5750\n",
      "Finished Training RNNModel\n",
      "\n",
      "---------- Test data (RNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       428\n",
      "           1       0.57      1.00      0.73       572\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Accuracy:  0.572\n",
      "Detection Rate (Recall):  1.0\n",
      "F1 Score:  0.727735368956743\n",
      "ROC AUC Score:  0.5\n"
     ]
    }
   ],
   "source": [
    "#MLP Target Model \n",
    "mlp_model_target = mlp_model(input_dim)\n",
    "criterion_mlp_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_target = optim.Adam(mlp_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# CNN Target Model\n",
    "cnn_model_target = cnn_model(input_dim)\n",
    "criterion_cnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_target = optim.Adam(cnn_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# RNN Target Model\n",
    "rnn_model_target = rnn_model(input_dim) \n",
    "criterion_rnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_target = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "# ----- MLP -----\n",
    "mlp_target = train_dl_model(mlp_model_target, train_loader, val_loader, criterion_mlp_model_target, optimizer_mlp_model_target, device, num_epochs=50)\n",
    "evaluate_dl_model(mlp_target, test_loader, device,model_type='mlp', name=\"Test\")\n",
    "\n",
    "# ----- CNN -----\n",
    "cnn_target = train_dl_model(cnn_model_target, train_loader, val_loader, criterion_cnn_model_target, optimizer_cnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(cnn_target, test_loader, device,model_type='cnn', name=\"Test\")\n",
    "\n",
    "# ----- RNN -----\n",
    "rnn_target = train_dl_model(rnn_model_target, train_loader, val_loader, criterion_rnn_model_target, optimizer_rnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(rnn_target, test_loader, device,model_type='rnn', name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb65e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train): (array([0, 1]), array([423, 577], dtype=int64))\n",
      "üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test): (array([0, 1]), array([ 855, 1145], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "SUB_TRAIN = min(1000, len(X_train_full))\n",
    "SUB_TEST = min(2000, len(X_test_full))\n",
    "# S·ª≠ d·ª•ng m·∫´u nh·ªè ho·∫∑c to√†n b·ªô d·ªØ li·ªáu\n",
    "X_train, y_train = X_train_full[:SUB_TRAIN], y_train_full[:SUB_TRAIN]\n",
    "X_test, y_test = X_test_full[:SUB_TEST], y_test_full[:SUB_TEST]\n",
    "# N·∫øu mu·ªën d√πng to√†n b·ªô d·ªØ li·ªáu, b·ªè d√≤ng tr√™n v√† d√πng:\n",
    "# X_train, y_train = X_train_full, y_train_full\n",
    "# X_test, y_test = X_test_full, y_test_full\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train):\", np.unique(y_train, return_counts=True))\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test):\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d39e49f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN-based selector with cluster-specific DQNs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training models for cluster 0\n",
      "Cluster 0, Epoch 1/30, Avg Reward: 1.0022\n",
      "Cluster 0, Epoch 2/30, Avg Reward: 0.9962\n",
      "Cluster 0, Epoch 3/30, Avg Reward: 1.0050\n",
      "Cluster 0, Epoch 4/30, Avg Reward: 1.0023\n",
      "Cluster 0, Epoch 5/30, Avg Reward: 1.0059\n",
      "Cluster 0, Epoch 6/30, Avg Reward: 0.9959\n",
      "Cluster 0, Epoch 7/30, Avg Reward: 0.9930\n",
      "Cluster 0, Epoch 8/30, Avg Reward: 1.0055\n",
      "Cluster 0, Epoch 9/30, Avg Reward: 1.0047\n",
      "Cluster 0, Epoch 10/30, Avg Reward: 1.0056\n",
      "Cluster 0, Epoch 11/30, Avg Reward: 0.9896\n",
      "Cluster 0, Epoch 12/30, Avg Reward: 1.0039\n",
      "Cluster 0, Epoch 13/30, Avg Reward: 0.9961\n",
      "Cluster 0, Epoch 14/30, Avg Reward: 1.0037\n",
      "Cluster 0, Epoch 15/30, Avg Reward: 0.9902\n",
      "Cluster 0, Epoch 16/30, Avg Reward: 0.9995\n",
      "Cluster 0, Epoch 17/30, Avg Reward: 0.9995\n",
      "Cluster 0, Epoch 18/30, Avg Reward: 1.0067\n",
      "Cluster 0, Epoch 19/30, Avg Reward: 1.0027\n",
      "Cluster 0, Epoch 20/30, Avg Reward: 0.9993\n",
      "Cluster 0, Epoch 21/30, Avg Reward: 1.0085\n",
      "Cluster 0, Epoch 22/30, Avg Reward: 1.0047\n",
      "Cluster 0, Epoch 23/30, Avg Reward: 1.0076\n",
      "Cluster 0, Epoch 24/30, Avg Reward: 0.9982\n",
      "Cluster 0, Epoch 25/30, Avg Reward: 0.9878\n",
      "Cluster 0, Epoch 26/30, Avg Reward: 0.9959\n",
      "Cluster 0, Epoch 27/30, Avg Reward: 1.0019\n",
      "Cluster 0, Epoch 28/30, Avg Reward: 0.9996\n",
      "Cluster 0, Epoch 29/30, Avg Reward: 1.0053\n",
      "Cluster 0, Epoch 30/30, Avg Reward: 1.0022\n",
      "\n",
      " Training models for cluster 1\n",
      "Cluster 1, Epoch 1/30, Avg Reward: 0.9805\n",
      "Cluster 1, Epoch 2/30, Avg Reward: 0.9843\n",
      "Cluster 1, Epoch 3/30, Avg Reward: 0.9880\n",
      "Cluster 1, Epoch 4/30, Avg Reward: 0.9855\n",
      "Cluster 1, Epoch 5/30, Avg Reward: 0.9826\n",
      "Cluster 1, Epoch 6/30, Avg Reward: 0.9850\n",
      "Cluster 1, Epoch 7/30, Avg Reward: 0.9939\n",
      "Cluster 1, Epoch 8/30, Avg Reward: 0.9898\n",
      "Cluster 1, Epoch 9/30, Avg Reward: 0.9699\n",
      "Cluster 1, Epoch 10/30, Avg Reward: 0.9871\n",
      "Cluster 1, Epoch 11/30, Avg Reward: 0.9951\n",
      "Cluster 1, Epoch 12/30, Avg Reward: 0.9990\n",
      "Cluster 1, Epoch 13/30, Avg Reward: 0.9837\n",
      "Cluster 1, Epoch 14/30, Avg Reward: 0.9734\n",
      "Cluster 1, Epoch 15/30, Avg Reward: 0.9784\n",
      "Cluster 1, Epoch 16/30, Avg Reward: 0.9921\n",
      "Cluster 1, Epoch 17/30, Avg Reward: 0.9870\n",
      "Cluster 1, Epoch 18/30, Avg Reward: 0.9815\n",
      "Cluster 1, Epoch 19/30, Avg Reward: 0.9916\n",
      "Cluster 1, Epoch 20/30, Avg Reward: 0.9945\n",
      "Cluster 1, Epoch 21/30, Avg Reward: 0.9836\n",
      "Cluster 1, Epoch 22/30, Avg Reward: 0.9810\n",
      "Cluster 1, Epoch 23/30, Avg Reward: 0.9864\n",
      "Cluster 1, Epoch 24/30, Avg Reward: 0.9905\n",
      "Cluster 1, Epoch 25/30, Avg Reward: 0.9796\n",
      "Cluster 1, Epoch 26/30, Avg Reward: 0.9853\n",
      "Cluster 1, Epoch 27/30, Avg Reward: 0.9991\n",
      "Cluster 1, Epoch 28/30, Avg Reward: 0.9826\n",
      "Cluster 1, Epoch 29/30, Avg Reward: 0.9915\n",
      "Cluster 1, Epoch 30/30, Avg Reward: 0.9792\n",
      "\n",
      " Training models for cluster 2\n",
      "Cluster 2, Epoch 1/30, Avg Reward: 1.0019\n",
      "Cluster 2, Epoch 2/30, Avg Reward: 1.0020\n",
      "Cluster 2, Epoch 3/30, Avg Reward: 0.9985\n",
      "Cluster 2, Epoch 4/30, Avg Reward: 0.9972\n",
      "Cluster 2, Epoch 5/30, Avg Reward: 1.0084\n",
      "Cluster 2, Epoch 6/30, Avg Reward: 0.9919\n",
      "Cluster 2, Epoch 7/30, Avg Reward: 0.9953\n",
      "Cluster 2, Epoch 8/30, Avg Reward: 1.0002\n",
      "Cluster 2, Epoch 9/30, Avg Reward: 0.9934\n",
      "Cluster 2, Epoch 10/30, Avg Reward: 1.0056\n",
      "Cluster 2, Epoch 11/30, Avg Reward: 0.9980\n",
      "Cluster 2, Epoch 12/30, Avg Reward: 1.0081\n",
      "Cluster 2, Epoch 13/30, Avg Reward: 0.9927\n",
      "Cluster 2, Epoch 14/30, Avg Reward: 0.9940\n",
      "Cluster 2, Epoch 15/30, Avg Reward: 1.0003\n",
      "Cluster 2, Epoch 16/30, Avg Reward: 1.0052\n",
      "Cluster 2, Epoch 17/30, Avg Reward: 0.9964\n",
      "Cluster 2, Epoch 18/30, Avg Reward: 1.0152\n",
      "Cluster 2, Epoch 19/30, Avg Reward: 0.9983\n",
      "Cluster 2, Epoch 20/30, Avg Reward: 1.0011\n",
      "Cluster 2, Epoch 21/30, Avg Reward: 0.9933\n",
      "Cluster 2, Epoch 22/30, Avg Reward: 1.0048\n",
      "Cluster 2, Epoch 23/30, Avg Reward: 1.0074\n",
      "Cluster 2, Epoch 24/30, Avg Reward: 0.9923\n",
      "Cluster 2, Epoch 25/30, Avg Reward: 1.0025\n",
      "Cluster 2, Epoch 26/30, Avg Reward: 0.9995\n",
      "Cluster 2, Epoch 27/30, Avg Reward: 0.9977\n",
      "Cluster 2, Epoch 28/30, Avg Reward: 0.9992\n",
      "Cluster 2, Epoch 29/30, Avg Reward: 0.9978\n",
      "Cluster 2, Epoch 30/30, Avg Reward: 1.0013\n",
      "Predicting on test set...\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 806 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 633 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 561 l·∫ßn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00      1145\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Accuracy: 0.999\n",
      "Recall (macro): 0.9988304093567251\n",
      "F1 Score (macro): 0.9989782197318031\n",
      "ROC AUC: 0.9988304093567251\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# DQN Training and Evaluation\n",
    "# =====================\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "dqn = DQNModelSelector(models, n_clusters=3)\n",
    "\n",
    "print(\"Training DQN-based selector with cluster-specific DQNs...\")\n",
    "dqn.train(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_dqn, arms = dqn.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_dqn = np.array([int(x) for x in y_pred_dqn])\n",
    "\n",
    "print(classification_report(y_test, y_pred_dqn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dqn))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dqn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7176a30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 287 samples\n",
      "Training arm 0 on cluster 0\n",
      "cluster_X_train shape: (287, 68)\n",
      "cluster_y_train shape: (287,)\n",
      "arm_mask shape: (287,)\n",
      "Training arm 1 on cluster 0\n",
      "cluster_X_train shape: (287, 68)\n",
      "cluster_y_train shape: (287,)\n",
      "arm_mask shape: (287,)\n",
      "Training arm 2 on cluster 0\n",
      "cluster_X_train shape: (287, 68)\n",
      "cluster_y_train shape: (287,)\n",
      "arm_mask shape: (287,)\n",
      "Cluster 1: 713 samples\n",
      "Training arm 0 on cluster 1\n",
      "cluster_X_train shape: (713, 68)\n",
      "cluster_y_train shape: (713,)\n",
      "arm_mask shape: (713,)\n",
      "Training arm 1 on cluster 1\n",
      "cluster_X_train shape: (713, 68)\n",
      "cluster_y_train shape: (713,)\n",
      "arm_mask shape: (713,)\n",
      "Training arm 2 on cluster 1\n",
      "cluster_X_train shape: (713, 68)\n",
      "cluster_y_train shape: (713,)\n",
      "arm_mask shape: (713,)\n",
      "Setting reward_sums arm 0 on cluster 0\n",
      "Setting reward_sums arm 1 on cluster 0\n",
      "Setting reward_sums arm 2 on cluster 0\n",
      "Setting reward_sums arm 0 on cluster 1\n",
      "Setting reward_sums arm 1 on cluster 1\n",
      "Setting reward_sums arm 2 on cluster 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00      1145\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Accuracy: 0.9965\n",
      "Recall (macro): 0.996647003243188\n",
      "F1 Score (macro): 0.9964264117779341\n",
      "ROC AUC: 0.9966470032431881\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# MAB Training and Evaluation\n",
    "# =====================\n",
    "mab = MultiArmedBanditThompsonSampling(n_arms=3, n_clusters=2)\n",
    "mab.train(X_train, y_train)\n",
    "\n",
    "y_pred_mab, selected_arms = mab.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_mab = np.array([int(x) for x in y_pred_mab])\n",
    "\n",
    "print(classification_report(y_test, y_pred_mab))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mab))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_mab, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_mab, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_mab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18203be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38408, 68) (29316, 68)\n",
      "19\n",
      "[0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66] 56\n",
      "[3, 7, 13, 32, 48, 49, 50, 52, 53, 57, 59] 11\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "attacks_data = X_test_full[y_test_full == 1]\n",
    "normal_data = X_test_full[y_test_full == 0]\n",
    "print(attacks_data.shape, normal_data.shape)\n",
    "\n",
    "FUNCTIONAL_FEATURES = [\n",
    " ' min_seg_size_forward',' Bwd Header Length',' Destination Port'\n",
    " 'Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s'\n",
    " 'Total Length of Fwd Packets',' Subflow Fwd Bytes',' Max Packet Length'\n",
    " 'Bwd Packet Length Max',' Avg Bwd Segment Size',' Bwd Packet Length Mean'\n",
    " ' Fwd Packet Length Max',' Average Packet Size',' Packet Length Std'\n",
    " ' Packet Length Mean',' Bwd Packet Length Std',' Bwd Packet Length Min'\n",
    " ' Fwd Packet Length Std',' Fwd Packet Length Min',' Min Packet Length'\n",
    " ' Fwd Packet Length Mean',' Avg Fwd Segment Size',' act_data_pkt_fwd'\n",
    " ' Total Fwd Packets','Subflow Fwd Packets',' Total Backward Packets']\n",
    "print(len(FUNCTIONAL_FEATURES))\n",
    "FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c not in FUNCTIONAL_FEATURES][:-1]\n",
    "print(FUNCTIONAL_FEATURES_IDEXES, len(FUNCTIONAL_FEATURES_IDEXES))\n",
    "NON_FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c in FUNCTIONAL_FEATURES]\n",
    "print(NON_FUNCTIONAL_FEATURES_IDEXES, len(NON_FUNCTIONAL_FEATURES_IDEXES))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357c40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier\n",
    "class Classifier(ScikitlearnClassifier):\n",
    "    \n",
    "    def __init__(self, model, clip_values=None, preprocessing=(0, 1), attacks=[]):\n",
    "        super(Classifier, self).__init__(model=model, clip_values=clip_values, preprocessing=preprocessing)\n",
    "        self._attacks = attacks\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        # Set attacks features to X\n",
    "        for i in FUNCTIONAL_FEATURES_IDEXES:\n",
    "            for j in range(len(x)):\n",
    "                x[j][i] = self._attacks[j][i]\n",
    "        predictions = self._model.predict(x)\n",
    "        return to_categorical(predictions, nb_classes=self._get_nb_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285ce3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:04<00:00, 113.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  GaussianNB()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 427 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 313 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 260 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  0.996\n",
      "F1 Score:  0.9979959919839679\n",
      "ROC AUC Score:  0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:03<00:00, 132.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  DecisionTreeClassifier()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 427 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 313 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 260 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       500\n",
      "           1       1.00      0.99      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       1.00      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.995\n",
      "Detection Rate:  0.992\n",
      "F1 Score:  0.9949849548645938\n",
      "ROC AUC Score:  0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:04<00:00, 116.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  LogisticRegression()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 427 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 313 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 260 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  0.996\n",
      "F1 Score:  0.9979959919839679\n",
      "ROC AUC Score:  0.998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:21<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  RandomForestClassifier(random_state=42)\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 427 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 313 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 260 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  0.996\n",
      "F1 Score:  0.9979959919839679\n",
      "ROC AUC Score:  0.998\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "=== MAB ===\n",
      "Accuracy:  0.99725\n",
      "Detection Rate:  0.995\n",
      "F1 Score:  0.9972432327041244\n",
      "ROC AUC Score:  0.99725\n"
     ]
    }
   ],
   "source": [
    "# ===================== Adversarial Attacks on ML Models =====================\n",
    "models = [nb, dt, lr, rf]\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "\n",
    "for model in models:\n",
    "    classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n",
    "    attack = ZooAttack(classifier=classifier, targeted=False, nb_parallel=60)\n",
    "    \n",
    "    x_test_adv = attack.generate(attacks_data[:500], np.zeros((attacks_data[:500].shape[0], 1)))\n",
    "\n",
    "    non_adv_x_test = np.concatenate((attacks_data[:500], normal_data[:500]))\n",
    "    non_adv_y_test = np.concatenate((np.ones((attacks_data[:500].shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data[:500]))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    y_pred_dqn = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn)\n",
    "    recall = recall_score(y_true, y_pred_dqn)\n",
    "    f1 = f1_score(y_true, y_pred_dqn)\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8106ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======> Attacking model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ZOO: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:36<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 427 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 313 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 260 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       500\n",
      "           1       1.00      0.99      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.994\n",
      "Detection Rate:  0.992\n",
      "F1 Score:  0.9939879759519038\n",
      "ROC AUC Score:  0.994\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "=== MAB ===\n",
      "Accuracy:  0.994\n",
      "Detection Rate:  0.992\n",
      "F1 Score:  0.9939879759519038\n",
      "ROC AUC Score:  0.994\n"
     ]
    }
   ],
   "source": [
    "# ===================== Adversarial Attacks on DL Models =====================\n",
    "models = [mlp_target]\n",
    "criterions = [criterion_mlp_model_target]\n",
    "optimizers = [optimizer_mlp_model_target]\n",
    "input_shapes = [(input_dim,)]\n",
    "model_types = ['mlp']\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "attacks_data = attacks_data.astype(np.float32)\n",
    "normal_data = normal_data.astype(np.float32)\n",
    "for i, model in enumerate(models):\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        loss=criterions[i],\n",
    "        optimizer=optimizers[i],\n",
    "        input_shape=input_shapes[i],\n",
    "        nb_classes=2,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n======> Attacking model: {model_types[i].upper()}\")\n",
    "    \n",
    "    x_input = attacks_data[:500]\n",
    "    normal_data_reshaped = normal_data[:500]\n",
    "\n",
    "    # Sinh m·∫´u t·∫•n c√¥ng\n",
    "    attack = ZooAttack(classifier=classifier, targeted=False, nb_parallel=60)\n",
    "    x_test_adv = attack.generate(x_input, np.zeros((x_input.shape[0], 1)))\n",
    "\n",
    "    # G·ªôp v·ªõi d·ªØ li·ªáu b√¨nh th∆∞·ªùng\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data_reshaped))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data_reshaped.shape[0], 1))))\n",
    "    adv_x_test = adv_x_test.astype(np.float64)\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    if adv_x_test.ndim == 3:\n",
    "        adv_x_test = adv_x_test.reshape((adv_x_test.shape[0], -1))\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_pred_dqn  = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn )\n",
    "    recall = recall_score(y_true, y_pred_dqn )\n",
    "    f1 = f1_score(y_true, y_pred_dqn )\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn )\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39DQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
