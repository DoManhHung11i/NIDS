{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddbae6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from art.estimators.classification import KerasClassifier, SklearnClassifier\n",
    "from art.attacks.evasion import HopSkipJump, ZooAttack, ProjectedGradientDescent, CarliniL2Method\n",
    "from art.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Input\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset, datasets_types\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado\n",
      "Loading new data\n",
      "labels: {'Web Attack � XSS', 'Infiltration', 'Web Attack � Brute Force', 'Web Attack � Sql Injection'}\n",
      "Dataset Preprocesado\n"
     ]
    }
   ],
   "source": [
    "name = \"CIC-IDS_2017_2\"\n",
    "df = load_data(\n",
    "            [\n",
    "                \"./shared/data/CIC_2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
    "                \"./shared/data/CIC_2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "            ],\n",
    "            seed\n",
    "        )\n",
    "print(\"Dataset loaded\")\n",
    "df_preprocessed = preprocess_dataset(\n",
    "    df, save=True, dataset_type=\"CIC_2017\", seed=seed, load=False, name_save=name, name_load=name)\n",
    "print(\"Dataset preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "919c9d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "(321277, 70)\n",
      "(321277,)\n",
      "(137691, 70)\n",
      "(137691,)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_preprocessed.x_train\n",
    "y_train = df_preprocessed.y_train\n",
    "x_test = df_preprocessed.x_test\n",
    "y_test = df_preprocessed.y_test\n",
    "\n",
    "y_train = y_train.apply(lambda x: int(x))\n",
    "y_test = y_test.apply(lambda x: int(x))\n",
    "\n",
    "print(y_train.unique())\n",
    "print(y_test.unique())\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41e81f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 70) (137026, 70)\n"
     ]
    }
   ],
   "source": [
    "attacks_data = x_test[y_test == 1]\n",
    "normal_data = x_test[y_test == 0]\n",
    "print(attacks_data.shape, normal_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5255ba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "321277/321277 [==============================] - 15s 45us/step - loss: 0.0052 - acc: 0.9991\n",
      "Epoch 2/3\n",
      "321277/321277 [==============================] - 13s 40us/step - loss: 0.0030 - acc: 0.9994\n",
      "Epoch 3/3\n",
      "321277/321277 [==============================] - 13s 39us/step - loss: 0.0028 - acc: 0.9995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c46169e48>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Model\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(128, input_dim=x_train.shape[1], activation='relu'))\n",
    "mlp_model.add(Dense(64, activation='relu'))\n",
    "mlp_model.add(Dense(2, activation='softmax'))  # Update to have 2 output units for binary classification\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy for multi-class\n",
    "\n",
    "# Convert y_train and y_test to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_model.fit(x_train, y_train_one_hot, epochs=3, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cf10d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "321277/321277 [==============================] - 81s 253us/step - loss: 0.0070 - acc: 0.9987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c462035c8>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu', input_shape=(x_train.shape[1], 1)))  # Assuming 1D data\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(2, activation='softmax'))  # Update to have 2 output units for binary classification\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy for multi-class\n",
    "\n",
    "# Reshaping data for CNN (as CNN expects 3D input)\n",
    "x_train_cnn = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test_cnn = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Convert y_train and y_test to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(x_train_cnn, y_train_one_hot, epochs=1, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bf29738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "321277/321277 [==============================] - 406s 1ms/step - loss: 0.0316 - acc: 0.9952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c46d7cfc8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model using LSTM\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(64, input_shape=(x_train.shape[1], 1), return_sequences=False))\n",
    "rnn_model.add(Dense(32, activation='relu'))\n",
    "rnn_model.add(Dense(2, activation='softmax'))  # Update to have 2 output units for binary classification\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy for multi-class\n",
    "\n",
    "# Reshaping data for RNN\n",
    "x_train_rnn = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test_rnn = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Train the RNN model\n",
    "rnn_model.fit(x_train_rnn, y_train_one_hot, epochs=1, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d3465370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68] 58\n",
      "[3, 7, 13, 33, 50, 51, 52, 54, 55, 59, 61] 11\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "FUNCTIONAL_FEATURES = [\n",
    " ' min_seg_size_forward',' Bwd Header Length',' Destination Port'\n",
    " 'Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s'\n",
    " 'Total Length of Fwd Packets',' Subflow Fwd Bytes',' Max Packet Length'\n",
    " 'Bwd Packet Length Max',' Avg Bwd Segment Size',' Bwd Packet Length Mean'\n",
    " ' Fwd Packet Length Max',' Average Packet Size',' Packet Length Std'\n",
    " ' Packet Length Mean',' Bwd Packet Length Std',' Bwd Packet Length Min'\n",
    " ' Fwd Packet Length Std',' Fwd Packet Length Min',' Min Packet Length'\n",
    " ' Fwd Packet Length Mean',' Avg Fwd Segment Size',' act_data_pkt_fwd'\n",
    " ' Total Fwd Packets','Subflow Fwd Packets',' Total Backward Packets']\n",
    "print(len(FUNCTIONAL_FEATURES))\n",
    "FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c not in FUNCTIONAL_FEATURES][:-1]\n",
    "print(FUNCTIONAL_FEATURES_IDEXES, len(FUNCTIONAL_FEATURES_IDEXES))\n",
    "NON_FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c in FUNCTIONAL_FEATURES]\n",
    "print(NON_FUNCTIONAL_FEATURES_IDEXES, len(NON_FUNCTIONAL_FEATURES_IDEXES))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a0a0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(KerasClassifier):\n",
    "    \n",
    "    def __init__(self, model, clip_values=None, preprocessing=(0, 1), attacks=[]):\n",
    "        # Wrap model into ART classifier\n",
    "        super(Classifier, self).__init__(model=model, clip_values=clip_values, preprocessing=preprocessing)\n",
    "        self._attacks = attacks\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        # Set attacks features to X\n",
    "        for i in FUNCTIONAL_FEATURES_IDEXES:\n",
    "            for j in range(len(x)):\n",
    "                x[j][i] = self._attacks[j][i]\n",
    "        predictions = self._model.predict(x)\n",
    "        return to_categorical(predictions, num_classes=self._get_nb_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79109f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_for_model(model, x_data):\n",
    "    from tensorflow import keras  # hoặc `import keras` nếu bạn dùng keras thường\n",
    "    first_layer = type(model.layers[0]).__name__.lower()\n",
    "\n",
    "    if 'dense' in first_layer:\n",
    "        return x_data.reshape((x_data.shape[0], -1))  # MLP\n",
    "    elif 'conv1d' in first_layer:\n",
    "        return x_data.reshape((x_data.shape[0], x_data.shape[1], 1))  # CNN\n",
    "    elif 'lstm' in first_layer:\n",
    "        return x_data.reshape((x_data.shape[0], x_data.shape[1], 1)) \n",
    "    else:\n",
    "        raise ValueError(f\"Không rõ loại mô hình với lớp đầu tiên: {first_layer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_art_classifier(model):\n",
    "    # Wrap model into ART classifier\n",
    "    classifier = KerasClassifier(model=model, clip_values=(0, 1), use_logits=False)\n",
    "    return classifier\n",
    "\n",
    "# Create Carlini-Wagner L2 Attack\n",
    "def create_carlini_wagner_attack(classifier):\n",
    "    # Initialize Carlini L2 attack\n",
    "    cw_attack = CarliniL2Method(classifier, targeted=False, max_iter=300, confidence=0, learning_rate=0.01, binary_search_steps=3)\n",
    "    return cw_attack\n",
    "\n",
    "# Train and test the model with Carlini-Wagner attack\n",
    "def train_and_test_with_carlini_wagner(model, model_name, classifier, attack_data, normal_data):\n",
    "    # Create Carlini-Wagner L2 attack\n",
    "    cw_attack = create_carlini_wagner_attack(classifier)\n",
    "    \n",
    "    x_input = prepare_input_for_model(model, attack_data[:100])\n",
    "    x_test_adv = cw_attack.generate(x_input)\n",
    "    # Generate adversarial data using Carlini-Wagner attack\n",
    "    # x_test_adv = cw_attack.generate(x_test[:10])  # Apply attack on the first 100 samples\n",
    "    \n",
    "    # Concatenate adversarial examples with normal data\n",
    "    non_adv_x_test = np.concatenate((attack_data[:100], normal_data[:100]))\n",
    "    non_adv_y_test = np.concatenate((np.ones((attack_data[:100].shape[0], 1)), np.zeros((normal_data[:100].shape[0], 1))))\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data[:100]))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data[:100].shape[0], 1))))\n",
    "    \n",
    "    # Evaluate the model with the adversarial data\n",
    "    print(\"==========> Model: \", model_name)\n",
    "   # Predict for non-adversarial data\n",
    "    non_adv_predictions = model.predict(non_adv_x_test)\n",
    "    non_adv_pred_labels = np.argmax(non_adv_predictions, axis=1)  # If the output is probabilities\n",
    "    \n",
    "    # Predict for adversarial data\n",
    "    adv_predictions = model.predict(adv_x_test)\n",
    "    adv_pred_labels = np.argmax(adv_predictions, axis=1)\n",
    "\n",
    "    # Convert true labels to integer type\n",
    "    true_non_adv_labels = non_adv_y_test.flatten().astype(int)\n",
    "    true_adv_labels = adv_y_test.flatten().astype(int)\n",
    "\n",
    "   # Evaluate the model on non-adversarial data\n",
    "    print(\"---------- Non adversarial data\")\n",
    "    print(classification_report(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"Accuracy: \", accuracy_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"Detection Rate: \", recall_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"F1 Score: \", f1_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"ROC AUC Score: \", roc_auc_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "\n",
    "    # Evaluate the model on adversarial data\n",
    "    print(\"---------- Adversarial data\")\n",
    "    print(classification_report(true_adv_labels, adv_pred_labels))\n",
    "    print(\"Accuracy: \", accuracy_score(true_adv_labels, adv_pred_labels))\n",
    "    print(\"Detection Rate (Recall): \", recall_score(true_adv_labels, adv_pred_labels))\n",
    "    print(\"F1 Score: \", f1_score(true_adv_labels, adv_pred_labels))\n",
    "    print(\"ROC AUC Score: \", roc_auc_score(true_adv_labels, adv_pred_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2d0c8df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP model with Carlini-Wagner attack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 100/100 [07:26<00:00,  4.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========> Model:  MLP\n",
      "---------- Non adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94       100\n",
      "           1       1.00      0.88      0.94       100\n",
      "\n",
      "    accuracy                           0.94       200\n",
      "   macro avg       0.95      0.94      0.94       200\n",
      "weighted avg       0.95      0.94      0.94       200\n",
      "\n",
      "Accuracy:  0.94\n",
      "Detection Rate:  0.88\n",
      "F1 Score:  0.9361702127659575\n",
      "ROC AUC Score:  0.94\n",
      "---------- Adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75       100\n",
      "           1       1.00      0.32      0.48       100\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.80      0.66      0.62       200\n",
      "weighted avg       0.80      0.66      0.62       200\n",
      "\n",
      "Accuracy:  0.66\n",
      "Detection Rate (Recall):  0.32\n",
      "F1 Score:  0.48484848484848486\n",
      "ROC AUC Score:  0.66\n",
      "Evaluating CNN model with Carlini-Wagner attack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 100/100 [19:00<00:00, 11.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========> Model:  CNN\n",
      "---------- Non adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       100\n",
      "           1       1.00      0.91      0.95       100\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.96      0.96      0.95       200\n",
      "weighted avg       0.96      0.95      0.95       200\n",
      "\n",
      "Accuracy:  0.955\n",
      "Detection Rate:  0.91\n",
      "F1 Score:  0.9528795811518325\n",
      "ROC AUC Score:  0.9550000000000001\n",
      "---------- Adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93       100\n",
      "           1       1.00      0.84      0.91       100\n",
      "\n",
      "    accuracy                           0.92       200\n",
      "   macro avg       0.93      0.92      0.92       200\n",
      "weighted avg       0.93      0.92      0.92       200\n",
      "\n",
      "Accuracy:  0.92\n",
      "Detection Rate (Recall):  0.84\n",
      "F1 Score:  0.9130434782608696\n",
      "ROC AUC Score:  0.9199999999999999\n",
      "Evaluating RNN model with Carlini-Wagner attack...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2:  35%|███▌      | 35/100 [40:46<1:15:43, 69.90s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9780\\857654779.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# Test the model with Carlini-Wagner adversarial data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Evaluating {model_name} model with Carlini-Wagner attack...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mtrain_and_test_with_carlini_wagner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattack_data_reshaped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormal_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormal_data_reshaped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9780\\2763586414.py\u001b[0m in \u001b[0;36mtrain_and_test_with_carlini_wagner\u001b[1;34m(model, model_name, classifier, attack_data, normal_data)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mx_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprepare_input_for_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattack_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mx_test_adv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcw_attack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Generate adversarial data using Carlini-Wagner attack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# x_test_adv = cw_attack.generate(x_test[:10])  # Apply attack on the first 100 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\art\\attacks\\evasion\\carlini.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m                             \u001b[0mnew_x_adv_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                             \u001b[0my_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactive_and_do_halving\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                             \u001b[0mc_current\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mactive_and_do_halving\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                         )\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\art\\attacks\\evasion\\carlini.py\u001b[0m in \u001b[0;36m_loss\u001b[1;34m(self, x, x_adv, target, c_weight)\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_adv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mART_NUMPY_DTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m             \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m         )\n\u001b[0;32m    156\u001b[0m         \u001b[0mz_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_predicted\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\art\\estimators\\classification\\classifier.py\u001b[0m in \u001b[0;36mreplacement_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m                     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mreplacement_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\art\\estimators\\classification\\keras.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, training_mode, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_preprocessed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;31m# Apply postprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m                                             steps=steps)\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [mlp_model,cnn_model, rnn_model]\n",
    "model_names = ['MLP', 'CNN', 'RNN']\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    # Wrap model into ART classifier\n",
    "    classifier = KerasClassifier(model, clip_values=(0, 1))\n",
    "    \n",
    "    # Determine the data to use for each model\n",
    "    if model_name == \"CNN\" or model_name == \"RNN\":\n",
    "        # If the model is CNN or RNN, reshape normal_data to be 3D\n",
    "        normal_data_reshaped = normal_data.reshape((normal_data.shape[0], normal_data.shape[1], 1))\n",
    "        attack_data_reshaped = attacks_data.reshape((attacks_data.shape[0], attacks_data.shape[1], 1))\n",
    "    else:\n",
    "        # For MLP (or other models), keep normal_data as 2D\n",
    "        normal_data_reshaped = normal_data\n",
    "        attack_data_reshaped = attacks_data\n",
    "\n",
    "    # Test the model with Carlini-Wagner adversarial data\n",
    "    print(f\"Evaluating {model_name} model with Carlini-Wagner attack...\")\n",
    "    train_and_test_with_carlini_wagner(model, model_name, classifier, attack_data=attack_data_reshaped, normal_data=normal_data_reshaped)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
