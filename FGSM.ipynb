{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825f82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "from art.estimators.classification import KerasClassifier, SklearnClassifier\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, LSTM, Input\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset, datasets_types\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "seed = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21262fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Loading new data\n",
      "labels: {'Web Attack � Brute Force', 'Web Attack � Sql Injection', 'Web Attack � XSS', 'FTP-Patator', 'Infiltration', 'SSH-Patator'}\n",
      "Dataset preprocessed\n"
     ]
    }
   ],
   "source": [
    "name = \"CIC-IDS_2017_2\"\n",
    "df = load_data(\n",
    "            [\n",
    "                \"./shared/data/CIC_2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\",\n",
    "                \"./shared/data/CIC_2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "                \"./shared/data/CIC_2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "            ],\n",
    "            seed\n",
    "        )\n",
    "print(\"Dataset loaded\")\n",
    "df_preprocessed = preprocess_dataset(\n",
    "    df, save=True, dataset_type=\"CIC_2017\", seed=seed, load=False, name_save=name, name_load=name)\n",
    "print(\"Dataset preprocessed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d9842a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n",
      "[0 1]\n",
      "(633413, 70)\n",
      "(633413,)\n",
      "(271464, 70)\n",
      "(271464,)\n"
     ]
    }
   ],
   "source": [
    "x_train = df_preprocessed.x_train\n",
    "y_train = df_preprocessed.y_train\n",
    "x_test = df_preprocessed.x_test\n",
    "y_test = df_preprocessed.y_test\n",
    "\n",
    "y_train = y_train.apply(lambda x: int(x))\n",
    "y_test = y_test.apply(lambda x: int(x))\n",
    "\n",
    "print(y_train.unique())\n",
    "print(y_test.unique())\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2944c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4815, 70) (266649, 70)\n"
     ]
    }
   ],
   "source": [
    "attacks_data = x_test[y_test == 1]\n",
    "normal_data = x_test[y_test == 0]\n",
    "print(attacks_data.shape, normal_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ee38cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "633413/633413 [==============================] - 28s 45us/step - loss: 0.0095 - acc: 0.9974\n",
      "Epoch 2/3\n",
      "633413/633413 [==============================] - 30s 47us/step - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 3/3\n",
      "633413/633413 [==============================] - 30s 48us/step - loss: 0.0045 - acc: 0.9991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x185b0d18ac8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Model\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(128, input_dim=x_train.shape[1], activation='relu'))\n",
    "mlp_model.add(Dense(64, activation='relu'))\n",
    "mlp_model.add(Dense(2, activation='softmax'))  # Update to have 2 output units for binary classification\n",
    "\n",
    "mlp_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy for multi-class\n",
    "\n",
    "# Convert y_train and y_test to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_model.fit(x_train, y_train_one_hot, epochs=3, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6845213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda3\\envs\\env3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/1\n",
      "633413/633413 [==============================] - 151s 238us/step - loss: 0.0122 - acc: 0.9964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1858b8c0fc8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN Model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu', input_shape=(x_train.shape[1], 1)))  # Assuming 1D data\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(2, activation='softmax'))  # Update to have 2 output units for binary classification\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy for multi-class\n",
    "\n",
    "# Reshaping data for CNN (as CNN expects 3D input)\n",
    "x_train_cnn = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test_cnn = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Convert y_train and y_test to one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(x_train_cnn, y_train_one_hot, epochs=1, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be26736f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "633413/633413 [==============================] - 958s 2ms/step - loss: 0.0777 - acc: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1858c84e808>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model using LSTM\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(64, input_shape=(x_train.shape[1], 1), return_sequences=False))\n",
    "rnn_model.add(Dense(32, activation='relu'))\n",
    "rnn_model.add(Dense(2, activation='softmax'))  # Update to have 2 output units for binary classification\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  # Use categorical_crossentropy for multi-class\n",
    "\n",
    "# Reshaping data for RNN\n",
    "x_train_rnn = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test_rnn = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "# Train the RNN model\n",
    "rnn_model.fit(x_train_rnn, y_train_one_hot, epochs=1, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd728019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "[0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 56, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68] 58\n",
      "[3, 7, 13, 33, 50, 51, 52, 54, 55, 59, 61] 11\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "FUNCTIONAL_FEATURES = [\n",
    " ' min_seg_size_forward',' Bwd Header Length',' Destination Port'\n",
    " 'Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s'\n",
    " 'Total Length of Fwd Packets',' Subflow Fwd Bytes',' Max Packet Length'\n",
    " 'Bwd Packet Length Max',' Avg Bwd Segment Size',' Bwd Packet Length Mean'\n",
    " ' Fwd Packet Length Max',' Average Packet Size',' Packet Length Std'\n",
    " ' Packet Length Mean',' Bwd Packet Length Std',' Bwd Packet Length Min'\n",
    " ' Fwd Packet Length Std',' Fwd Packet Length Min',' Min Packet Length'\n",
    " ' Fwd Packet Length Mean',' Avg Fwd Segment Size',' act_data_pkt_fwd'\n",
    " ' Total Fwd Packets','Subflow Fwd Packets',' Total Backward Packets']\n",
    "print(len(FUNCTIONAL_FEATURES))\n",
    "FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c not in FUNCTIONAL_FEATURES][:-1]\n",
    "print(FUNCTIONAL_FEATURES_IDEXES, len(FUNCTIONAL_FEATURES_IDEXES))\n",
    "NON_FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c in FUNCTIONAL_FEATURES]\n",
    "print(NON_FUNCTIONAL_FEATURES_IDEXES, len(NON_FUNCTIONAL_FEATURES_IDEXES))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb0af2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(KerasClassifier):\n",
    "    \n",
    "    def __init__(self, model, clip_values=None, preprocessing=(0, 1), attacks=[]):\n",
    "        # Wrap model into ART classifier\n",
    "        super(Classifier, self).__init__(model=model, clip_values=clip_values, preprocessing=preprocessing)\n",
    "        self._attacks = attacks\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        # Set attacks features to X\n",
    "        for i in FUNCTIONAL_FEATURES_IDEXES:\n",
    "            for j in range(len(x)):\n",
    "                x[j][i] = self._attacks[j][i]\n",
    "        predictions = self._model.predict(x)\n",
    "        return to_categorical(predictions, num_classes=self._get_nb_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd36ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input_for_model(model, x_data):\n",
    "    from tensorflow import keras  # hoặc `import keras` nếu bạn dùng keras thường\n",
    "    first_layer = type(model.layers[0]).__name__.lower()\n",
    "\n",
    "    if 'dense' in first_layer:\n",
    "        return x_data.reshape((x_data.shape[0], -1))  # MLP\n",
    "    elif 'conv1d' in first_layer:\n",
    "        return x_data.reshape((x_data.shape[0], x_data.shape[1], 1))  # CNN\n",
    "    elif 'lstm' in first_layer:\n",
    "        return x_data.reshape((x_data.shape[0], x_data.shape[1], 1)) \n",
    "    else:\n",
    "        raise ValueError(f\"Không rõ loại mô hình với lớp đầu tiên: {first_layer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18875fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGSM attack\n",
    "def create_fgsm_attack(classifier, epsilon=0.1):\n",
    "    fgsm_attack = FastGradientMethod(estimator=classifier, eps=epsilon)\n",
    "    return fgsm_attack\n",
    "def train_and_test_with_fgsm(model, model_name, classifier, attack_data, normal_data):\n",
    "    fgsm_attack = create_fgsm_attack(classifier)\n",
    "\n",
    "    x_input = prepare_input_for_model(model, attack_data[:100])\n",
    "    x_test_adv = fgsm_attack.generate(x_input)\n",
    "\n",
    "    # Concatenate adversarial examples with normal data\n",
    "    non_adv_x_test = np.concatenate((attack_data[:100], normal_data[:100]))\n",
    "    non_adv_y_test = np.concatenate((np.ones((attack_data[:100].shape[0], 1)), np.zeros((normal_data[:100].shape[0], 1))))\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data[:100]))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data[:100].shape[0], 1))))\n",
    "\n",
    "    print(\"==========> Model: \", model_name)\n",
    "\n",
    "    # Predict for non-adversarial data\n",
    "    non_adv_predictions = model.predict(non_adv_x_test)\n",
    "    non_adv_pred_labels = np.argmax(non_adv_predictions, axis=1)\n",
    "\n",
    "    # Predict for adversarial data\n",
    "    adv_predictions = model.predict(adv_x_test)\n",
    "    adv_pred_labels = np.argmax(adv_predictions, axis=1)\n",
    "\n",
    "    true_non_adv_labels = non_adv_y_test.flatten().astype(int)\n",
    "    true_adv_labels = adv_y_test.flatten().astype(int)\n",
    "\n",
    "    # Evaluate the model on non-adversarial data\n",
    "    print(\"---------- Non adversarial data\")\n",
    "    print(classification_report(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"Accuracy: \", accuracy_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"Detection Rate: \", recall_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"F1 Score: \", f1_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "    print(\"ROC AUC Score: \", roc_auc_score(true_non_adv_labels, non_adv_pred_labels))\n",
    "\n",
    "    # Evaluate the model on adversarial data\n",
    "    print(\"---------- Adversarial data (FGSM)\")\n",
    "    print(classification_report(true_adv_labels, adv_pred_labels))\n",
    "    print(\"Accuracy: \", accuracy_score(true_adv_labels, adv_pred_labels))\n",
    "    print(\"Detection Rate (Recall): \", recall_score(true_adv_labels, adv_pred_labels))\n",
    "    print(\"F1 Score: \", f1_score(true_adv_labels, adv_pred_labels))\n",
    "    print(\"ROC AUC Score: \", roc_auc_score(true_adv_labels, adv_pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28f9229f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating MLP model with FGSM attack...\n",
      "==========> Model:  MLP\n",
      "---------- Non adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       100\n",
      "           1       1.00      0.98      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       0.99      0.99      0.99       200\n",
      "weighted avg       0.99      0.99      0.99       200\n",
      "\n",
      "Accuracy:  0.99\n",
      "Detection Rate:  0.98\n",
      "F1 Score:  0.98989898989899\n",
      "ROC AUC Score:  0.99\n",
      "---------- Adversarial data (FGSM)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      1.00      0.67       100\n",
      "           1       1.00      0.03      0.06       100\n",
      "\n",
      "    accuracy                           0.52       200\n",
      "   macro avg       0.75      0.52      0.37       200\n",
      "weighted avg       0.75      0.52      0.37       200\n",
      "\n",
      "Accuracy:  0.515\n",
      "Detection Rate (Recall):  0.03\n",
      "F1 Score:  0.058252427184466014\n",
      "ROC AUC Score:  0.515\n",
      "\n",
      "Evaluating CNN model with FGSM attack...\n",
      "==========> Model:  CNN\n",
      "---------- Non adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       100\n",
      "           1       1.00      0.99      0.99       100\n",
      "\n",
      "    accuracy                           0.99       200\n",
      "   macro avg       1.00      0.99      0.99       200\n",
      "weighted avg       1.00      0.99      0.99       200\n",
      "\n",
      "Accuracy:  0.995\n",
      "Detection Rate:  0.99\n",
      "F1 Score:  0.9949748743718593\n",
      "ROC AUC Score:  0.995\n",
      "---------- Adversarial data (FGSM)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       100\n",
      "           1       1.00      0.01      0.02       100\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.75      0.51      0.34       200\n",
      "weighted avg       0.75      0.51      0.34       200\n",
      "\n",
      "Accuracy:  0.505\n",
      "Detection Rate (Recall):  0.01\n",
      "F1 Score:  0.019801980198019802\n",
      "ROC AUC Score:  0.505\n",
      "\n",
      "Evaluating RNN model with FGSM attack...\n",
      "==========> Model:  RNN\n",
      "---------- Non adversarial data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76       100\n",
      "           1       1.00      0.36      0.53       100\n",
      "\n",
      "    accuracy                           0.68       200\n",
      "   macro avg       0.80      0.68      0.64       200\n",
      "weighted avg       0.80      0.68      0.64       200\n",
      "\n",
      "Accuracy:  0.68\n",
      "Detection Rate:  0.36\n",
      "F1 Score:  0.5294117647058824\n",
      "ROC AUC Score:  0.6799999999999999\n",
      "---------- Adversarial data (FGSM)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67       100\n",
      "           1       1.00      0.01      0.02       100\n",
      "\n",
      "    accuracy                           0.51       200\n",
      "   macro avg       0.75      0.51      0.34       200\n",
      "weighted avg       0.75      0.51      0.34       200\n",
      "\n",
      "Accuracy:  0.505\n",
      "Detection Rate (Recall):  0.01\n",
      "F1 Score:  0.019801980198019802\n",
      "ROC AUC Score:  0.505\n"
     ]
    }
   ],
   "source": [
    "models = [mlp_model, cnn_model, rnn_model]\n",
    "model_names = ['MLP', 'CNN', 'RNN']\n",
    "\n",
    "for model, model_name in zip(models, model_names):\n",
    "    try:\n",
    "        print(f\"\\nEvaluating {model_name} model with FGSM attack...\")\n",
    "\n",
    "        classifier = KerasClassifier(model=model, clip_values=(0, 1))\n",
    "\n",
    "        if model_name in [\"CNN\", \"RNN\"]:\n",
    "            normal_data_reshaped = normal_data.reshape((normal_data.shape[0], normal_data.shape[1], 1))\n",
    "            attack_data_reshaped = attacks_data.reshape((attacks_data.shape[0], attacks_data.shape[1], 1))\n",
    "        else:\n",
    "            normal_data_reshaped = normal_data\n",
    "            attack_data_reshaped = attacks_data\n",
    "\n",
    "        train_and_test_with_fgsm(model, model_name, classifier, attack_data=attack_data_reshaped, normal_data=normal_data_reshaped)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error while evaluating model {model_name}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
