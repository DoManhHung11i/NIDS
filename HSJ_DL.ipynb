{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99d9a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset\n",
    "from intrusion_detection_systems.models import cnn_model, mlp_model, rnn_model\n",
    "from intrusion_detection_systems import train_dl_model, evaluate_dl_model\n",
    "from agent.DQN import DQNModelSelector\n",
    "from agent.MAB import MultiArmedBanditDLThompsonSampling\n",
    "\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnClassifier\n",
    "from art.utils import to_categorical\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b68f433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Loading new data\n",
      "labels: {'DDoS'}\n",
      "Dataset preprocessed\n",
      "Train full shape: (158021, 68), labels distribution: (array(['0', '1'], dtype=object), array([68402, 89619], dtype=int64))\n",
      "Test full shape: (67724, 68), labels distribution: (array(['0', '1'], dtype=object), array([29316, 38408], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "name = \"CIC-IDS_2017_2\"\n",
    "df = load_data(\n",
    "            [\n",
    "                \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "            ],\n",
    "            42\n",
    "        )\n",
    "print(\"Dataset loaded\")\n",
    "df_preprocessed = preprocess_dataset(\n",
    "    df, save=True, dataset_type=\"CIC_2017\", seed=42, load=False, name_save=name, name_load=name)\n",
    "print(\"Dataset preprocessed\")\n",
    "\n",
    "X_train_full, y_train_full = df_preprocessed.x_train, df_preprocessed.y_train\n",
    "X_test_full, y_test_full = df_preprocessed.x_test, df_preprocessed.y_test\n",
    "print(f\"Train full shape: {X_train_full.shape}, labels distribution: {np.unique(y_train_full, return_counts=True)}\")\n",
    "print(f\"Test full shape: {X_test_full.shape}, labels distribution: {np.unique(y_test_full, return_counts=True)}\")\n",
    "y_train_full = np.array([int(str(x).strip()) for x in y_train_full])\n",
    "y_test_full = np.array([int(str(x).strip()) for x in y_test_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d98fb012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a NB Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_full, y_train_full)\n",
    "# Train a RF Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_full, y_train_full)\n",
    "# Train a DT Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_full, y_train_full)\n",
    "# Train a LR Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0638ff93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MLP Model ---\n",
      "MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "--- CNN Model ---\n",
      "CNNModel(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1792, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "--- RNN Model (LSTM) ---\n",
      "RNNModel(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_full.shape[1]\n",
    "#MLP Model\n",
    "mlp_model_pt = mlp_model(input_dim)\n",
    "criterion_mlp_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_pt = optim.Adam(mlp_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- MLP Model ---\")\n",
    "print(mlp_model_pt)\n",
    "print(f\"Criterion: {criterion_mlp_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_mlp_model_pt}\")\n",
    "# CNN Model\n",
    "cnn_model_pt = cnn_model(input_dim)\n",
    "criterion_cnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_pt = optim.Adam(cnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- CNN Model ---\")\n",
    "print(cnn_model_pt)\n",
    "print(f\"Criterion: {criterion_cnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_cnn_model_pt}\")\n",
    "# RNN Model\n",
    "rnn_model_pt = rnn_model(input_dim) \n",
    "criterion_rnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_pt = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- RNN Model (LSTM) ---\")\n",
    "print(rnn_model_pt)\n",
    "print(f\"Criterion: {criterion_rnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_rnn_model_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6327aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train DL models for attack\n",
    "# Chia t·∫≠p train -> train v√† validation\n",
    "X_small = X_train_full[:1000]\n",
    "y_small = y_train_full[:1000]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_small, y_small, test_size=0.2, random_state=42, stratify=y_small\n",
    ")\n",
    "\n",
    "# Chuy·ªÉn sang tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_full[:1000], dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_full[:1000], dtype=torch.long)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0af86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/50], Train Loss: 0.6778, Train Acc: 0.5775, Val Loss: 0.6689, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6658, Train Acc: 0.5775, Val Loss: 0.6530, Val Acc: 0.5750\n",
      "Epoch [3/50], Train Loss: 0.6511, Train Acc: 0.5775, Val Loss: 0.6317, Val Acc: 0.6550\n",
      "Epoch [4/50], Train Loss: 0.6303, Train Acc: 0.6713, Val Loss: 0.6036, Val Acc: 0.7450\n",
      "Epoch [5/50], Train Loss: 0.6021, Train Acc: 0.7150, Val Loss: 0.5637, Val Acc: 0.7700\n",
      "Epoch [6/50], Train Loss: 0.5646, Train Acc: 0.7312, Val Loss: 0.5150, Val Acc: 0.7700\n",
      "Epoch [7/50], Train Loss: 0.5176, Train Acc: 0.7438, Val Loss: 0.4586, Val Acc: 0.7750\n",
      "Epoch [8/50], Train Loss: 0.4647, Train Acc: 0.7588, Val Loss: 0.4011, Val Acc: 0.8050\n",
      "Epoch [9/50], Train Loss: 0.4093, Train Acc: 0.7812, Val Loss: 0.3440, Val Acc: 0.8350\n",
      "Epoch [10/50], Train Loss: 0.3553, Train Acc: 0.7963, Val Loss: 0.2879, Val Acc: 0.9350\n",
      "Epoch [11/50], Train Loss: 0.3031, Train Acc: 0.9437, Val Loss: 0.2377, Val Acc: 0.9750\n",
      "Epoch [12/50], Train Loss: 0.2523, Train Acc: 0.9487, Val Loss: 0.1902, Val Acc: 0.9750\n",
      "Epoch [13/50], Train Loss: 0.2109, Train Acc: 0.9537, Val Loss: 0.1553, Val Acc: 0.9750\n",
      "Epoch [14/50], Train Loss: 0.1779, Train Acc: 0.9587, Val Loss: 0.1235, Val Acc: 0.9750\n",
      "Epoch [15/50], Train Loss: 0.1539, Train Acc: 0.9613, Val Loss: 0.1035, Val Acc: 0.9750\n",
      "Epoch [16/50], Train Loss: 0.1369, Train Acc: 0.9625, Val Loss: 0.0905, Val Acc: 0.9800\n",
      "Epoch [17/50], Train Loss: 0.1246, Train Acc: 0.9613, Val Loss: 0.0781, Val Acc: 0.9850\n",
      "Epoch [18/50], Train Loss: 0.1140, Train Acc: 0.9625, Val Loss: 0.0708, Val Acc: 0.9900\n",
      "Epoch [19/50], Train Loss: 0.1069, Train Acc: 0.9663, Val Loss: 0.0654, Val Acc: 0.9900\n",
      "Epoch [20/50], Train Loss: 0.1008, Train Acc: 0.9663, Val Loss: 0.0616, Val Acc: 0.9900\n",
      "Epoch [21/50], Train Loss: 0.0984, Train Acc: 0.9675, Val Loss: 0.0608, Val Acc: 0.9900\n",
      "Epoch [22/50], Train Loss: 0.0944, Train Acc: 0.9688, Val Loss: 0.0572, Val Acc: 0.9900\n",
      "Epoch [23/50], Train Loss: 0.0904, Train Acc: 0.9675, Val Loss: 0.0546, Val Acc: 0.9900\n",
      "Epoch [24/50], Train Loss: 0.0880, Train Acc: 0.9700, Val Loss: 0.0528, Val Acc: 0.9900\n",
      "Epoch [25/50], Train Loss: 0.0851, Train Acc: 0.9700, Val Loss: 0.0512, Val Acc: 0.9900\n",
      "Epoch [26/50], Train Loss: 0.0822, Train Acc: 0.9700, Val Loss: 0.0506, Val Acc: 0.9900\n",
      "Epoch [27/50], Train Loss: 0.0798, Train Acc: 0.9712, Val Loss: 0.0487, Val Acc: 0.9900\n",
      "Epoch [28/50], Train Loss: 0.0789, Train Acc: 0.9712, Val Loss: 0.0498, Val Acc: 0.9900\n",
      "Epoch [29/50], Train Loss: 0.0762, Train Acc: 0.9712, Val Loss: 0.0493, Val Acc: 0.9900\n",
      "Epoch [30/50], Train Loss: 0.0752, Train Acc: 0.9712, Val Loss: 0.0481, Val Acc: 0.9900\n",
      "Epoch [31/50], Train Loss: 0.0734, Train Acc: 0.9712, Val Loss: 0.0478, Val Acc: 0.9900\n",
      "Epoch [32/50], Train Loss: 0.0720, Train Acc: 0.9725, Val Loss: 0.0482, Val Acc: 0.9900\n",
      "Epoch [33/50], Train Loss: 0.0711, Train Acc: 0.9725, Val Loss: 0.0469, Val Acc: 0.9900\n",
      "Epoch [34/50], Train Loss: 0.0719, Train Acc: 0.9725, Val Loss: 0.0475, Val Acc: 0.9900\n",
      "Epoch [35/50], Train Loss: 0.0687, Train Acc: 0.9725, Val Loss: 0.0512, Val Acc: 0.9900\n",
      "Epoch [36/50], Train Loss: 0.0699, Train Acc: 0.9725, Val Loss: 0.0479, Val Acc: 0.9900\n",
      "Epoch [37/50], Train Loss: 0.0666, Train Acc: 0.9725, Val Loss: 0.0462, Val Acc: 0.9900\n",
      "Epoch [38/50], Train Loss: 0.0656, Train Acc: 0.9725, Val Loss: 0.0462, Val Acc: 0.9900\n",
      "Epoch [39/50], Train Loss: 0.0673, Train Acc: 0.9725, Val Loss: 0.0448, Val Acc: 0.9900\n",
      "Epoch [40/50], Train Loss: 0.0631, Train Acc: 0.9738, Val Loss: 0.0437, Val Acc: 0.9900\n",
      "Epoch [41/50], Train Loss: 0.0667, Train Acc: 0.9738, Val Loss: 0.0420, Val Acc: 0.9900\n",
      "Epoch [42/50], Train Loss: 0.0632, Train Acc: 0.9725, Val Loss: 0.0412, Val Acc: 0.9900\n",
      "Epoch [43/50], Train Loss: 0.0628, Train Acc: 0.9738, Val Loss: 0.0415, Val Acc: 0.9900\n",
      "Epoch [44/50], Train Loss: 0.0634, Train Acc: 0.9750, Val Loss: 0.0418, Val Acc: 0.9900\n",
      "Epoch [45/50], Train Loss: 0.0639, Train Acc: 0.9750, Val Loss: 0.0411, Val Acc: 0.9900\n",
      "Epoch [46/50], Train Loss: 0.0636, Train Acc: 0.9738, Val Loss: 0.0421, Val Acc: 0.9900\n",
      "Epoch [47/50], Train Loss: 0.0612, Train Acc: 0.9738, Val Loss: 0.0431, Val Acc: 0.9900\n",
      "Epoch [48/50], Train Loss: 0.0614, Train Acc: 0.9738, Val Loss: 0.0411, Val Acc: 0.9900\n",
      "Epoch [49/50], Train Loss: 0.0631, Train Acc: 0.9738, Val Loss: 0.0399, Val Acc: 0.9900\n",
      "Epoch [50/50], Train Loss: 0.0632, Train Acc: 0.9750, Val Loss: 0.0435, Val Acc: 0.9900\n",
      "Finished Training MLPModel\n",
      "\n",
      "---------- Test data (MLPModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       428\n",
      "           1       0.94      1.00      0.97       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.97      0.96      0.96      1000\n",
      "weighted avg       0.97      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.965\n",
      "Detection Rate (Recall):  0.9982517482517482\n",
      "F1 Score:  0.9702633814783348\n",
      "ROC AUC Score:  0.9594062479576498\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6774, Train Acc: 0.5575, Val Loss: 0.6596, Val Acc: 0.7200\n",
      "Epoch [2/50], Train Loss: 0.6519, Train Acc: 0.6800, Val Loss: 0.6275, Val Acc: 0.7200\n",
      "Epoch [3/50], Train Loss: 0.6187, Train Acc: 0.7037, Val Loss: 0.5856, Val Acc: 0.7450\n",
      "Epoch [4/50], Train Loss: 0.5822, Train Acc: 0.7200, Val Loss: 0.5455, Val Acc: 0.7450\n",
      "Epoch [5/50], Train Loss: 0.5494, Train Acc: 0.7200, Val Loss: 0.5353, Val Acc: 0.8100\n",
      "Epoch [6/50], Train Loss: 0.5333, Train Acc: 0.7412, Val Loss: 0.5031, Val Acc: 0.7300\n",
      "Epoch [7/50], Train Loss: 0.5104, Train Acc: 0.7275, Val Loss: 0.4845, Val Acc: 0.7400\n",
      "Epoch [8/50], Train Loss: 0.4856, Train Acc: 0.7250, Val Loss: 0.4705, Val Acc: 0.8250\n",
      "Epoch [9/50], Train Loss: 0.4737, Train Acc: 0.7788, Val Loss: 0.4447, Val Acc: 0.8250\n",
      "Epoch [10/50], Train Loss: 0.4429, Train Acc: 0.8588, Val Loss: 0.4284, Val Acc: 0.7400\n",
      "Epoch [11/50], Train Loss: 0.4203, Train Acc: 0.7738, Val Loss: 0.4034, Val Acc: 0.8450\n",
      "Epoch [12/50], Train Loss: 0.3977, Train Acc: 0.8912, Val Loss: 0.3697, Val Acc: 0.8650\n",
      "Epoch [13/50], Train Loss: 0.3644, Train Acc: 0.9087, Val Loss: 0.3416, Val Acc: 0.8850\n",
      "Epoch [14/50], Train Loss: 0.3395, Train Acc: 0.9087, Val Loss: 0.3149, Val Acc: 0.8850\n",
      "Epoch [15/50], Train Loss: 0.3100, Train Acc: 0.9225, Val Loss: 0.2878, Val Acc: 0.9050\n",
      "Epoch [16/50], Train Loss: 0.2863, Train Acc: 0.9150, Val Loss: 0.2598, Val Acc: 0.9200\n",
      "Epoch [17/50], Train Loss: 0.2624, Train Acc: 0.9375, Val Loss: 0.2451, Val Acc: 0.9200\n",
      "Epoch [18/50], Train Loss: 0.2509, Train Acc: 0.9300, Val Loss: 0.2185, Val Acc: 0.9350\n",
      "Epoch [19/50], Train Loss: 0.2316, Train Acc: 0.9387, Val Loss: 0.1953, Val Acc: 0.9300\n",
      "Epoch [20/50], Train Loss: 0.2202, Train Acc: 0.9463, Val Loss: 0.1789, Val Acc: 0.9350\n",
      "Epoch [21/50], Train Loss: 0.1982, Train Acc: 0.9425, Val Loss: 0.1622, Val Acc: 0.9350\n",
      "Epoch [22/50], Train Loss: 0.1918, Train Acc: 0.9425, Val Loss: 0.1539, Val Acc: 0.9650\n",
      "Epoch [23/50], Train Loss: 0.1794, Train Acc: 0.9537, Val Loss: 0.1397, Val Acc: 0.9450\n",
      "Epoch [24/50], Train Loss: 0.1649, Train Acc: 0.9513, Val Loss: 0.1311, Val Acc: 0.9600\n",
      "Epoch [25/50], Train Loss: 0.1562, Train Acc: 0.9513, Val Loss: 0.1230, Val Acc: 0.9600\n",
      "Epoch [26/50], Train Loss: 0.1498, Train Acc: 0.9525, Val Loss: 0.1193, Val Acc: 0.9700\n",
      "Epoch [27/50], Train Loss: 0.1452, Train Acc: 0.9575, Val Loss: 0.1135, Val Acc: 0.9650\n",
      "Epoch [28/50], Train Loss: 0.1397, Train Acc: 0.9563, Val Loss: 0.1103, Val Acc: 0.9650\n",
      "Epoch [29/50], Train Loss: 0.1331, Train Acc: 0.9575, Val Loss: 0.1067, Val Acc: 0.9600\n",
      "Epoch [30/50], Train Loss: 0.1303, Train Acc: 0.9587, Val Loss: 0.1050, Val Acc: 0.9700\n",
      "Epoch [31/50], Train Loss: 0.1264, Train Acc: 0.9600, Val Loss: 0.1037, Val Acc: 0.9600\n",
      "Epoch [32/50], Train Loss: 0.1270, Train Acc: 0.9563, Val Loss: 0.1081, Val Acc: 0.9800\n",
      "Epoch [33/50], Train Loss: 0.1274, Train Acc: 0.9625, Val Loss: 0.1039, Val Acc: 0.9550\n",
      "Epoch [34/50], Train Loss: 0.1224, Train Acc: 0.9563, Val Loss: 0.1101, Val Acc: 0.9800\n",
      "Epoch [35/50], Train Loss: 0.1270, Train Acc: 0.9563, Val Loss: 0.1023, Val Acc: 0.9550\n",
      "Epoch [36/50], Train Loss: 0.1233, Train Acc: 0.9587, Val Loss: 0.0985, Val Acc: 0.9750\n",
      "Epoch [37/50], Train Loss: 0.1153, Train Acc: 0.9637, Val Loss: 0.0938, Val Acc: 0.9650\n",
      "Epoch [38/50], Train Loss: 0.1111, Train Acc: 0.9613, Val Loss: 0.0926, Val Acc: 0.9700\n",
      "Epoch [39/50], Train Loss: 0.1101, Train Acc: 0.9625, Val Loss: 0.0990, Val Acc: 0.9600\n",
      "Epoch [40/50], Train Loss: 0.1113, Train Acc: 0.9625, Val Loss: 0.0971, Val Acc: 0.9650\n",
      "Epoch [41/50], Train Loss: 0.1107, Train Acc: 0.9587, Val Loss: 0.0937, Val Acc: 0.9700\n",
      "Epoch [42/50], Train Loss: 0.1100, Train Acc: 0.9663, Val Loss: 0.0885, Val Acc: 0.9650\n",
      "Epoch [43/50], Train Loss: 0.1127, Train Acc: 0.9600, Val Loss: 0.0869, Val Acc: 0.9650\n",
      "Epoch [44/50], Train Loss: 0.1033, Train Acc: 0.9650, Val Loss: 0.0920, Val Acc: 0.9750\n",
      "Epoch [45/50], Train Loss: 0.1019, Train Acc: 0.9650, Val Loss: 0.0887, Val Acc: 0.9600\n",
      "Epoch [46/50], Train Loss: 0.1008, Train Acc: 0.9613, Val Loss: 0.0876, Val Acc: 0.9700\n",
      "Epoch [47/50], Train Loss: 0.0995, Train Acc: 0.9650, Val Loss: 0.0837, Val Acc: 0.9700\n",
      "Epoch [48/50], Train Loss: 0.0988, Train Acc: 0.9637, Val Loss: 0.0832, Val Acc: 0.9700\n",
      "Epoch [49/50], Train Loss: 0.0993, Train Acc: 0.9675, Val Loss: 0.0829, Val Acc: 0.9750\n",
      "Epoch [50/50], Train Loss: 0.0965, Train Acc: 0.9613, Val Loss: 0.0890, Val Acc: 0.9700\n",
      "Finished Training CNNModel\n",
      "\n",
      "---------- Test data (CNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94       428\n",
      "           1       0.93      0.99      0.96       572\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.96      0.95      0.95      1000\n",
      "weighted avg       0.96      0.95      0.95      1000\n",
      "\n",
      "Accuracy:  0.955\n",
      "Detection Rate (Recall):  0.9947552447552448\n",
      "F1 Score:  0.9619611158072696\n",
      "ROC AUC Score:  0.9483122018168748\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [3/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [4/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [5/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [6/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [7/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [8/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [9/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [10/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [11/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [12/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [13/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [14/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [15/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [16/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [17/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [18/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [19/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [20/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [21/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [22/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [23/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [24/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [25/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [26/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [27/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [28/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [29/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [30/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [31/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [32/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [33/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [34/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [35/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [36/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [37/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [38/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [39/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [40/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [41/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [42/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [43/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [44/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [45/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [46/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [47/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [48/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [49/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Epoch [50/50], Train Loss: 0.6848, Train Acc: 0.5775, Val Loss: 0.6851, Val Acc: 0.5750\n",
      "Finished Training RNNModel\n",
      "\n",
      "---------- Test data (RNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       428\n",
      "           1       0.57      1.00      0.73       572\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Accuracy:  0.572\n",
      "Detection Rate (Recall):  1.0\n",
      "F1 Score:  0.727735368956743\n",
      "ROC AUC Score:  0.5\n"
     ]
    }
   ],
   "source": [
    "#MLP Target Model \n",
    "mlp_model_target = mlp_model(input_dim)\n",
    "criterion_mlp_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_target = optim.Adam(mlp_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# CNN Target Model\n",
    "cnn_model_target = cnn_model(input_dim)\n",
    "criterion_cnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_target = optim.Adam(cnn_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# RNN Target Model\n",
    "rnn_model_target = rnn_model(input_dim) \n",
    "criterion_rnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_target = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "# ----- MLP -----\n",
    "mlp_target = train_dl_model(mlp_model_target, train_loader, val_loader, criterion_mlp_model_target, optimizer_mlp_model_target, device, num_epochs=50)\n",
    "evaluate_dl_model(mlp_target, test_loader, device,model_type='mlp', name=\"Test\")\n",
    "\n",
    "# ----- CNN -----\n",
    "cnn_target = train_dl_model(cnn_model_target, train_loader, val_loader, criterion_cnn_model_target, optimizer_cnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(cnn_target, test_loader, device,model_type='cnn', name=\"Test\")\n",
    "\n",
    "# ----- RNN -----\n",
    "rnn_target = train_dl_model(rnn_model_target, train_loader, val_loader, criterion_rnn_model_target, optimizer_rnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(rnn_target, test_loader, device,model_type='rnn', name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c9ee917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train): (array([0, 1]), array([423, 577], dtype=int64))\n",
      "üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test): (array([0, 1]), array([ 855, 1145], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "SUB_TRAIN = min(1000, len(X_train_full))\n",
    "SUB_TEST = min(2000, len(X_test_full))\n",
    "# S·ª≠ d·ª•ng m·∫´u nh·ªè ho·∫∑c to√†n b·ªô d·ªØ li·ªáu\n",
    "X_train, y_train = X_train_full[:SUB_TRAIN], y_train_full[:SUB_TRAIN]\n",
    "X_test, y_test = X_test_full[:SUB_TEST], y_test_full[:SUB_TEST]\n",
    "# N·∫øu mu·ªën d√πng to√†n b·ªô d·ªØ li·ªáu, b·ªè d√≤ng tr√™n v√† d√πng:\n",
    "# X_train, y_train = X_train_full, y_train_full\n",
    "# X_test, y_test = X_test_full, y_test_full\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train):\", np.unique(y_train, return_counts=True))\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test):\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e6b2c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN-based selector with cluster-specific DQNs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training for cluster 0 ===\n",
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/100], Train Loss: 0.7305, Train Acc: 0.3632, Val Loss: 0.5106, Val Acc: 0.9821\n",
      "Epoch [2/100], Train Loss: 0.4305, Train Acc: 0.9910, Val Loss: 0.2923, Val Acc: 0.9821\n",
      "Epoch [3/100], Train Loss: 0.2314, Train Acc: 0.9865, Val Loss: 0.1564, Val Acc: 0.9821\n",
      "Epoch [4/100], Train Loss: 0.1168, Train Acc: 0.9910, Val Loss: 0.0973, Val Acc: 0.9821\n",
      "Epoch [5/100], Train Loss: 0.0602, Train Acc: 0.9910, Val Loss: 0.0813, Val Acc: 0.9821\n",
      "Epoch [6/100], Train Loss: 0.0336, Train Acc: 0.9910, Val Loss: 0.0806, Val Acc: 0.9821\n",
      "Epoch [7/100], Train Loss: 0.0190, Train Acc: 0.9910, Val Loss: 0.0805, Val Acc: 0.9821\n",
      "Epoch [8/100], Train Loss: 0.0100, Train Acc: 0.9955, Val Loss: 0.0791, Val Acc: 0.9821\n",
      "Epoch [9/100], Train Loss: 0.0035, Train Acc: 1.0000, Val Loss: 0.0781, Val Acc: 0.9821\n",
      "Epoch [10/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0779, Val Acc: 0.9821\n",
      "Epoch [11/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0783, Val Acc: 0.9821\n",
      "Epoch [12/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0792, Val Acc: 0.9821\n",
      "Epoch [13/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0806, Val Acc: 0.9821\n",
      "Epoch [14/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0822, Val Acc: 0.9821\n",
      "Epoch [15/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0840, Val Acc: 0.9821\n",
      "Epoch [16/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0859, Val Acc: 0.9821\n",
      "Epoch [17/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0877, Val Acc: 0.9821\n",
      "Epoch [18/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0895, Val Acc: 0.9821\n",
      "Epoch [19/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0912, Val Acc: 0.9821\n",
      "Epoch [20/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0929, Val Acc: 0.9821\n",
      "Epoch [21/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0946, Val Acc: 0.9821\n",
      "Epoch [22/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0963, Val Acc: 0.9821\n",
      "Epoch [23/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0979, Val Acc: 0.9821\n",
      "Epoch [24/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0994, Val Acc: 0.9821\n",
      "Epoch [25/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1009, Val Acc: 0.9821\n",
      "Epoch [26/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1023, Val Acc: 0.9821\n",
      "Epoch [27/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1037, Val Acc: 0.9821\n",
      "Epoch [28/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1050, Val Acc: 0.9821\n",
      "Epoch [29/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1063, Val Acc: 0.9821\n",
      "Epoch [30/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1075, Val Acc: 0.9821\n",
      "Epoch [31/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1088, Val Acc: 0.9821\n",
      "Epoch [32/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1100, Val Acc: 0.9821\n",
      "Epoch [33/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1113, Val Acc: 0.9821\n",
      "Epoch [34/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1125, Val Acc: 0.9821\n",
      "Epoch [35/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1136, Val Acc: 0.9821\n",
      "Epoch [36/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1147, Val Acc: 0.9821\n",
      "Epoch [37/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1158, Val Acc: 0.9821\n",
      "Epoch [38/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1169, Val Acc: 0.9821\n",
      "Epoch [39/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1178, Val Acc: 0.9821\n",
      "Epoch [40/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1188, Val Acc: 0.9821\n",
      "Epoch [41/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1197, Val Acc: 0.9821\n",
      "Epoch [42/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1206, Val Acc: 0.9821\n",
      "Epoch [43/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1214, Val Acc: 0.9821\n",
      "Epoch [44/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1223, Val Acc: 0.9821\n",
      "Epoch [45/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1231, Val Acc: 0.9821\n",
      "Epoch [46/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1240, Val Acc: 0.9821\n",
      "Epoch [47/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1248, Val Acc: 0.9821\n",
      "Epoch [48/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.1255, Val Acc: 0.9821\n",
      "Epoch [49/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1262, Val Acc: 0.9821\n",
      "Epoch [50/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1269, Val Acc: 0.9821\n",
      "Epoch [51/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1275, Val Acc: 0.9821\n",
      "Epoch [52/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1281, Val Acc: 0.9821\n",
      "Epoch [53/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1287, Val Acc: 0.9821\n",
      "Epoch [54/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1293, Val Acc: 0.9821\n",
      "Epoch [55/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1300, Val Acc: 0.9821\n",
      "Epoch [56/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1306, Val Acc: 0.9821\n",
      "Epoch [57/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1312, Val Acc: 0.9821\n",
      "Epoch [58/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1318, Val Acc: 0.9821\n",
      "Epoch [59/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1324, Val Acc: 0.9821\n",
      "Epoch [60/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1329, Val Acc: 0.9821\n",
      "Epoch [61/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1335, Val Acc: 0.9821\n",
      "Epoch [62/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1340, Val Acc: 0.9821\n",
      "Epoch [63/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1345, Val Acc: 0.9821\n",
      "Epoch [64/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1351, Val Acc: 0.9821\n",
      "Epoch [65/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1356, Val Acc: 0.9821\n",
      "Epoch [66/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1362, Val Acc: 0.9821\n",
      "Epoch [67/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1367, Val Acc: 0.9821\n",
      "Epoch [68/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1372, Val Acc: 0.9821\n",
      "Epoch [69/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1377, Val Acc: 0.9821\n",
      "Epoch [70/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1381, Val Acc: 0.9821\n",
      "Epoch [71/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1385, Val Acc: 0.9821\n",
      "Epoch [72/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1390, Val Acc: 0.9821\n",
      "Epoch [73/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1395, Val Acc: 0.9821\n",
      "Epoch [74/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1399, Val Acc: 0.9821\n",
      "Epoch [75/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1403, Val Acc: 0.9821\n",
      "Epoch [76/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1408, Val Acc: 0.9821\n",
      "Epoch [77/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1412, Val Acc: 0.9821\n",
      "Epoch [78/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1416, Val Acc: 0.9821\n",
      "Epoch [79/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1420, Val Acc: 0.9821\n",
      "Epoch [80/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1424, Val Acc: 0.9821\n",
      "Epoch [81/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1428, Val Acc: 0.9821\n",
      "Epoch [82/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1433, Val Acc: 0.9821\n",
      "Epoch [83/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1438, Val Acc: 0.9821\n",
      "Epoch [84/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1441, Val Acc: 0.9821\n",
      "Epoch [85/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1445, Val Acc: 0.9821\n",
      "Epoch [86/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1449, Val Acc: 0.9821\n",
      "Epoch [87/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1452, Val Acc: 0.9821\n",
      "Epoch [88/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1456, Val Acc: 0.9821\n",
      "Epoch [89/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1459, Val Acc: 0.9821\n",
      "Epoch [90/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1463, Val Acc: 0.9821\n",
      "Epoch [91/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1466, Val Acc: 0.9821\n",
      "Epoch [92/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1469, Val Acc: 0.9821\n",
      "Epoch [93/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1472, Val Acc: 0.9821\n",
      "Epoch [94/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1475, Val Acc: 0.9821\n",
      "Epoch [95/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1478, Val Acc: 0.9821\n",
      "Epoch [96/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1481, Val Acc: 0.9821\n",
      "Epoch [97/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1484, Val Acc: 0.9821\n",
      "Epoch [98/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1487, Val Acc: 0.9821\n",
      "Epoch [99/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1490, Val Acc: 0.9821\n",
      "Epoch [100/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.1494, Val Acc: 0.9821\n",
      "Finished Training MLPModel\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.4149, Train Acc: 0.8879, Val Loss: 0.1536, Val Acc: 0.9643\n",
      "Epoch [2/100], Train Loss: 0.1519, Train Acc: 0.9686, Val Loss: 0.0634, Val Acc: 0.9821\n",
      "Epoch [3/100], Train Loss: 0.0417, Train Acc: 0.9910, Val Loss: 0.0395, Val Acc: 0.9821\n",
      "Epoch [4/100], Train Loss: 0.0202, Train Acc: 1.0000, Val Loss: 0.0267, Val Acc: 1.0000\n",
      "Epoch [5/100], Train Loss: 0.0117, Train Acc: 1.0000, Val Loss: 0.0184, Val Acc: 1.0000\n",
      "Epoch [6/100], Train Loss: 0.0046, Train Acc: 1.0000, Val Loss: 0.0184, Val Acc: 0.9821\n",
      "Epoch [7/100], Train Loss: 0.0017, Train Acc: 1.0000, Val Loss: 0.0230, Val Acc: 0.9821\n",
      "Epoch [8/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0285, Val Acc: 0.9821\n",
      "Epoch [9/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0330, Val Acc: 0.9821\n",
      "Epoch [10/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0355, Val Acc: 0.9821\n",
      "Epoch [11/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0369, Val Acc: 0.9821\n",
      "Epoch [12/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0372, Val Acc: 0.9821\n",
      "Epoch [13/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0375, Val Acc: 0.9821\n",
      "Epoch [14/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0376, Val Acc: 0.9821\n",
      "Epoch [15/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0379, Val Acc: 0.9821\n",
      "Epoch [16/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0381, Val Acc: 0.9821\n",
      "Epoch [17/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0384, Val Acc: 0.9821\n",
      "Epoch [18/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0387, Val Acc: 0.9821\n",
      "Epoch [19/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0390, Val Acc: 0.9821\n",
      "Epoch [20/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0394, Val Acc: 0.9821\n",
      "Epoch [21/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0398, Val Acc: 0.9821\n",
      "Epoch [22/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0402, Val Acc: 0.9821\n",
      "Epoch [23/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0404, Val Acc: 0.9821\n",
      "Epoch [24/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0408, Val Acc: 0.9821\n",
      "Epoch [25/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0410, Val Acc: 0.9821\n",
      "Epoch [26/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0412, Val Acc: 0.9821\n",
      "Epoch [27/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0415, Val Acc: 0.9821\n",
      "Epoch [28/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0418, Val Acc: 0.9821\n",
      "Epoch [29/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0421, Val Acc: 0.9821\n",
      "Epoch [30/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0423, Val Acc: 0.9821\n",
      "Epoch [31/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0426, Val Acc: 0.9821\n",
      "Epoch [32/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0428, Val Acc: 0.9821\n",
      "Epoch [33/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0430, Val Acc: 0.9821\n",
      "Epoch [34/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0433, Val Acc: 0.9821\n",
      "Epoch [35/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0434, Val Acc: 0.9821\n",
      "Epoch [36/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0435, Val Acc: 0.9821\n",
      "Epoch [37/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0437, Val Acc: 0.9821\n",
      "Epoch [38/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0441, Val Acc: 0.9821\n",
      "Epoch [39/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0444, Val Acc: 0.9821\n",
      "Epoch [40/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0445, Val Acc: 0.9821\n",
      "Epoch [41/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0448, Val Acc: 0.9821\n",
      "Epoch [42/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0450, Val Acc: 0.9821\n",
      "Epoch [43/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0451, Val Acc: 0.9821\n",
      "Epoch [44/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0453, Val Acc: 0.9821\n",
      "Epoch [45/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0456, Val Acc: 0.9821\n",
      "Epoch [46/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0458, Val Acc: 0.9821\n",
      "Epoch [47/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0460, Val Acc: 0.9821\n",
      "Epoch [48/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0463, Val Acc: 0.9821\n",
      "Epoch [49/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0464, Val Acc: 0.9821\n",
      "Epoch [50/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0465, Val Acc: 0.9821\n",
      "Epoch [51/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0466, Val Acc: 0.9821\n",
      "Epoch [52/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0468, Val Acc: 0.9821\n",
      "Epoch [53/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0468, Val Acc: 0.9821\n",
      "Epoch [54/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0469, Val Acc: 0.9821\n",
      "Epoch [55/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0469, Val Acc: 0.9821\n",
      "Epoch [56/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0471, Val Acc: 0.9821\n",
      "Epoch [57/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0473, Val Acc: 0.9821\n",
      "Epoch [58/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0475, Val Acc: 0.9821\n",
      "Epoch [59/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0476, Val Acc: 0.9821\n",
      "Epoch [60/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0477, Val Acc: 0.9821\n",
      "Epoch [61/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0477, Val Acc: 0.9821\n",
      "Epoch [62/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0478, Val Acc: 0.9821\n",
      "Epoch [63/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0480, Val Acc: 0.9821\n",
      "Epoch [64/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0481, Val Acc: 0.9821\n",
      "Epoch [65/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [66/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [67/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0480, Val Acc: 0.9821\n",
      "Epoch [68/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0478, Val Acc: 0.9821\n",
      "Epoch [69/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0478, Val Acc: 0.9821\n",
      "Epoch [70/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0476, Val Acc: 0.9821\n",
      "Epoch [71/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0474, Val Acc: 0.9821\n",
      "Epoch [72/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0471, Val Acc: 0.9821\n",
      "Epoch [73/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0470, Val Acc: 0.9821\n",
      "Epoch [74/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0469, Val Acc: 0.9821\n",
      "Epoch [75/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0467, Val Acc: 0.9821\n",
      "Epoch [76/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0468, Val Acc: 0.9821\n",
      "Epoch [77/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0470, Val Acc: 0.9821\n",
      "Epoch [78/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0471, Val Acc: 0.9821\n",
      "Epoch [79/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0474, Val Acc: 0.9821\n",
      "Epoch [80/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0477, Val Acc: 0.9821\n",
      "Epoch [81/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0479, Val Acc: 0.9821\n",
      "Epoch [82/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [83/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0483, Val Acc: 0.9821\n",
      "Epoch [84/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0483, Val Acc: 0.9821\n",
      "Epoch [85/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [86/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [87/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0481, Val Acc: 0.9821\n",
      "Epoch [88/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [89/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0483, Val Acc: 0.9821\n",
      "Epoch [90/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [91/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0482, Val Acc: 0.9821\n",
      "Epoch [92/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0483, Val Acc: 0.9821\n",
      "Epoch [93/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0483, Val Acc: 0.9821\n",
      "Epoch [94/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0485, Val Acc: 0.9821\n",
      "Epoch [95/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0486, Val Acc: 0.9821\n",
      "Epoch [96/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0488, Val Acc: 0.9821\n",
      "Epoch [97/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0488, Val Acc: 0.9821\n",
      "Epoch [98/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0488, Val Acc: 0.9821\n",
      "Epoch [99/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0487, Val Acc: 0.9821\n",
      "Epoch [100/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0487, Val Acc: 0.9821\n",
      "Finished Training CNNModel\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.7159, Train Acc: 0.0314, Val Loss: 0.6931, Val Acc: 0.9821\n",
      "Epoch [2/100], Train Loss: 0.6841, Train Acc: 0.9641, Val Loss: 0.6639, Val Acc: 0.9643\n",
      "Epoch [3/100], Train Loss: 0.6545, Train Acc: 0.9686, Val Loss: 0.6361, Val Acc: 0.9643\n",
      "Epoch [4/100], Train Loss: 0.6257, Train Acc: 0.9686, Val Loss: 0.6001, Val Acc: 0.9643\n",
      "Epoch [5/100], Train Loss: 0.5806, Train Acc: 0.9686, Val Loss: 0.5298, Val Acc: 0.9643\n",
      "Epoch [6/100], Train Loss: 0.4818, Train Acc: 0.9686, Val Loss: 0.3618, Val Acc: 0.9643\n",
      "Epoch [7/100], Train Loss: 0.3023, Train Acc: 0.9686, Val Loss: 0.2242, Val Acc: 0.9643\n",
      "Epoch [8/100], Train Loss: 0.1932, Train Acc: 0.9686, Val Loss: 0.1682, Val Acc: 0.9643\n",
      "Epoch [9/100], Train Loss: 0.1492, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [10/100], Train Loss: 0.1419, Train Acc: 0.9686, Val Loss: 0.1569, Val Acc: 0.9643\n",
      "Epoch [11/100], Train Loss: 0.1418, Train Acc: 0.9686, Val Loss: 0.1611, Val Acc: 0.9643\n",
      "Epoch [12/100], Train Loss: 0.1446, Train Acc: 0.9686, Val Loss: 0.1632, Val Acc: 0.9643\n",
      "Epoch [13/100], Train Loss: 0.1458, Train Acc: 0.9686, Val Loss: 0.1633, Val Acc: 0.9643\n",
      "Epoch [14/100], Train Loss: 0.1455, Train Acc: 0.9686, Val Loss: 0.1606, Val Acc: 0.9643\n",
      "Epoch [15/100], Train Loss: 0.1426, Train Acc: 0.9686, Val Loss: 0.1587, Val Acc: 0.9643\n",
      "Epoch [16/100], Train Loss: 0.1407, Train Acc: 0.9686, Val Loss: 0.1562, Val Acc: 0.9643\n",
      "Epoch [17/100], Train Loss: 0.1410, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [18/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [19/100], Train Loss: 0.1403, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [20/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [21/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [22/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1542, Val Acc: 0.9643\n",
      "Epoch [23/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [24/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [25/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [26/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [27/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1547, Val Acc: 0.9643\n",
      "Epoch [28/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1549, Val Acc: 0.9643\n",
      "Epoch [29/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1552, Val Acc: 0.9643\n",
      "Epoch [30/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1551, Val Acc: 0.9643\n",
      "Epoch [31/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1548, Val Acc: 0.9643\n",
      "Epoch [32/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [33/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [34/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [35/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [36/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [37/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [38/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [39/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [40/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [41/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [42/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [43/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [44/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [45/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [46/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [47/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [48/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1542, Val Acc: 0.9643\n",
      "Epoch [49/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [50/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1540, Val Acc: 0.9643\n",
      "Epoch [51/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1540, Val Acc: 0.9643\n",
      "Epoch [52/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1540, Val Acc: 0.9643\n",
      "Epoch [53/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1540, Val Acc: 0.9643\n",
      "Epoch [54/100], Train Loss: 0.1400, Train Acc: 0.9686, Val Loss: 0.1542, Val Acc: 0.9643\n",
      "Epoch [55/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1540, Val Acc: 0.9643\n",
      "Epoch [56/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1538, Val Acc: 0.9643\n",
      "Epoch [57/100], Train Loss: 0.1393, Train Acc: 0.9686, Val Loss: 0.1538, Val Acc: 0.9643\n",
      "Epoch [58/100], Train Loss: 0.1392, Train Acc: 0.9686, Val Loss: 0.1536, Val Acc: 0.9643\n",
      "Epoch [59/100], Train Loss: 0.1389, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [60/100], Train Loss: 0.1383, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [61/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [62/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [63/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [64/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [65/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1549, Val Acc: 0.9643\n",
      "Epoch [66/100], Train Loss: 0.1400, Train Acc: 0.9686, Val Loss: 0.1552, Val Acc: 0.9643\n",
      "Epoch [67/100], Train Loss: 0.1400, Train Acc: 0.9686, Val Loss: 0.1548, Val Acc: 0.9643\n",
      "Epoch [68/100], Train Loss: 0.1400, Train Acc: 0.9686, Val Loss: 0.1547, Val Acc: 0.9643\n",
      "Epoch [69/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1549, Val Acc: 0.9643\n",
      "Epoch [70/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [71/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [72/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1542, Val Acc: 0.9643\n",
      "Epoch [73/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [74/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [75/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1550, Val Acc: 0.9643\n",
      "Epoch [76/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [77/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [78/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [79/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1542, Val Acc: 0.9643\n",
      "Epoch [80/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [81/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [82/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [83/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [84/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [85/100], Train Loss: 0.1404, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [86/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Epoch [87/100], Train Loss: 0.1405, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [88/100], Train Loss: 0.1398, Train Acc: 0.9686, Val Loss: 0.1541, Val Acc: 0.9643\n",
      "Epoch [89/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1542, Val Acc: 0.9643\n",
      "Epoch [90/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [91/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1547, Val Acc: 0.9643\n",
      "Epoch [92/100], Train Loss: 0.1401, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [93/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1544, Val Acc: 0.9643\n",
      "Epoch [94/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [95/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1545, Val Acc: 0.9643\n",
      "Epoch [96/100], Train Loss: 0.1396, Train Acc: 0.9686, Val Loss: 0.1546, Val Acc: 0.9643\n",
      "Epoch [97/100], Train Loss: 0.1395, Train Acc: 0.9686, Val Loss: 0.1547, Val Acc: 0.9643\n",
      "Epoch [98/100], Train Loss: 0.1399, Train Acc: 0.9686, Val Loss: 0.1551, Val Acc: 0.9643\n",
      "Epoch [99/100], Train Loss: 0.1397, Train Acc: 0.9686, Val Loss: 0.1547, Val Acc: 0.9643\n",
      "Epoch [100/100], Train Loss: 0.1404, Train Acc: 0.9686, Val Loss: 0.1543, Val Acc: 0.9643\n",
      "Finished Training RNNModel\n",
      "Cluster 0, Epoch 1/30, Avg Reward: 0.9683\n",
      "Cluster 0, Epoch 2/30, Avg Reward: 0.9780\n",
      "Cluster 0, Epoch 3/30, Avg Reward: 0.9746\n",
      "Cluster 0, Epoch 4/30, Avg Reward: 0.9776\n",
      "Cluster 0, Epoch 5/30, Avg Reward: 0.9888\n",
      "Cluster 0, Epoch 6/30, Avg Reward: 0.9767\n",
      "Cluster 0, Epoch 7/30, Avg Reward: 0.9751\n",
      "Cluster 0, Epoch 8/30, Avg Reward: 0.9712\n",
      "Cluster 0, Epoch 9/30, Avg Reward: 0.9754\n",
      "Cluster 0, Epoch 10/30, Avg Reward: 0.9745\n",
      "Cluster 0, Epoch 11/30, Avg Reward: 0.9655\n",
      "Cluster 0, Epoch 12/30, Avg Reward: 0.9600\n",
      "Cluster 0, Epoch 13/30, Avg Reward: 0.9757\n",
      "Cluster 0, Epoch 14/30, Avg Reward: 0.9663\n",
      "Cluster 0, Epoch 15/30, Avg Reward: 0.9667\n",
      "Cluster 0, Epoch 16/30, Avg Reward: 0.9860\n",
      "Cluster 0, Epoch 17/30, Avg Reward: 0.9613\n",
      "Cluster 0, Epoch 18/30, Avg Reward: 0.9755\n",
      "Cluster 0, Epoch 19/30, Avg Reward: 0.9887\n",
      "Cluster 0, Epoch 20/30, Avg Reward: 0.9756\n",
      "Cluster 0, Epoch 21/30, Avg Reward: 0.9723\n",
      "Cluster 0, Epoch 22/30, Avg Reward: 0.9692\n",
      "Cluster 0, Epoch 23/30, Avg Reward: 0.9828\n",
      "Cluster 0, Epoch 24/30, Avg Reward: 0.9647\n",
      "Cluster 0, Epoch 25/30, Avg Reward: 0.9919\n",
      "Cluster 0, Epoch 26/30, Avg Reward: 0.9779\n",
      "Cluster 0, Epoch 27/30, Avg Reward: 0.9742\n",
      "Cluster 0, Epoch 28/30, Avg Reward: 0.9636\n",
      "Cluster 0, Epoch 29/30, Avg Reward: 0.9811\n",
      "Cluster 0, Epoch 30/30, Avg Reward: 0.9852\n",
      "\n",
      "=== Training for cluster 1 ===\n",
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/100], Train Loss: 0.5975, Train Acc: 0.7979, Val Loss: 0.5264, Val Acc: 0.7979\n",
      "Epoch [2/100], Train Loss: 0.4771, Train Acc: 0.8032, Val Loss: 0.4291, Val Acc: 0.8191\n",
      "Epoch [3/100], Train Loss: 0.3724, Train Acc: 0.8511, Val Loss: 0.3563, Val Acc: 0.8617\n",
      "Epoch [4/100], Train Loss: 0.2895, Train Acc: 0.8723, Val Loss: 0.3047, Val Acc: 0.8511\n",
      "Epoch [5/100], Train Loss: 0.2139, Train Acc: 0.9069, Val Loss: 0.2798, Val Acc: 0.8936\n",
      "Epoch [6/100], Train Loss: 0.1693, Train Acc: 0.9388, Val Loss: 0.2737, Val Acc: 0.8936\n",
      "Epoch [7/100], Train Loss: 0.1456, Train Acc: 0.9415, Val Loss: 0.2725, Val Acc: 0.8936\n",
      "Epoch [8/100], Train Loss: 0.1356, Train Acc: 0.9441, Val Loss: 0.2746, Val Acc: 0.9043\n",
      "Epoch [9/100], Train Loss: 0.1277, Train Acc: 0.9495, Val Loss: 0.2662, Val Acc: 0.9043\n",
      "Epoch [10/100], Train Loss: 0.1279, Train Acc: 0.9495, Val Loss: 0.2648, Val Acc: 0.9149\n",
      "Epoch [11/100], Train Loss: 0.1218, Train Acc: 0.9521, Val Loss: 0.2676, Val Acc: 0.9149\n",
      "Epoch [12/100], Train Loss: 0.1193, Train Acc: 0.9521, Val Loss: 0.2579, Val Acc: 0.9149\n",
      "Epoch [13/100], Train Loss: 0.1177, Train Acc: 0.9548, Val Loss: 0.2563, Val Acc: 0.9149\n",
      "Epoch [14/100], Train Loss: 0.1154, Train Acc: 0.9521, Val Loss: 0.2569, Val Acc: 0.9149\n",
      "Epoch [15/100], Train Loss: 0.1134, Train Acc: 0.9548, Val Loss: 0.2513, Val Acc: 0.9255\n",
      "Epoch [16/100], Train Loss: 0.1138, Train Acc: 0.9548, Val Loss: 0.2497, Val Acc: 0.9255\n",
      "Epoch [17/100], Train Loss: 0.1144, Train Acc: 0.9548, Val Loss: 0.2524, Val Acc: 0.9255\n",
      "Epoch [18/100], Train Loss: 0.1116, Train Acc: 0.9521, Val Loss: 0.2603, Val Acc: 0.9255\n",
      "Epoch [19/100], Train Loss: 0.1096, Train Acc: 0.9548, Val Loss: 0.2545, Val Acc: 0.9362\n",
      "Epoch [20/100], Train Loss: 0.1191, Train Acc: 0.9548, Val Loss: 0.2569, Val Acc: 0.9362\n",
      "Epoch [21/100], Train Loss: 0.1167, Train Acc: 0.9548, Val Loss: 0.2748, Val Acc: 0.9255\n",
      "Epoch [22/100], Train Loss: 0.1126, Train Acc: 0.9521, Val Loss: 0.2605, Val Acc: 0.9362\n",
      "Epoch [23/100], Train Loss: 0.1205, Train Acc: 0.9548, Val Loss: 0.2670, Val Acc: 0.9362\n",
      "Epoch [24/100], Train Loss: 0.1135, Train Acc: 0.9548, Val Loss: 0.2751, Val Acc: 0.9255\n",
      "Epoch [25/100], Train Loss: 0.1109, Train Acc: 0.9548, Val Loss: 0.2684, Val Acc: 0.9362\n",
      "Epoch [26/100], Train Loss: 0.1096, Train Acc: 0.9548, Val Loss: 0.2737, Val Acc: 0.9362\n",
      "Epoch [27/100], Train Loss: 0.1109, Train Acc: 0.9548, Val Loss: 0.2802, Val Acc: 0.9255\n",
      "Epoch [28/100], Train Loss: 0.1071, Train Acc: 0.9548, Val Loss: 0.2781, Val Acc: 0.9362\n",
      "Epoch [29/100], Train Loss: 0.1053, Train Acc: 0.9548, Val Loss: 0.2820, Val Acc: 0.9362\n",
      "Epoch [30/100], Train Loss: 0.1049, Train Acc: 0.9548, Val Loss: 0.2866, Val Acc: 0.9362\n",
      "Epoch [31/100], Train Loss: 0.1045, Train Acc: 0.9548, Val Loss: 0.2924, Val Acc: 0.9255\n",
      "Epoch [32/100], Train Loss: 0.1064, Train Acc: 0.9548, Val Loss: 0.2911, Val Acc: 0.9362\n",
      "Epoch [33/100], Train Loss: 0.1054, Train Acc: 0.9548, Val Loss: 0.2985, Val Acc: 0.9255\n",
      "Epoch [34/100], Train Loss: 0.1048, Train Acc: 0.9548, Val Loss: 0.3007, Val Acc: 0.9362\n",
      "Epoch [35/100], Train Loss: 0.1030, Train Acc: 0.9548, Val Loss: 0.3052, Val Acc: 0.9362\n",
      "Epoch [36/100], Train Loss: 0.1028, Train Acc: 0.9548, Val Loss: 0.3104, Val Acc: 0.9362\n",
      "Epoch [37/100], Train Loss: 0.1031, Train Acc: 0.9548, Val Loss: 0.3180, Val Acc: 0.9362\n",
      "Epoch [38/100], Train Loss: 0.1051, Train Acc: 0.9548, Val Loss: 0.3199, Val Acc: 0.9362\n",
      "Epoch [39/100], Train Loss: 0.0993, Train Acc: 0.9548, Val Loss: 0.3234, Val Acc: 0.9362\n",
      "Epoch [40/100], Train Loss: 0.1020, Train Acc: 0.9548, Val Loss: 0.3277, Val Acc: 0.9362\n",
      "Epoch [41/100], Train Loss: 0.1000, Train Acc: 0.9548, Val Loss: 0.3334, Val Acc: 0.9362\n",
      "Epoch [42/100], Train Loss: 0.1008, Train Acc: 0.9548, Val Loss: 0.3407, Val Acc: 0.9362\n",
      "Epoch [43/100], Train Loss: 0.1004, Train Acc: 0.9548, Val Loss: 0.3452, Val Acc: 0.9362\n",
      "Epoch [44/100], Train Loss: 0.1020, Train Acc: 0.9548, Val Loss: 0.3537, Val Acc: 0.9362\n",
      "Epoch [45/100], Train Loss: 0.1002, Train Acc: 0.9548, Val Loss: 0.3583, Val Acc: 0.9362\n",
      "Epoch [46/100], Train Loss: 0.0983, Train Acc: 0.9548, Val Loss: 0.3628, Val Acc: 0.9362\n",
      "Epoch [47/100], Train Loss: 0.1005, Train Acc: 0.9548, Val Loss: 0.3698, Val Acc: 0.9362\n",
      "Epoch [48/100], Train Loss: 0.0962, Train Acc: 0.9548, Val Loss: 0.3773, Val Acc: 0.9362\n",
      "Epoch [49/100], Train Loss: 0.1050, Train Acc: 0.9548, Val Loss: 0.3783, Val Acc: 0.9362\n",
      "Epoch [50/100], Train Loss: 0.1011, Train Acc: 0.9574, Val Loss: 0.3833, Val Acc: 0.9362\n",
      "Epoch [51/100], Train Loss: 0.1026, Train Acc: 0.9548, Val Loss: 0.3901, Val Acc: 0.9362\n",
      "Epoch [52/100], Train Loss: 0.0965, Train Acc: 0.9548, Val Loss: 0.3959, Val Acc: 0.9362\n",
      "Epoch [53/100], Train Loss: 0.0975, Train Acc: 0.9548, Val Loss: 0.4031, Val Acc: 0.9362\n",
      "Epoch [54/100], Train Loss: 0.0979, Train Acc: 0.9574, Val Loss: 0.4083, Val Acc: 0.9362\n",
      "Epoch [55/100], Train Loss: 0.0988, Train Acc: 0.9574, Val Loss: 0.4123, Val Acc: 0.9362\n",
      "Epoch [56/100], Train Loss: 0.0957, Train Acc: 0.9574, Val Loss: 0.4211, Val Acc: 0.9362\n",
      "Epoch [57/100], Train Loss: 0.1043, Train Acc: 0.9574, Val Loss: 0.4302, Val Acc: 0.9362\n",
      "Epoch [58/100], Train Loss: 0.1028, Train Acc: 0.9548, Val Loss: 0.4336, Val Acc: 0.9362\n",
      "Epoch [59/100], Train Loss: 0.0955, Train Acc: 0.9574, Val Loss: 0.4348, Val Acc: 0.9362\n",
      "Epoch [60/100], Train Loss: 0.0993, Train Acc: 0.9574, Val Loss: 0.4462, Val Acc: 0.9362\n",
      "Epoch [61/100], Train Loss: 0.0967, Train Acc: 0.9574, Val Loss: 0.4521, Val Acc: 0.9362\n",
      "Epoch [62/100], Train Loss: 0.0991, Train Acc: 0.9574, Val Loss: 0.4524, Val Acc: 0.9362\n",
      "Epoch [63/100], Train Loss: 0.0941, Train Acc: 0.9574, Val Loss: 0.4613, Val Acc: 0.9362\n",
      "Epoch [64/100], Train Loss: 0.0979, Train Acc: 0.9574, Val Loss: 0.4649, Val Acc: 0.9362\n",
      "Epoch [65/100], Train Loss: 0.0932, Train Acc: 0.9574, Val Loss: 0.4723, Val Acc: 0.9362\n",
      "Epoch [66/100], Train Loss: 0.0964, Train Acc: 0.9574, Val Loss: 0.4730, Val Acc: 0.9362\n",
      "Epoch [67/100], Train Loss: 0.0947, Train Acc: 0.9574, Val Loss: 0.4767, Val Acc: 0.9362\n",
      "Epoch [68/100], Train Loss: 0.0945, Train Acc: 0.9574, Val Loss: 0.4834, Val Acc: 0.9362\n",
      "Epoch [69/100], Train Loss: 0.0946, Train Acc: 0.9574, Val Loss: 0.4902, Val Acc: 0.9362\n",
      "Epoch [70/100], Train Loss: 0.0958, Train Acc: 0.9574, Val Loss: 0.4930, Val Acc: 0.9362\n",
      "Epoch [71/100], Train Loss: 0.0964, Train Acc: 0.9574, Val Loss: 0.4990, Val Acc: 0.9362\n",
      "Epoch [72/100], Train Loss: 0.0943, Train Acc: 0.9574, Val Loss: 0.5051, Val Acc: 0.9362\n",
      "Epoch [73/100], Train Loss: 0.0952, Train Acc: 0.9574, Val Loss: 0.5069, Val Acc: 0.9362\n",
      "Epoch [74/100], Train Loss: 0.0973, Train Acc: 0.9574, Val Loss: 0.5154, Val Acc: 0.9362\n",
      "Epoch [75/100], Train Loss: 0.0931, Train Acc: 0.9574, Val Loss: 0.5205, Val Acc: 0.9362\n",
      "Epoch [76/100], Train Loss: 0.0985, Train Acc: 0.9574, Val Loss: 0.5195, Val Acc: 0.9362\n",
      "Epoch [77/100], Train Loss: 0.0938, Train Acc: 0.9574, Val Loss: 0.5206, Val Acc: 0.9362\n",
      "Epoch [78/100], Train Loss: 0.0958, Train Acc: 0.9574, Val Loss: 0.5259, Val Acc: 0.9362\n",
      "Epoch [79/100], Train Loss: 0.0959, Train Acc: 0.9574, Val Loss: 0.5330, Val Acc: 0.9362\n",
      "Epoch [80/100], Train Loss: 0.0937, Train Acc: 0.9574, Val Loss: 0.5337, Val Acc: 0.9362\n",
      "Epoch [81/100], Train Loss: 0.0966, Train Acc: 0.9574, Val Loss: 0.5369, Val Acc: 0.9362\n",
      "Epoch [82/100], Train Loss: 0.0940, Train Acc: 0.9574, Val Loss: 0.5435, Val Acc: 0.9362\n",
      "Epoch [83/100], Train Loss: 0.0939, Train Acc: 0.9574, Val Loss: 0.5483, Val Acc: 0.9362\n",
      "Epoch [84/100], Train Loss: 0.0943, Train Acc: 0.9574, Val Loss: 0.5519, Val Acc: 0.9362\n",
      "Epoch [85/100], Train Loss: 0.0952, Train Acc: 0.9574, Val Loss: 0.5547, Val Acc: 0.9362\n",
      "Epoch [86/100], Train Loss: 0.0950, Train Acc: 0.9574, Val Loss: 0.5598, Val Acc: 0.9362\n",
      "Epoch [87/100], Train Loss: 0.0938, Train Acc: 0.9574, Val Loss: 0.5648, Val Acc: 0.9362\n",
      "Epoch [88/100], Train Loss: 0.0937, Train Acc: 0.9574, Val Loss: 0.5665, Val Acc: 0.9362\n",
      "Epoch [89/100], Train Loss: 0.0955, Train Acc: 0.9574, Val Loss: 0.5686, Val Acc: 0.9362\n",
      "Epoch [90/100], Train Loss: 0.0933, Train Acc: 0.9574, Val Loss: 0.5722, Val Acc: 0.9362\n",
      "Epoch [91/100], Train Loss: 0.0951, Train Acc: 0.9574, Val Loss: 0.5784, Val Acc: 0.9362\n",
      "Epoch [92/100], Train Loss: 0.0950, Train Acc: 0.9574, Val Loss: 0.5804, Val Acc: 0.9362\n",
      "Epoch [93/100], Train Loss: 0.0941, Train Acc: 0.9574, Val Loss: 0.5802, Val Acc: 0.9362\n",
      "Epoch [94/100], Train Loss: 0.0942, Train Acc: 0.9574, Val Loss: 0.5835, Val Acc: 0.9362\n",
      "Epoch [95/100], Train Loss: 0.0934, Train Acc: 0.9574, Val Loss: 0.5886, Val Acc: 0.9362\n",
      "Epoch [96/100], Train Loss: 0.0968, Train Acc: 0.9574, Val Loss: 0.5939, Val Acc: 0.9362\n",
      "Epoch [97/100], Train Loss: 0.0933, Train Acc: 0.9574, Val Loss: 0.5963, Val Acc: 0.9362\n",
      "Epoch [98/100], Train Loss: 0.0957, Train Acc: 0.9574, Val Loss: 0.5969, Val Acc: 0.9362\n",
      "Epoch [99/100], Train Loss: 0.0952, Train Acc: 0.9574, Val Loss: 0.5988, Val Acc: 0.9362\n",
      "Epoch [100/100], Train Loss: 0.0943, Train Acc: 0.9574, Val Loss: 0.6035, Val Acc: 0.9362\n",
      "Finished Training MLPModel\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.4840, Train Acc: 0.8085, Val Loss: 0.4397, Val Acc: 0.8511\n",
      "Epoch [2/100], Train Loss: 0.3520, Train Acc: 0.8298, Val Loss: 0.4445, Val Acc: 0.7979\n",
      "Epoch [3/100], Train Loss: 0.2713, Train Acc: 0.8617, Val Loss: 0.4191, Val Acc: 0.8511\n",
      "Epoch [4/100], Train Loss: 0.2360, Train Acc: 0.8750, Val Loss: 0.3772, Val Acc: 0.8936\n",
      "Epoch [5/100], Train Loss: 0.1887, Train Acc: 0.9441, Val Loss: 0.3669, Val Acc: 0.8936\n",
      "Epoch [6/100], Train Loss: 0.1692, Train Acc: 0.9441, Val Loss: 0.3541, Val Acc: 0.8936\n",
      "Epoch [7/100], Train Loss: 0.1510, Train Acc: 0.9441, Val Loss: 0.3418, Val Acc: 0.8936\n",
      "Epoch [8/100], Train Loss: 0.1399, Train Acc: 0.9468, Val Loss: 0.3330, Val Acc: 0.9043\n",
      "Epoch [9/100], Train Loss: 0.1411, Train Acc: 0.9468, Val Loss: 0.3345, Val Acc: 0.9043\n",
      "Epoch [10/100], Train Loss: 0.1357, Train Acc: 0.9468, Val Loss: 0.3375, Val Acc: 0.9043\n",
      "Epoch [11/100], Train Loss: 0.1309, Train Acc: 0.9468, Val Loss: 0.3030, Val Acc: 0.9149\n",
      "Epoch [12/100], Train Loss: 0.1241, Train Acc: 0.9521, Val Loss: 0.2942, Val Acc: 0.9043\n",
      "Epoch [13/100], Train Loss: 0.1201, Train Acc: 0.9521, Val Loss: 0.3099, Val Acc: 0.9043\n",
      "Epoch [14/100], Train Loss: 0.1191, Train Acc: 0.9521, Val Loss: 0.3276, Val Acc: 0.9043\n",
      "Epoch [15/100], Train Loss: 0.1213, Train Acc: 0.9495, Val Loss: 0.3327, Val Acc: 0.9043\n",
      "Epoch [16/100], Train Loss: 0.1166, Train Acc: 0.9521, Val Loss: 0.3254, Val Acc: 0.9255\n",
      "Epoch [17/100], Train Loss: 0.1172, Train Acc: 0.9548, Val Loss: 0.3367, Val Acc: 0.9043\n",
      "Epoch [18/100], Train Loss: 0.1151, Train Acc: 0.9521, Val Loss: 0.3443, Val Acc: 0.9255\n",
      "Epoch [19/100], Train Loss: 0.1099, Train Acc: 0.9548, Val Loss: 0.3487, Val Acc: 0.9043\n",
      "Epoch [20/100], Train Loss: 0.1171, Train Acc: 0.9495, Val Loss: 0.3417, Val Acc: 0.9255\n",
      "Epoch [21/100], Train Loss: 0.1113, Train Acc: 0.9521, Val Loss: 0.3424, Val Acc: 0.9043\n",
      "Epoch [22/100], Train Loss: 0.1117, Train Acc: 0.9548, Val Loss: 0.3506, Val Acc: 0.9255\n",
      "Epoch [23/100], Train Loss: 0.1086, Train Acc: 0.9548, Val Loss: 0.3573, Val Acc: 0.9149\n",
      "Epoch [24/100], Train Loss: 0.1080, Train Acc: 0.9548, Val Loss: 0.3632, Val Acc: 0.9149\n",
      "Epoch [25/100], Train Loss: 0.1073, Train Acc: 0.9548, Val Loss: 0.3581, Val Acc: 0.9255\n",
      "Epoch [26/100], Train Loss: 0.1111, Train Acc: 0.9548, Val Loss: 0.3639, Val Acc: 0.9149\n",
      "Epoch [27/100], Train Loss: 0.1341, Train Acc: 0.9495, Val Loss: 0.3926, Val Acc: 0.9255\n",
      "Epoch [28/100], Train Loss: 0.1119, Train Acc: 0.9548, Val Loss: 0.3834, Val Acc: 0.9149\n",
      "Epoch [29/100], Train Loss: 0.1085, Train Acc: 0.9548, Val Loss: 0.3686, Val Acc: 0.9255\n",
      "Epoch [30/100], Train Loss: 0.1058, Train Acc: 0.9548, Val Loss: 0.3736, Val Acc: 0.9149\n",
      "Epoch [31/100], Train Loss: 0.1041, Train Acc: 0.9548, Val Loss: 0.3826, Val Acc: 0.9255\n",
      "Epoch [32/100], Train Loss: 0.1097, Train Acc: 0.9521, Val Loss: 0.3744, Val Acc: 0.9149\n",
      "Epoch [33/100], Train Loss: 0.1183, Train Acc: 0.9521, Val Loss: 0.4144, Val Acc: 0.9255\n",
      "Epoch [34/100], Train Loss: 0.1115, Train Acc: 0.9548, Val Loss: 0.4259, Val Acc: 0.9255\n",
      "Epoch [35/100], Train Loss: 0.1052, Train Acc: 0.9548, Val Loss: 0.4069, Val Acc: 0.9149\n",
      "Epoch [36/100], Train Loss: 0.1019, Train Acc: 0.9548, Val Loss: 0.3956, Val Acc: 0.9362\n",
      "Epoch [37/100], Train Loss: 0.1027, Train Acc: 0.9548, Val Loss: 0.3922, Val Acc: 0.9255\n",
      "Epoch [38/100], Train Loss: 0.1014, Train Acc: 0.9574, Val Loss: 0.4022, Val Acc: 0.9255\n",
      "Epoch [39/100], Train Loss: 0.1004, Train Acc: 0.9548, Val Loss: 0.4124, Val Acc: 0.9255\n",
      "Epoch [40/100], Train Loss: 0.1022, Train Acc: 0.9548, Val Loss: 0.4028, Val Acc: 0.9255\n",
      "Epoch [41/100], Train Loss: 0.1070, Train Acc: 0.9548, Val Loss: 0.4141, Val Acc: 0.9362\n",
      "Epoch [42/100], Train Loss: 0.1149, Train Acc: 0.9574, Val Loss: 0.4197, Val Acc: 0.9255\n",
      "Epoch [43/100], Train Loss: 0.1011, Train Acc: 0.9574, Val Loss: 0.4270, Val Acc: 0.9362\n",
      "Epoch [44/100], Train Loss: 0.1054, Train Acc: 0.9574, Val Loss: 0.4236, Val Acc: 0.9255\n",
      "Epoch [45/100], Train Loss: 0.1023, Train Acc: 0.9548, Val Loss: 0.4270, Val Acc: 0.9362\n",
      "Epoch [46/100], Train Loss: 0.1032, Train Acc: 0.9574, Val Loss: 0.4227, Val Acc: 0.9255\n",
      "Epoch [47/100], Train Loss: 0.1087, Train Acc: 0.9574, Val Loss: 0.4326, Val Acc: 0.9362\n",
      "Epoch [48/100], Train Loss: 0.0965, Train Acc: 0.9574, Val Loss: 0.4362, Val Acc: 0.9255\n",
      "Epoch [49/100], Train Loss: 0.0983, Train Acc: 0.9574, Val Loss: 0.4356, Val Acc: 0.9362\n",
      "Epoch [50/100], Train Loss: 0.0980, Train Acc: 0.9574, Val Loss: 0.4328, Val Acc: 0.9362\n",
      "Epoch [51/100], Train Loss: 0.0970, Train Acc: 0.9574, Val Loss: 0.4338, Val Acc: 0.9362\n",
      "Epoch [52/100], Train Loss: 0.0969, Train Acc: 0.9574, Val Loss: 0.4316, Val Acc: 0.9255\n",
      "Epoch [53/100], Train Loss: 0.0981, Train Acc: 0.9574, Val Loss: 0.4426, Val Acc: 0.9255\n",
      "Epoch [54/100], Train Loss: 0.1003, Train Acc: 0.9574, Val Loss: 0.4523, Val Acc: 0.9255\n",
      "Epoch [55/100], Train Loss: 0.1006, Train Acc: 0.9574, Val Loss: 0.4544, Val Acc: 0.9362\n",
      "Epoch [56/100], Train Loss: 0.1043, Train Acc: 0.9574, Val Loss: 0.4382, Val Acc: 0.9255\n",
      "Epoch [57/100], Train Loss: 0.0944, Train Acc: 0.9574, Val Loss: 0.4559, Val Acc: 0.9362\n",
      "Epoch [58/100], Train Loss: 0.1050, Train Acc: 0.9574, Val Loss: 0.4482, Val Acc: 0.9255\n",
      "Epoch [59/100], Train Loss: 0.0998, Train Acc: 0.9574, Val Loss: 0.4590, Val Acc: 0.9362\n",
      "Epoch [60/100], Train Loss: 0.0973, Train Acc: 0.9574, Val Loss: 0.4416, Val Acc: 0.9362\n",
      "Epoch [61/100], Train Loss: 0.0954, Train Acc: 0.9574, Val Loss: 0.4535, Val Acc: 0.9362\n",
      "Epoch [62/100], Train Loss: 0.0951, Train Acc: 0.9574, Val Loss: 0.4582, Val Acc: 0.9362\n",
      "Epoch [63/100], Train Loss: 0.0956, Train Acc: 0.9574, Val Loss: 0.4607, Val Acc: 0.9255\n",
      "Epoch [64/100], Train Loss: 0.0966, Train Acc: 0.9574, Val Loss: 0.4654, Val Acc: 0.9362\n",
      "Epoch [65/100], Train Loss: 0.0955, Train Acc: 0.9574, Val Loss: 0.4760, Val Acc: 0.9362\n",
      "Epoch [66/100], Train Loss: 0.0964, Train Acc: 0.9574, Val Loss: 0.4704, Val Acc: 0.9362\n",
      "Epoch [67/100], Train Loss: 0.0944, Train Acc: 0.9574, Val Loss: 0.4655, Val Acc: 0.9362\n",
      "Epoch [68/100], Train Loss: 0.0961, Train Acc: 0.9574, Val Loss: 0.4690, Val Acc: 0.9362\n",
      "Epoch [69/100], Train Loss: 0.0964, Train Acc: 0.9574, Val Loss: 0.4735, Val Acc: 0.9362\n",
      "Epoch [70/100], Train Loss: 0.0997, Train Acc: 0.9574, Val Loss: 0.4741, Val Acc: 0.9255\n",
      "Epoch [71/100], Train Loss: 0.1013, Train Acc: 0.9574, Val Loss: 0.4900, Val Acc: 0.9362\n",
      "Epoch [72/100], Train Loss: 0.0956, Train Acc: 0.9574, Val Loss: 0.4733, Val Acc: 0.9255\n",
      "Epoch [73/100], Train Loss: 0.0966, Train Acc: 0.9574, Val Loss: 0.4817, Val Acc: 0.9362\n",
      "Epoch [74/100], Train Loss: 0.0993, Train Acc: 0.9574, Val Loss: 0.4758, Val Acc: 0.9255\n",
      "Epoch [75/100], Train Loss: 0.0984, Train Acc: 0.9574, Val Loss: 0.4788, Val Acc: 0.9362\n",
      "Epoch [76/100], Train Loss: 0.1006, Train Acc: 0.9574, Val Loss: 0.4723, Val Acc: 0.9362\n",
      "Epoch [77/100], Train Loss: 0.0998, Train Acc: 0.9574, Val Loss: 0.4675, Val Acc: 0.9362\n",
      "Epoch [78/100], Train Loss: 0.0974, Train Acc: 0.9574, Val Loss: 0.4847, Val Acc: 0.9362\n",
      "Epoch [79/100], Train Loss: 0.0952, Train Acc: 0.9574, Val Loss: 0.4743, Val Acc: 0.9255\n",
      "Epoch [80/100], Train Loss: 0.1000, Train Acc: 0.9574, Val Loss: 0.4863, Val Acc: 0.9362\n",
      "Epoch [81/100], Train Loss: 0.0964, Train Acc: 0.9574, Val Loss: 0.4777, Val Acc: 0.9362\n",
      "Epoch [82/100], Train Loss: 0.1016, Train Acc: 0.9574, Val Loss: 0.4787, Val Acc: 0.9362\n",
      "Epoch [83/100], Train Loss: 0.0993, Train Acc: 0.9574, Val Loss: 0.4853, Val Acc: 0.9362\n",
      "Epoch [84/100], Train Loss: 0.0954, Train Acc: 0.9574, Val Loss: 0.4757, Val Acc: 0.9362\n",
      "Epoch [85/100], Train Loss: 0.0944, Train Acc: 0.9574, Val Loss: 0.4793, Val Acc: 0.9362\n",
      "Epoch [86/100], Train Loss: 0.0954, Train Acc: 0.9574, Val Loss: 0.4816, Val Acc: 0.9362\n",
      "Epoch [87/100], Train Loss: 0.0954, Train Acc: 0.9574, Val Loss: 0.4817, Val Acc: 0.9362\n",
      "Epoch [88/100], Train Loss: 0.0945, Train Acc: 0.9574, Val Loss: 0.4945, Val Acc: 0.9362\n",
      "Epoch [89/100], Train Loss: 0.0965, Train Acc: 0.9574, Val Loss: 0.4937, Val Acc: 0.9362\n",
      "Epoch [90/100], Train Loss: 0.0956, Train Acc: 0.9574, Val Loss: 0.4825, Val Acc: 0.9362\n",
      "Epoch [91/100], Train Loss: 0.1014, Train Acc: 0.9574, Val Loss: 0.4875, Val Acc: 0.9362\n",
      "Epoch [92/100], Train Loss: 0.0974, Train Acc: 0.9574, Val Loss: 0.4915, Val Acc: 0.9362\n",
      "Epoch [93/100], Train Loss: 0.0969, Train Acc: 0.9574, Val Loss: 0.4822, Val Acc: 0.9362\n",
      "Epoch [94/100], Train Loss: 0.0943, Train Acc: 0.9574, Val Loss: 0.5014, Val Acc: 0.9362\n",
      "Epoch [95/100], Train Loss: 0.1064, Train Acc: 0.9388, Val Loss: 0.4792, Val Acc: 0.9362\n",
      "Epoch [96/100], Train Loss: 0.1016, Train Acc: 0.9574, Val Loss: 0.4785, Val Acc: 0.9362\n",
      "Epoch [97/100], Train Loss: 0.0938, Train Acc: 0.9574, Val Loss: 0.4902, Val Acc: 0.9362\n",
      "Epoch [98/100], Train Loss: 0.0942, Train Acc: 0.9574, Val Loss: 0.4845, Val Acc: 0.9362\n",
      "Epoch [99/100], Train Loss: 0.1007, Train Acc: 0.9574, Val Loss: 0.4877, Val Acc: 0.9362\n",
      "Epoch [100/100], Train Loss: 0.0947, Train Acc: 0.9574, Val Loss: 0.5024, Val Acc: 0.9362\n",
      "Finished Training CNNModel\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.6595, Train Acc: 0.7979, Val Loss: 0.6402, Val Acc: 0.7979\n",
      "Epoch [2/100], Train Loss: 0.6262, Train Acc: 0.7979, Val Loss: 0.6051, Val Acc: 0.7979\n",
      "Epoch [3/100], Train Loss: 0.5837, Train Acc: 0.7979, Val Loss: 0.5423, Val Acc: 0.7979\n",
      "Epoch [4/100], Train Loss: 0.4913, Train Acc: 0.7979, Val Loss: 0.4894, Val Acc: 0.7979\n",
      "Epoch [5/100], Train Loss: 0.4827, Train Acc: 0.7979, Val Loss: 0.4629, Val Acc: 0.7979\n",
      "Epoch [6/100], Train Loss: 0.4506, Train Acc: 0.7979, Val Loss: 0.4560, Val Acc: 0.7979\n",
      "Epoch [7/100], Train Loss: 0.4365, Train Acc: 0.7979, Val Loss: 0.4362, Val Acc: 0.7979\n",
      "Epoch [8/100], Train Loss: 0.4121, Train Acc: 0.7979, Val Loss: 0.4213, Val Acc: 0.7979\n",
      "Epoch [9/100], Train Loss: 0.3931, Train Acc: 0.7979, Val Loss: 0.4063, Val Acc: 0.7979\n",
      "Epoch [10/100], Train Loss: 0.3618, Train Acc: 0.7979, Val Loss: 0.3944, Val Acc: 0.7979\n",
      "Epoch [11/100], Train Loss: 0.3406, Train Acc: 0.8138, Val Loss: 0.3823, Val Acc: 0.8617\n",
      "Epoch [12/100], Train Loss: 0.3087, Train Acc: 0.8511, Val Loss: 0.3865, Val Acc: 0.8511\n",
      "Epoch [13/100], Train Loss: 0.2913, Train Acc: 0.8723, Val Loss: 0.3625, Val Acc: 0.8511\n",
      "Epoch [14/100], Train Loss: 0.2561, Train Acc: 0.8750, Val Loss: 0.3694, Val Acc: 0.8511\n",
      "Epoch [15/100], Train Loss: 0.2446, Train Acc: 0.9255, Val Loss: 0.3627, Val Acc: 0.8404\n",
      "Epoch [16/100], Train Loss: 0.2361, Train Acc: 0.9122, Val Loss: 0.3698, Val Acc: 0.8511\n",
      "Epoch [17/100], Train Loss: 0.2234, Train Acc: 0.9282, Val Loss: 0.3550, Val Acc: 0.8511\n",
      "Epoch [18/100], Train Loss: 0.2173, Train Acc: 0.9309, Val Loss: 0.3561, Val Acc: 0.8617\n",
      "Epoch [19/100], Train Loss: 0.2085, Train Acc: 0.9309, Val Loss: 0.3623, Val Acc: 0.8830\n",
      "Epoch [20/100], Train Loss: 0.2019, Train Acc: 0.9415, Val Loss: 0.3453, Val Acc: 0.8936\n",
      "Epoch [21/100], Train Loss: 0.1967, Train Acc: 0.9415, Val Loss: 0.3220, Val Acc: 0.8936\n",
      "Epoch [22/100], Train Loss: 0.1906, Train Acc: 0.9441, Val Loss: 0.3320, Val Acc: 0.8936\n",
      "Epoch [23/100], Train Loss: 0.1857, Train Acc: 0.9415, Val Loss: 0.3240, Val Acc: 0.8936\n",
      "Epoch [24/100], Train Loss: 0.1804, Train Acc: 0.9415, Val Loss: 0.3276, Val Acc: 0.8830\n",
      "Epoch [25/100], Train Loss: 0.1747, Train Acc: 0.9415, Val Loss: 0.3206, Val Acc: 0.8830\n",
      "Epoch [26/100], Train Loss: 0.1690, Train Acc: 0.9415, Val Loss: 0.3103, Val Acc: 0.8830\n",
      "Epoch [27/100], Train Loss: 0.1660, Train Acc: 0.9441, Val Loss: 0.3180, Val Acc: 0.8830\n",
      "Epoch [28/100], Train Loss: 0.1621, Train Acc: 0.9415, Val Loss: 0.3199, Val Acc: 0.8830\n",
      "Epoch [29/100], Train Loss: 0.1628, Train Acc: 0.9388, Val Loss: 0.2962, Val Acc: 0.8830\n",
      "Epoch [30/100], Train Loss: 0.1675, Train Acc: 0.9441, Val Loss: 0.2832, Val Acc: 0.9043\n",
      "Epoch [31/100], Train Loss: 0.1629, Train Acc: 0.9441, Val Loss: 0.3149, Val Acc: 0.8830\n",
      "Epoch [32/100], Train Loss: 0.1569, Train Acc: 0.9441, Val Loss: 0.2897, Val Acc: 0.9043\n",
      "Epoch [33/100], Train Loss: 0.1539, Train Acc: 0.9441, Val Loss: 0.3002, Val Acc: 0.8830\n",
      "Epoch [34/100], Train Loss: 0.1529, Train Acc: 0.9441, Val Loss: 0.2978, Val Acc: 0.8936\n",
      "Epoch [35/100], Train Loss: 0.1533, Train Acc: 0.9441, Val Loss: 0.3083, Val Acc: 0.8830\n",
      "Epoch [36/100], Train Loss: 0.1515, Train Acc: 0.9441, Val Loss: 0.2865, Val Acc: 0.9043\n",
      "Epoch [37/100], Train Loss: 0.1568, Train Acc: 0.9468, Val Loss: 0.2923, Val Acc: 0.8936\n",
      "Epoch [38/100], Train Loss: 0.1642, Train Acc: 0.9415, Val Loss: 0.3118, Val Acc: 0.8830\n",
      "Epoch [39/100], Train Loss: 0.1618, Train Acc: 0.9441, Val Loss: 0.2642, Val Acc: 0.9043\n",
      "Epoch [40/100], Train Loss: 0.1593, Train Acc: 0.9441, Val Loss: 0.3164, Val Acc: 0.8830\n",
      "Epoch [41/100], Train Loss: 0.1516, Train Acc: 0.9415, Val Loss: 0.2633, Val Acc: 0.9043\n",
      "Epoch [42/100], Train Loss: 0.1537, Train Acc: 0.9468, Val Loss: 0.2949, Val Acc: 0.9043\n",
      "Epoch [43/100], Train Loss: 0.1500, Train Acc: 0.9441, Val Loss: 0.2910, Val Acc: 0.9043\n",
      "Epoch [44/100], Train Loss: 0.1524, Train Acc: 0.9468, Val Loss: 0.2912, Val Acc: 0.9043\n",
      "Epoch [45/100], Train Loss: 0.1463, Train Acc: 0.9468, Val Loss: 0.2911, Val Acc: 0.8936\n",
      "Epoch [46/100], Train Loss: 0.1480, Train Acc: 0.9468, Val Loss: 0.2827, Val Acc: 0.8936\n",
      "Epoch [47/100], Train Loss: 0.1472, Train Acc: 0.9468, Val Loss: 0.2735, Val Acc: 0.9043\n",
      "Epoch [48/100], Train Loss: 0.1457, Train Acc: 0.9468, Val Loss: 0.2720, Val Acc: 0.9043\n",
      "Epoch [49/100], Train Loss: 0.1456, Train Acc: 0.9468, Val Loss: 0.2822, Val Acc: 0.9043\n",
      "Epoch [50/100], Train Loss: 0.1491, Train Acc: 0.9468, Val Loss: 0.2878, Val Acc: 0.9043\n",
      "Epoch [51/100], Train Loss: 0.1438, Train Acc: 0.9468, Val Loss: 0.2655, Val Acc: 0.9043\n",
      "Epoch [52/100], Train Loss: 0.1435, Train Acc: 0.9468, Val Loss: 0.2610, Val Acc: 0.9043\n",
      "Epoch [53/100], Train Loss: 0.1466, Train Acc: 0.9468, Val Loss: 0.2545, Val Acc: 0.9043\n",
      "Epoch [54/100], Train Loss: 0.1476, Train Acc: 0.9468, Val Loss: 0.2771, Val Acc: 0.9043\n",
      "Epoch [55/100], Train Loss: 0.1471, Train Acc: 0.9468, Val Loss: 0.2704, Val Acc: 0.9043\n",
      "Epoch [56/100], Train Loss: 0.1504, Train Acc: 0.9468, Val Loss: 0.2778, Val Acc: 0.9043\n",
      "Epoch [57/100], Train Loss: 0.1513, Train Acc: 0.9495, Val Loss: 0.2493, Val Acc: 0.9043\n",
      "Epoch [58/100], Train Loss: 0.1448, Train Acc: 0.9468, Val Loss: 0.3170, Val Acc: 0.8936\n",
      "Epoch [59/100], Train Loss: 0.1478, Train Acc: 0.9441, Val Loss: 0.2718, Val Acc: 0.9043\n",
      "Epoch [60/100], Train Loss: 0.1461, Train Acc: 0.9495, Val Loss: 0.2596, Val Acc: 0.9149\n",
      "Epoch [61/100], Train Loss: 0.1425, Train Acc: 0.9468, Val Loss: 0.2735, Val Acc: 0.9043\n",
      "Epoch [62/100], Train Loss: 0.1410, Train Acc: 0.9468, Val Loss: 0.2427, Val Acc: 0.9149\n",
      "Epoch [63/100], Train Loss: 0.1449, Train Acc: 0.9495, Val Loss: 0.2791, Val Acc: 0.9043\n",
      "Epoch [64/100], Train Loss: 0.1425, Train Acc: 0.9468, Val Loss: 0.2718, Val Acc: 0.9043\n",
      "Epoch [65/100], Train Loss: 0.1410, Train Acc: 0.9468, Val Loss: 0.2592, Val Acc: 0.9149\n",
      "Epoch [66/100], Train Loss: 0.1413, Train Acc: 0.9468, Val Loss: 0.2536, Val Acc: 0.9149\n",
      "Epoch [67/100], Train Loss: 0.1403, Train Acc: 0.9495, Val Loss: 0.2471, Val Acc: 0.9149\n",
      "Epoch [68/100], Train Loss: 0.1432, Train Acc: 0.9468, Val Loss: 0.2568, Val Acc: 0.9149\n",
      "Epoch [69/100], Train Loss: 0.1383, Train Acc: 0.9468, Val Loss: 0.2369, Val Acc: 0.9149\n",
      "Epoch [70/100], Train Loss: 0.1387, Train Acc: 0.9495, Val Loss: 0.2423, Val Acc: 0.9149\n",
      "Epoch [71/100], Train Loss: 0.1393, Train Acc: 0.9468, Val Loss: 0.2571, Val Acc: 0.9149\n",
      "Epoch [72/100], Train Loss: 0.1473, Train Acc: 0.9282, Val Loss: 0.2202, Val Acc: 0.9149\n",
      "Epoch [73/100], Train Loss: 0.1448, Train Acc: 0.9468, Val Loss: 0.2312, Val Acc: 0.9149\n",
      "Epoch [74/100], Train Loss: 0.1458, Train Acc: 0.9468, Val Loss: 0.2301, Val Acc: 0.9149\n",
      "Epoch [75/100], Train Loss: 0.1377, Train Acc: 0.9495, Val Loss: 0.2432, Val Acc: 0.9149\n",
      "Epoch [76/100], Train Loss: 0.1416, Train Acc: 0.9495, Val Loss: 0.2501, Val Acc: 0.9149\n",
      "Epoch [77/100], Train Loss: 0.1408, Train Acc: 0.9495, Val Loss: 0.2517, Val Acc: 0.9149\n",
      "Epoch [78/100], Train Loss: 0.1404, Train Acc: 0.9468, Val Loss: 0.2786, Val Acc: 0.9043\n",
      "Epoch [79/100], Train Loss: 0.1425, Train Acc: 0.9495, Val Loss: 0.2518, Val Acc: 0.9149\n",
      "Epoch [80/100], Train Loss: 0.1412, Train Acc: 0.9495, Val Loss: 0.2528, Val Acc: 0.9149\n",
      "Epoch [81/100], Train Loss: 0.1379, Train Acc: 0.9495, Val Loss: 0.2481, Val Acc: 0.9149\n",
      "Epoch [82/100], Train Loss: 0.1409, Train Acc: 0.9495, Val Loss: 0.2560, Val Acc: 0.9149\n",
      "Epoch [83/100], Train Loss: 0.1359, Train Acc: 0.9468, Val Loss: 0.2488, Val Acc: 0.9149\n",
      "Epoch [84/100], Train Loss: 0.1373, Train Acc: 0.9495, Val Loss: 0.2416, Val Acc: 0.9149\n",
      "Epoch [85/100], Train Loss: 0.1327, Train Acc: 0.9495, Val Loss: 0.2288, Val Acc: 0.9149\n",
      "Epoch [86/100], Train Loss: 0.1362, Train Acc: 0.9495, Val Loss: 0.2277, Val Acc: 0.9149\n",
      "Epoch [87/100], Train Loss: 0.1365, Train Acc: 0.9468, Val Loss: 0.2457, Val Acc: 0.9149\n",
      "Epoch [88/100], Train Loss: 0.1304, Train Acc: 0.9495, Val Loss: 0.2194, Val Acc: 0.9149\n",
      "Epoch [89/100], Train Loss: 0.1366, Train Acc: 0.9495, Val Loss: 0.2311, Val Acc: 0.9149\n",
      "Epoch [90/100], Train Loss: 0.1307, Train Acc: 0.9495, Val Loss: 0.2270, Val Acc: 0.9149\n",
      "Epoch [91/100], Train Loss: 0.1302, Train Acc: 0.9495, Val Loss: 0.2233, Val Acc: 0.9149\n",
      "Epoch [92/100], Train Loss: 0.1369, Train Acc: 0.9495, Val Loss: 0.2300, Val Acc: 0.9149\n",
      "Epoch [93/100], Train Loss: 0.1387, Train Acc: 0.9468, Val Loss: 0.2344, Val Acc: 0.9149\n",
      "Epoch [94/100], Train Loss: 0.1381, Train Acc: 0.9495, Val Loss: 0.2079, Val Acc: 0.9149\n",
      "Epoch [95/100], Train Loss: 0.1370, Train Acc: 0.9495, Val Loss: 0.2369, Val Acc: 0.9149\n",
      "Epoch [96/100], Train Loss: 0.1372, Train Acc: 0.9468, Val Loss: 0.2757, Val Acc: 0.9043\n",
      "Epoch [97/100], Train Loss: 0.1342, Train Acc: 0.9495, Val Loss: 0.2279, Val Acc: 0.9149\n",
      "Epoch [98/100], Train Loss: 0.1332, Train Acc: 0.9495, Val Loss: 0.2733, Val Acc: 0.9043\n",
      "Epoch [99/100], Train Loss: 0.1377, Train Acc: 0.9468, Val Loss: 0.2243, Val Acc: 0.9149\n",
      "Epoch [100/100], Train Loss: 0.1359, Train Acc: 0.9495, Val Loss: 0.2210, Val Acc: 0.9149\n",
      "Finished Training RNNModel\n",
      "Cluster 1, Epoch 1/30, Avg Reward: 0.8992\n",
      "Cluster 1, Epoch 2/30, Avg Reward: 0.8866\n",
      "Cluster 1, Epoch 3/30, Avg Reward: 0.8946\n",
      "Cluster 1, Epoch 4/30, Avg Reward: 0.8976\n",
      "Cluster 1, Epoch 5/30, Avg Reward: 0.9042\n",
      "Cluster 1, Epoch 6/30, Avg Reward: 0.8913\n",
      "Cluster 1, Epoch 7/30, Avg Reward: 0.9027\n",
      "Cluster 1, Epoch 8/30, Avg Reward: 0.8925\n",
      "Cluster 1, Epoch 9/30, Avg Reward: 0.9049\n",
      "Cluster 1, Epoch 10/30, Avg Reward: 0.9065\n",
      "Cluster 1, Epoch 11/30, Avg Reward: 0.8982\n",
      "Cluster 1, Epoch 12/30, Avg Reward: 0.8983\n",
      "Cluster 1, Epoch 13/30, Avg Reward: 0.8910\n",
      "Cluster 1, Epoch 14/30, Avg Reward: 0.9076\n",
      "Cluster 1, Epoch 15/30, Avg Reward: 0.9096\n",
      "Cluster 1, Epoch 16/30, Avg Reward: 0.8969\n",
      "Cluster 1, Epoch 17/30, Avg Reward: 0.9022\n",
      "Cluster 1, Epoch 18/30, Avg Reward: 0.9063\n",
      "Cluster 1, Epoch 19/30, Avg Reward: 0.9087\n",
      "Cluster 1, Epoch 20/30, Avg Reward: 0.9013\n",
      "Cluster 1, Epoch 21/30, Avg Reward: 0.8905\n",
      "Cluster 1, Epoch 22/30, Avg Reward: 0.8955\n",
      "Cluster 1, Epoch 23/30, Avg Reward: 0.8806\n",
      "Cluster 1, Epoch 24/30, Avg Reward: 0.8933\n",
      "Cluster 1, Epoch 25/30, Avg Reward: 0.9063\n",
      "Cluster 1, Epoch 26/30, Avg Reward: 0.8941\n",
      "Cluster 1, Epoch 27/30, Avg Reward: 0.8886\n",
      "Cluster 1, Epoch 28/30, Avg Reward: 0.9022\n",
      "Cluster 1, Epoch 29/30, Avg Reward: 0.8945\n",
      "Cluster 1, Epoch 30/30, Avg Reward: 0.9004\n",
      "\n",
      "=== Training for cluster 2 ===\n",
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/100], Train Loss: 0.6039, Train Acc: 0.8700, Val Loss: 0.4349, Val Acc: 0.9804\n",
      "Epoch [2/100], Train Loss: 0.3779, Train Acc: 0.9850, Val Loss: 0.2530, Val Acc: 0.9804\n",
      "Epoch [3/100], Train Loss: 0.2118, Train Acc: 0.9850, Val Loss: 0.1314, Val Acc: 0.9804\n",
      "Epoch [4/100], Train Loss: 0.1058, Train Acc: 0.9900, Val Loss: 0.0673, Val Acc: 0.9804\n",
      "Epoch [5/100], Train Loss: 0.0540, Train Acc: 0.9900, Val Loss: 0.0369, Val Acc: 0.9804\n",
      "Epoch [6/100], Train Loss: 0.0296, Train Acc: 0.9900, Val Loss: 0.0227, Val Acc: 1.0000\n",
      "Epoch [7/100], Train Loss: 0.0181, Train Acc: 0.9950, Val Loss: 0.0156, Val Acc: 1.0000\n",
      "Epoch [8/100], Train Loss: 0.0124, Train Acc: 0.9950, Val Loss: 0.0110, Val Acc: 1.0000\n",
      "Epoch [9/100], Train Loss: 0.0088, Train Acc: 0.9950, Val Loss: 0.0078, Val Acc: 1.0000\n",
      "Epoch [10/100], Train Loss: 0.0065, Train Acc: 1.0000, Val Loss: 0.0051, Val Acc: 1.0000\n",
      "Epoch [11/100], Train Loss: 0.0047, Train Acc: 1.0000, Val Loss: 0.0037, Val Acc: 1.0000\n",
      "Epoch [12/100], Train Loss: 0.0034, Train Acc: 1.0000, Val Loss: 0.0029, Val Acc: 1.0000\n",
      "Epoch [13/100], Train Loss: 0.0029, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch [14/100], Train Loss: 0.0023, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
      "Epoch [15/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0018, Val Acc: 1.0000\n",
      "Epoch [16/100], Train Loss: 0.0017, Train Acc: 1.0000, Val Loss: 0.0016, Val Acc: 1.0000\n",
      "Epoch [17/100], Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [18/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [19/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [20/100], Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [21/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [22/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [23/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [24/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [25/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [26/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [27/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [28/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [29/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [30/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [31/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [32/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [33/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [34/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [35/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [36/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [37/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [38/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [39/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [40/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [41/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [42/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [43/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [44/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [45/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [46/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [47/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [48/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [49/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [50/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [51/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [52/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [53/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [54/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [55/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [56/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [57/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [58/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [59/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [60/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [61/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [62/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [63/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [64/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [65/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [66/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [67/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [68/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [69/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [70/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [71/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [72/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [73/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [74/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [75/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [76/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [77/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [78/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [79/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [80/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [81/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [82/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [83/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [84/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [85/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [86/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [87/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [88/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [89/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [90/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [91/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [92/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [93/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [94/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [95/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [96/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [97/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [98/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [99/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [100/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Finished Training MLPModel\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.5026, Train Acc: 0.5950, Val Loss: 0.1469, Val Acc: 0.9804\n",
      "Epoch [2/100], Train Loss: 0.1072, Train Acc: 0.9700, Val Loss: 0.0553, Val Acc: 0.9804\n",
      "Epoch [3/100], Train Loss: 0.0467, Train Acc: 0.9850, Val Loss: 0.0354, Val Acc: 0.9804\n",
      "Epoch [4/100], Train Loss: 0.0291, Train Acc: 0.9900, Val Loss: 0.0250, Val Acc: 0.9804\n",
      "Epoch [5/100], Train Loss: 0.0214, Train Acc: 0.9900, Val Loss: 0.0183, Val Acc: 1.0000\n",
      "Epoch [6/100], Train Loss: 0.0164, Train Acc: 0.9900, Val Loss: 0.0131, Val Acc: 1.0000\n",
      "Epoch [7/100], Train Loss: 0.0118, Train Acc: 0.9950, Val Loss: 0.0094, Val Acc: 1.0000\n",
      "Epoch [8/100], Train Loss: 0.0085, Train Acc: 0.9950, Val Loss: 0.0068, Val Acc: 1.0000\n",
      "Epoch [9/100], Train Loss: 0.0066, Train Acc: 1.0000, Val Loss: 0.0052, Val Acc: 1.0000\n",
      "Epoch [10/100], Train Loss: 0.0044, Train Acc: 1.0000, Val Loss: 0.0041, Val Acc: 1.0000\n",
      "Epoch [11/100], Train Loss: 0.0033, Train Acc: 1.0000, Val Loss: 0.0033, Val Acc: 1.0000\n",
      "Epoch [12/100], Train Loss: 0.0024, Train Acc: 1.0000, Val Loss: 0.0027, Val Acc: 1.0000\n",
      "Epoch [13/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch [14/100], Train Loss: 0.0016, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
      "Epoch [15/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0018, Val Acc: 1.0000\n",
      "Epoch [16/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [17/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [18/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [19/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [20/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [21/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [22/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [23/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [24/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [25/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [26/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [27/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [28/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [29/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [30/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [31/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [32/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [33/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [34/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [35/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [36/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [37/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [38/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [39/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [40/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [41/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [42/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [43/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [44/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [45/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [46/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [47/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [48/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [49/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [50/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [51/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [52/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [53/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [54/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [55/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [56/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [57/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [58/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [59/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [60/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [61/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [62/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [63/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [64/100], Train Loss: 0.0001, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [65/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [66/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [67/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [68/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [69/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [70/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [71/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [72/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [73/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [74/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [75/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [76/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [77/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [78/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [79/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [80/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [81/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [82/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [83/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [84/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [85/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [86/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [87/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [88/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [89/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [90/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [91/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [92/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [93/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [94/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [95/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [96/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [97/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [98/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [99/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Epoch [100/100], Train Loss: 0.0000, Train Acc: 1.0000, Val Loss: 0.0001, Val Acc: 1.0000\n",
      "Finished Training CNNModel\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.7075, Train Acc: 0.1850, Val Loss: 0.6897, Val Acc: 0.6863\n",
      "Epoch [2/100], Train Loss: 0.6830, Train Acc: 0.7650, Val Loss: 0.6673, Val Acc: 0.8431\n",
      "Epoch [3/100], Train Loss: 0.6605, Train Acc: 0.8450, Val Loss: 0.6446, Val Acc: 0.8431\n",
      "Epoch [4/100], Train Loss: 0.6350, Train Acc: 0.8450, Val Loss: 0.6143, Val Acc: 0.8431\n",
      "Epoch [5/100], Train Loss: 0.6005, Train Acc: 0.8450, Val Loss: 0.5632, Val Acc: 0.8431\n",
      "Epoch [6/100], Train Loss: 0.5356, Train Acc: 0.8450, Val Loss: 0.4670, Val Acc: 0.8431\n",
      "Epoch [7/100], Train Loss: 0.4458, Train Acc: 0.8450, Val Loss: 0.4230, Val Acc: 0.8431\n",
      "Epoch [8/100], Train Loss: 0.4221, Train Acc: 0.8450, Val Loss: 0.4279, Val Acc: 0.8431\n",
      "Epoch [9/100], Train Loss: 0.4234, Train Acc: 0.8450, Val Loss: 0.4214, Val Acc: 0.8431\n",
      "Epoch [10/100], Train Loss: 0.4173, Train Acc: 0.8450, Val Loss: 0.4165, Val Acc: 0.8431\n",
      "Epoch [11/100], Train Loss: 0.4132, Train Acc: 0.8450, Val Loss: 0.4139, Val Acc: 0.8431\n",
      "Epoch [12/100], Train Loss: 0.4105, Train Acc: 0.8450, Val Loss: 0.4110, Val Acc: 0.8431\n",
      "Epoch [13/100], Train Loss: 0.4070, Train Acc: 0.8450, Val Loss: 0.4064, Val Acc: 0.8431\n",
      "Epoch [14/100], Train Loss: 0.4026, Train Acc: 0.8450, Val Loss: 0.4033, Val Acc: 0.8431\n",
      "Epoch [15/100], Train Loss: 0.3999, Train Acc: 0.8450, Val Loss: 0.3994, Val Acc: 0.8431\n",
      "Epoch [16/100], Train Loss: 0.3973, Train Acc: 0.8450, Val Loss: 0.3953, Val Acc: 0.8431\n",
      "Epoch [17/100], Train Loss: 0.3916, Train Acc: 0.8450, Val Loss: 0.3870, Val Acc: 0.8431\n",
      "Epoch [18/100], Train Loss: 0.3847, Train Acc: 0.8450, Val Loss: 0.3800, Val Acc: 0.8431\n",
      "Epoch [19/100], Train Loss: 0.3828, Train Acc: 0.8450, Val Loss: 0.3780, Val Acc: 0.8431\n",
      "Epoch [20/100], Train Loss: 0.3767, Train Acc: 0.8450, Val Loss: 0.3668, Val Acc: 0.8431\n",
      "Epoch [21/100], Train Loss: 0.3680, Train Acc: 0.8450, Val Loss: 0.3606, Val Acc: 0.8431\n",
      "Epoch [22/100], Train Loss: 0.3618, Train Acc: 0.8450, Val Loss: 0.3503, Val Acc: 0.8431\n",
      "Epoch [23/100], Train Loss: 0.3517, Train Acc: 0.8450, Val Loss: 0.3370, Val Acc: 0.8431\n",
      "Epoch [24/100], Train Loss: 0.3424, Train Acc: 0.8450, Val Loss: 0.3189, Val Acc: 0.8431\n",
      "Epoch [25/100], Train Loss: 0.3262, Train Acc: 0.8450, Val Loss: 0.3125, Val Acc: 0.8431\n",
      "Epoch [26/100], Train Loss: 0.3179, Train Acc: 0.8450, Val Loss: 0.2819, Val Acc: 0.8431\n",
      "Epoch [27/100], Train Loss: 0.2786, Train Acc: 0.8450, Val Loss: 0.2784, Val Acc: 0.8431\n",
      "Epoch [28/100], Train Loss: 0.2583, Train Acc: 0.8450, Val Loss: 0.1983, Val Acc: 0.8431\n",
      "Epoch [29/100], Train Loss: 0.2734, Train Acc: 0.8450, Val Loss: 0.2644, Val Acc: 0.8431\n",
      "Epoch [30/100], Train Loss: 0.2746, Train Acc: 0.8650, Val Loss: 0.2368, Val Acc: 0.9020\n",
      "Epoch [31/100], Train Loss: 0.2682, Train Acc: 0.8800, Val Loss: 0.2476, Val Acc: 0.9216\n",
      "Epoch [32/100], Train Loss: 0.2607, Train Acc: 0.8900, Val Loss: 0.2152, Val Acc: 0.8431\n",
      "Epoch [33/100], Train Loss: 0.2330, Train Acc: 0.8500, Val Loss: 0.1868, Val Acc: 0.8824\n",
      "Epoch [34/100], Train Loss: 0.1948, Train Acc: 0.9450, Val Loss: 0.2059, Val Acc: 0.9020\n",
      "Epoch [35/100], Train Loss: 0.2424, Train Acc: 0.8750, Val Loss: 0.2308, Val Acc: 0.8824\n",
      "Epoch [36/100], Train Loss: 0.2265, Train Acc: 0.8900, Val Loss: 0.2029, Val Acc: 0.8627\n",
      "Epoch [37/100], Train Loss: 0.1829, Train Acc: 0.9300, Val Loss: 0.1335, Val Acc: 0.9804\n",
      "Epoch [38/100], Train Loss: 0.1369, Train Acc: 0.9850, Val Loss: 0.1056, Val Acc: 0.9412\n",
      "Epoch [39/100], Train Loss: 0.1185, Train Acc: 0.9650, Val Loss: 0.1637, Val Acc: 0.9804\n",
      "Epoch [40/100], Train Loss: 0.0964, Train Acc: 0.9950, Val Loss: 0.0538, Val Acc: 1.0000\n",
      "Epoch [41/100], Train Loss: 0.0774, Train Acc: 0.9950, Val Loss: 0.0419, Val Acc: 1.0000\n",
      "Epoch [42/100], Train Loss: 0.0648, Train Acc: 0.9950, Val Loss: 0.0520, Val Acc: 0.9804\n",
      "Epoch [43/100], Train Loss: 0.0485, Train Acc: 0.9950, Val Loss: 0.0616, Val Acc: 0.9804\n",
      "Epoch [44/100], Train Loss: 0.0351, Train Acc: 0.9950, Val Loss: 0.1116, Val Acc: 0.9804\n",
      "Epoch [45/100], Train Loss: 0.0960, Train Acc: 0.9800, Val Loss: 0.3429, Val Acc: 0.8039\n",
      "Epoch [46/100], Train Loss: 0.1909, Train Acc: 0.9300, Val Loss: 0.0605, Val Acc: 0.9804\n",
      "Epoch [47/100], Train Loss: 0.0164, Train Acc: 1.0000, Val Loss: 0.0137, Val Acc: 1.0000\n",
      "Epoch [48/100], Train Loss: 0.0345, Train Acc: 0.9950, Val Loss: 0.0313, Val Acc: 1.0000\n",
      "Epoch [49/100], Train Loss: 0.0383, Train Acc: 0.9950, Val Loss: 0.0312, Val Acc: 1.0000\n",
      "Epoch [50/100], Train Loss: 0.0344, Train Acc: 0.9950, Val Loss: 0.0122, Val Acc: 1.0000\n",
      "Epoch [51/100], Train Loss: 0.0158, Train Acc: 0.9950, Val Loss: 0.0088, Val Acc: 1.0000\n",
      "Epoch [52/100], Train Loss: 0.0084, Train Acc: 1.0000, Val Loss: 0.0082, Val Acc: 1.0000\n",
      "Epoch [53/100], Train Loss: 0.0077, Train Acc: 1.0000, Val Loss: 0.0079, Val Acc: 1.0000\n",
      "Epoch [54/100], Train Loss: 0.0074, Train Acc: 1.0000, Val Loss: 0.0075, Val Acc: 1.0000\n",
      "Epoch [55/100], Train Loss: 0.0069, Train Acc: 1.0000, Val Loss: 0.0070, Val Acc: 1.0000\n",
      "Epoch [56/100], Train Loss: 0.0064, Train Acc: 1.0000, Val Loss: 0.0064, Val Acc: 1.0000\n",
      "Epoch [57/100], Train Loss: 0.0059, Train Acc: 1.0000, Val Loss: 0.0059, Val Acc: 1.0000\n",
      "Epoch [58/100], Train Loss: 0.0053, Train Acc: 1.0000, Val Loss: 0.0053, Val Acc: 1.0000\n",
      "Epoch [59/100], Train Loss: 0.0048, Train Acc: 1.0000, Val Loss: 0.0049, Val Acc: 1.0000\n",
      "Epoch [60/100], Train Loss: 0.0044, Train Acc: 1.0000, Val Loss: 0.0044, Val Acc: 1.0000\n",
      "Epoch [61/100], Train Loss: 0.0040, Train Acc: 1.0000, Val Loss: 0.0041, Val Acc: 1.0000\n",
      "Epoch [62/100], Train Loss: 0.0036, Train Acc: 1.0000, Val Loss: 0.0037, Val Acc: 1.0000\n",
      "Epoch [63/100], Train Loss: 0.0033, Train Acc: 1.0000, Val Loss: 0.0034, Val Acc: 1.0000\n",
      "Epoch [64/100], Train Loss: 0.0031, Train Acc: 1.0000, Val Loss: 0.0032, Val Acc: 1.0000\n",
      "Epoch [65/100], Train Loss: 0.0028, Train Acc: 1.0000, Val Loss: 0.0030, Val Acc: 1.0000\n",
      "Epoch [66/100], Train Loss: 0.0026, Train Acc: 1.0000, Val Loss: 0.0028, Val Acc: 1.0000\n",
      "Epoch [67/100], Train Loss: 0.0025, Train Acc: 1.0000, Val Loss: 0.0026, Val Acc: 1.0000\n",
      "Epoch [68/100], Train Loss: 0.0023, Train Acc: 1.0000, Val Loss: 0.0025, Val Acc: 1.0000\n",
      "Epoch [69/100], Train Loss: 0.0022, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch [70/100], Train Loss: 0.0021, Train Acc: 1.0000, Val Loss: 0.0023, Val Acc: 1.0000\n",
      "Epoch [71/100], Train Loss: 0.0020, Train Acc: 1.0000, Val Loss: 0.0022, Val Acc: 1.0000\n",
      "Epoch [72/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
      "Epoch [73/100], Train Loss: 0.0018, Train Acc: 1.0000, Val Loss: 0.0020, Val Acc: 1.0000\n",
      "Epoch [74/100], Train Loss: 0.0017, Train Acc: 1.0000, Val Loss: 0.0019, Val Acc: 1.0000\n",
      "Epoch [75/100], Train Loss: 0.0017, Train Acc: 1.0000, Val Loss: 0.0018, Val Acc: 1.0000\n",
      "Epoch [76/100], Train Loss: 0.0016, Train Acc: 1.0000, Val Loss: 0.0017, Val Acc: 1.0000\n",
      "Epoch [77/100], Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0017, Val Acc: 1.0000\n",
      "Epoch [78/100], Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0016, Val Acc: 1.0000\n",
      "Epoch [79/100], Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [80/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [81/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [82/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [83/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [84/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [85/100], Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [86/100], Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [87/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [88/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [89/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [90/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [91/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [92/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [93/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [94/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [95/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [96/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [97/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [98/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [99/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [100/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Finished Training RNNModel\n",
      "Cluster 2, Epoch 1/30, Avg Reward: 0.9984\n",
      "Cluster 2, Epoch 2/30, Avg Reward: 0.9968\n",
      "Cluster 2, Epoch 3/30, Avg Reward: 0.9901\n",
      "Cluster 2, Epoch 4/30, Avg Reward: 1.0076\n",
      "Cluster 2, Epoch 5/30, Avg Reward: 1.0047\n",
      "Cluster 2, Epoch 6/30, Avg Reward: 1.0172\n",
      "Cluster 2, Epoch 7/30, Avg Reward: 1.0028\n",
      "Cluster 2, Epoch 8/30, Avg Reward: 0.9955\n",
      "Cluster 2, Epoch 9/30, Avg Reward: 1.0022\n",
      "Cluster 2, Epoch 10/30, Avg Reward: 0.9982\n",
      "Cluster 2, Epoch 11/30, Avg Reward: 1.0002\n",
      "Cluster 2, Epoch 12/30, Avg Reward: 0.9938\n",
      "Cluster 2, Epoch 13/30, Avg Reward: 0.9957\n",
      "Cluster 2, Epoch 14/30, Avg Reward: 0.9957\n",
      "Cluster 2, Epoch 15/30, Avg Reward: 1.0088\n",
      "Cluster 2, Epoch 16/30, Avg Reward: 0.9930\n",
      "Cluster 2, Epoch 17/30, Avg Reward: 0.9960\n",
      "Cluster 2, Epoch 18/30, Avg Reward: 1.0007\n",
      "Cluster 2, Epoch 19/30, Avg Reward: 1.0114\n",
      "Cluster 2, Epoch 20/30, Avg Reward: 1.0035\n",
      "Cluster 2, Epoch 21/30, Avg Reward: 0.9795\n",
      "Cluster 2, Epoch 22/30, Avg Reward: 0.9913\n",
      "Cluster 2, Epoch 23/30, Avg Reward: 0.9994\n",
      "Cluster 2, Epoch 24/30, Avg Reward: 0.9963\n",
      "Cluster 2, Epoch 25/30, Avg Reward: 0.9957\n",
      "Cluster 2, Epoch 26/30, Avg Reward: 1.0047\n",
      "Cluster 2, Epoch 27/30, Avg Reward: 1.0043\n",
      "Cluster 2, Epoch 28/30, Avg Reward: 0.9946\n",
      "Cluster 2, Epoch 29/30, Avg Reward: 0.9996\n",
      "Cluster 2, Epoch 30/30, Avg Reward: 0.9985\n",
      "Predicting on test set...\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 895 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 593 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 512 l·∫ßn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       855\n",
      "           1       0.94      1.00      0.97      1145\n",
      "\n",
      "    accuracy                           0.96      2000\n",
      "   macro avg       0.97      0.96      0.96      2000\n",
      "weighted avg       0.97      0.96      0.96      2000\n",
      "\n",
      "Accuracy: 0.9645\n",
      "Recall (macro): 0.9586276462626727\n",
      "F1 Score (macro): 0.9633181000119087\n",
      "ROC AUC: 0.9586276462626727\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# DQN Training and Evaluation\n",
    "# =====================\n",
    "models = [\n",
    "    mlp_model_pt,\n",
    "    cnn_model_pt,\n",
    "    rnn_model_pt\n",
    "]\n",
    "\n",
    "dqn = DQNModelSelector(models, n_clusters=3)\n",
    "\n",
    "print(\"Training DQN-based selector with cluster-specific DQNs...\")\n",
    "dqn.train(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_dqn, arms = dqn.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_dqn = np.array([int(x) for x in y_pred_dqn])\n",
    "\n",
    "print(classification_report(y_test, y_pred_dqn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dqn))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dqn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eeb499b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 707 samples\n",
      "Training Arm 0 (MLPModel) on Cluster 0\n",
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/100], Train Loss: 0.6917, Train Acc: 0.5078, Val Loss: 0.6760, Val Acc: 0.6775\n",
      "Epoch [2/100], Train Loss: 0.6675, Train Acc: 0.6775, Val Loss: 0.6542, Val Acc: 0.6775\n",
      "Epoch [3/100], Train Loss: 0.6469, Train Acc: 0.6775, Val Loss: 0.6340, Val Acc: 0.6775\n",
      "Epoch [4/100], Train Loss: 0.6275, Train Acc: 0.6775, Val Loss: 0.6156, Val Acc: 0.6775\n",
      "Epoch [5/100], Train Loss: 0.6105, Train Acc: 0.6775, Val Loss: 0.6005, Val Acc: 0.6775\n",
      "Epoch [6/100], Train Loss: 0.5953, Train Acc: 0.6775, Val Loss: 0.5867, Val Acc: 0.6775\n",
      "Epoch [7/100], Train Loss: 0.5805, Train Acc: 0.6775, Val Loss: 0.5697, Val Acc: 0.6775\n",
      "Epoch [8/100], Train Loss: 0.5621, Train Acc: 0.6803, Val Loss: 0.5482, Val Acc: 0.6846\n",
      "Epoch [9/100], Train Loss: 0.5378, Train Acc: 0.6846, Val Loss: 0.5189, Val Acc: 0.6917\n",
      "Epoch [10/100], Train Loss: 0.5048, Train Acc: 0.6945, Val Loss: 0.4791, Val Acc: 0.7100\n",
      "Epoch [11/100], Train Loss: 0.4616, Train Acc: 0.7171, Val Loss: 0.4310, Val Acc: 0.7369\n",
      "Epoch [12/100], Train Loss: 0.4105, Train Acc: 0.7511, Val Loss: 0.3738, Val Acc: 0.7822\n",
      "Epoch [13/100], Train Loss: 0.3507, Train Acc: 0.8897, Val Loss: 0.3108, Val Acc: 0.9760\n",
      "Epoch [14/100], Train Loss: 0.2863, Train Acc: 0.9788, Val Loss: 0.2463, Val Acc: 0.9844\n",
      "Epoch [15/100], Train Loss: 0.2234, Train Acc: 0.9887, Val Loss: 0.1878, Val Acc: 0.9915\n",
      "Epoch [16/100], Train Loss: 0.1681, Train Acc: 0.9915, Val Loss: 0.1389, Val Acc: 0.9915\n",
      "Epoch [17/100], Train Loss: 0.1240, Train Acc: 0.9915, Val Loss: 0.1016, Val Acc: 0.9929\n",
      "Epoch [18/100], Train Loss: 0.0908, Train Acc: 0.9929, Val Loss: 0.0748, Val Acc: 0.9943\n",
      "Epoch [19/100], Train Loss: 0.0672, Train Acc: 0.9943, Val Loss: 0.0562, Val Acc: 0.9972\n",
      "Epoch [20/100], Train Loss: 0.0511, Train Acc: 0.9972, Val Loss: 0.0433, Val Acc: 0.9972\n",
      "Epoch [21/100], Train Loss: 0.0397, Train Acc: 0.9986, Val Loss: 0.0343, Val Acc: 0.9986\n",
      "Epoch [22/100], Train Loss: 0.0316, Train Acc: 0.9986, Val Loss: 0.0279, Val Acc: 0.9986\n",
      "Epoch [23/100], Train Loss: 0.0261, Train Acc: 0.9986, Val Loss: 0.0231, Val Acc: 1.0000\n",
      "Epoch [24/100], Train Loss: 0.0219, Train Acc: 1.0000, Val Loss: 0.0196, Val Acc: 1.0000\n",
      "Epoch [25/100], Train Loss: 0.0185, Train Acc: 1.0000, Val Loss: 0.0169, Val Acc: 1.0000\n",
      "Epoch [26/100], Train Loss: 0.0161, Train Acc: 1.0000, Val Loss: 0.0146, Val Acc: 1.0000\n",
      "Epoch [27/100], Train Loss: 0.0139, Train Acc: 1.0000, Val Loss: 0.0128, Val Acc: 1.0000\n",
      "Epoch [28/100], Train Loss: 0.0122, Train Acc: 1.0000, Val Loss: 0.0113, Val Acc: 1.0000\n",
      "Epoch [29/100], Train Loss: 0.0109, Train Acc: 1.0000, Val Loss: 0.0101, Val Acc: 1.0000\n",
      "Epoch [30/100], Train Loss: 0.0097, Train Acc: 1.0000, Val Loss: 0.0090, Val Acc: 1.0000\n",
      "Epoch [31/100], Train Loss: 0.0087, Train Acc: 1.0000, Val Loss: 0.0081, Val Acc: 1.0000\n",
      "Epoch [32/100], Train Loss: 0.0078, Train Acc: 1.0000, Val Loss: 0.0074, Val Acc: 1.0000\n",
      "Epoch [33/100], Train Loss: 0.0071, Train Acc: 1.0000, Val Loss: 0.0067, Val Acc: 1.0000\n",
      "Epoch [34/100], Train Loss: 0.0064, Train Acc: 1.0000, Val Loss: 0.0060, Val Acc: 1.0000\n",
      "Epoch [35/100], Train Loss: 0.0059, Train Acc: 1.0000, Val Loss: 0.0056, Val Acc: 1.0000\n",
      "Epoch [36/100], Train Loss: 0.0054, Train Acc: 1.0000, Val Loss: 0.0050, Val Acc: 1.0000\n",
      "Epoch [37/100], Train Loss: 0.0050, Train Acc: 1.0000, Val Loss: 0.0046, Val Acc: 1.0000\n",
      "Epoch [38/100], Train Loss: 0.0045, Train Acc: 1.0000, Val Loss: 0.0042, Val Acc: 1.0000\n",
      "Epoch [39/100], Train Loss: 0.0041, Train Acc: 1.0000, Val Loss: 0.0038, Val Acc: 1.0000\n",
      "Epoch [40/100], Train Loss: 0.0038, Train Acc: 1.0000, Val Loss: 0.0035, Val Acc: 1.0000\n",
      "Epoch [41/100], Train Loss: 0.0035, Train Acc: 1.0000, Val Loss: 0.0032, Val Acc: 1.0000\n",
      "Epoch [42/100], Train Loss: 0.0032, Train Acc: 1.0000, Val Loss: 0.0030, Val Acc: 1.0000\n",
      "Epoch [43/100], Train Loss: 0.0029, Train Acc: 1.0000, Val Loss: 0.0028, Val Acc: 1.0000\n",
      "Epoch [44/100], Train Loss: 0.0027, Train Acc: 1.0000, Val Loss: 0.0026, Val Acc: 1.0000\n",
      "Epoch [45/100], Train Loss: 0.0025, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch [46/100], Train Loss: 0.0023, Train Acc: 1.0000, Val Loss: 0.0022, Val Acc: 1.0000\n",
      "Epoch [47/100], Train Loss: 0.0021, Train Acc: 1.0000, Val Loss: 0.0020, Val Acc: 1.0000\n",
      "Epoch [48/100], Train Loss: 0.0020, Train Acc: 1.0000, Val Loss: 0.0019, Val Acc: 1.0000\n",
      "Epoch [49/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0018, Val Acc: 1.0000\n",
      "Epoch [50/100], Train Loss: 0.0018, Train Acc: 1.0000, Val Loss: 0.0017, Val Acc: 1.0000\n",
      "Epoch [51/100], Train Loss: 0.0016, Train Acc: 1.0000, Val Loss: 0.0016, Val Acc: 1.0000\n",
      "Epoch [52/100], Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [53/100], Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [54/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [55/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [56/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [57/100], Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0011, Val Acc: 1.0000\n",
      "Epoch [58/100], Train Loss: 0.0011, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [59/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0010, Val Acc: 1.0000\n",
      "Epoch [60/100], Train Loss: 0.0010, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [61/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0009, Val Acc: 1.0000\n",
      "Epoch [62/100], Train Loss: 0.0009, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [63/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [64/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0008, Val Acc: 1.0000\n",
      "Epoch [65/100], Train Loss: 0.0008, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [66/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [67/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0007, Val Acc: 1.0000\n",
      "Epoch [68/100], Train Loss: 0.0007, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [69/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [70/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [71/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0006, Val Acc: 1.0000\n",
      "Epoch [72/100], Train Loss: 0.0006, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [73/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [74/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [75/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [76/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0005, Val Acc: 1.0000\n",
      "Epoch [77/100], Train Loss: 0.0005, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [78/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [79/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [80/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [81/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [82/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [83/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [84/100], Train Loss: 0.0004, Train Acc: 1.0000, Val Loss: 0.0004, Val Acc: 1.0000\n",
      "Epoch [85/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [86/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [87/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [88/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [89/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [90/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [91/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [92/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [93/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [94/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [95/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [96/100], Train Loss: 0.0003, Train Acc: 1.0000, Val Loss: 0.0003, Val Acc: 1.0000\n",
      "Epoch [97/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [98/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [99/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Epoch [100/100], Train Loss: 0.0002, Train Acc: 1.0000, Val Loss: 0.0002, Val Acc: 1.0000\n",
      "Finished Training MLPModel\n",
      "Training Arm 1 (CNNModel) on Cluster 0\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.6438, Train Acc: 0.6351, Val Loss: 0.6434, Val Acc: 0.6775\n",
      "Epoch [2/100], Train Loss: 0.6261, Train Acc: 0.6775, Val Loss: 0.6275, Val Acc: 0.6775\n",
      "Epoch [3/100], Train Loss: 0.6286, Train Acc: 0.6775, Val Loss: 0.6217, Val Acc: 0.6775\n",
      "Epoch [4/100], Train Loss: 0.6208, Train Acc: 0.6775, Val Loss: 0.6165, Val Acc: 0.6775\n",
      "Epoch [5/100], Train Loss: 0.6152, Train Acc: 0.6775, Val Loss: 0.6098, Val Acc: 0.6775\n",
      "Epoch [6/100], Train Loss: 0.6076, Train Acc: 0.6775, Val Loss: 0.6003, Val Acc: 0.6775\n",
      "Epoch [7/100], Train Loss: 0.5960, Train Acc: 0.6775, Val Loss: 0.5881, Val Acc: 0.6775\n",
      "Epoch [8/100], Train Loss: 0.5829, Train Acc: 0.6775, Val Loss: 0.5720, Val Acc: 0.6775\n",
      "Epoch [9/100], Train Loss: 0.5634, Train Acc: 0.6775, Val Loss: 0.5492, Val Acc: 0.6775\n",
      "Epoch [10/100], Train Loss: 0.5387, Train Acc: 0.6775, Val Loss: 0.5194, Val Acc: 0.6803\n",
      "Epoch [11/100], Train Loss: 0.5070, Train Acc: 0.6888, Val Loss: 0.4829, Val Acc: 0.6902\n",
      "Epoch [12/100], Train Loss: 0.4698, Train Acc: 0.6902, Val Loss: 0.4401, Val Acc: 0.8854\n",
      "Epoch [13/100], Train Loss: 0.4249, Train Acc: 0.9095, Val Loss: 0.3912, Val Acc: 0.9081\n",
      "Epoch [14/100], Train Loss: 0.3734, Train Acc: 0.9208, Val Loss: 0.3394, Val Acc: 0.9264\n",
      "Epoch [15/100], Train Loss: 0.3194, Train Acc: 0.9279, Val Loss: 0.2878, Val Acc: 0.9562\n",
      "Epoch [16/100], Train Loss: 0.2693, Train Acc: 0.9491, Val Loss: 0.2367, Val Acc: 0.9576\n",
      "Epoch [17/100], Train Loss: 0.2211, Train Acc: 0.9618, Val Loss: 0.1925, Val Acc: 0.9675\n",
      "Epoch [18/100], Train Loss: 0.1792, Train Acc: 0.9717, Val Loss: 0.1555, Val Acc: 0.9788\n",
      "Epoch [19/100], Train Loss: 0.1434, Train Acc: 0.9802, Val Loss: 0.1248, Val Acc: 0.9859\n",
      "Epoch [20/100], Train Loss: 0.1156, Train Acc: 0.9873, Val Loss: 0.0997, Val Acc: 0.9901\n",
      "Epoch [21/100], Train Loss: 0.0929, Train Acc: 0.9929, Val Loss: 0.0803, Val Acc: 0.9929\n",
      "Epoch [22/100], Train Loss: 0.0779, Train Acc: 0.9915, Val Loss: 0.0681, Val Acc: 0.9958\n",
      "Epoch [23/100], Train Loss: 0.0628, Train Acc: 0.9958, Val Loss: 0.0559, Val Acc: 0.9958\n",
      "Epoch [24/100], Train Loss: 0.0525, Train Acc: 0.9958, Val Loss: 0.0458, Val Acc: 0.9986\n",
      "Epoch [25/100], Train Loss: 0.0426, Train Acc: 0.9972, Val Loss: 0.0384, Val Acc: 0.9972\n",
      "Epoch [26/100], Train Loss: 0.0361, Train Acc: 0.9986, Val Loss: 0.0328, Val Acc: 0.9986\n",
      "Epoch [27/100], Train Loss: 0.0311, Train Acc: 0.9986, Val Loss: 0.0285, Val Acc: 0.9986\n",
      "Epoch [28/100], Train Loss: 0.0274, Train Acc: 0.9986, Val Loss: 0.0250, Val Acc: 0.9986\n",
      "Epoch [29/100], Train Loss: 0.0240, Train Acc: 0.9986, Val Loss: 0.0222, Val Acc: 0.9986\n",
      "Epoch [30/100], Train Loss: 0.0216, Train Acc: 0.9986, Val Loss: 0.0198, Val Acc: 0.9986\n",
      "Epoch [31/100], Train Loss: 0.0196, Train Acc: 0.9986, Val Loss: 0.0179, Val Acc: 0.9986\n",
      "Epoch [32/100], Train Loss: 0.0172, Train Acc: 0.9986, Val Loss: 0.0164, Val Acc: 0.9986\n",
      "Epoch [33/100], Train Loss: 0.0163, Train Acc: 0.9986, Val Loss: 0.0148, Val Acc: 0.9986\n",
      "Epoch [34/100], Train Loss: 0.0151, Train Acc: 0.9986, Val Loss: 0.0134, Val Acc: 1.0000\n",
      "Epoch [35/100], Train Loss: 0.0142, Train Acc: 0.9986, Val Loss: 0.0128, Val Acc: 0.9986\n",
      "Epoch [36/100], Train Loss: 0.0145, Train Acc: 0.9986, Val Loss: 0.0120, Val Acc: 1.0000\n",
      "Epoch [37/100], Train Loss: 0.0117, Train Acc: 1.0000, Val Loss: 0.0115, Val Acc: 0.9986\n",
      "Epoch [38/100], Train Loss: 0.0106, Train Acc: 0.9986, Val Loss: 0.0104, Val Acc: 1.0000\n",
      "Epoch [39/100], Train Loss: 0.0100, Train Acc: 1.0000, Val Loss: 0.0093, Val Acc: 1.0000\n",
      "Epoch [40/100], Train Loss: 0.0095, Train Acc: 1.0000, Val Loss: 0.0088, Val Acc: 1.0000\n",
      "Epoch [41/100], Train Loss: 0.0088, Train Acc: 1.0000, Val Loss: 0.0083, Val Acc: 1.0000\n",
      "Epoch [42/100], Train Loss: 0.0083, Train Acc: 1.0000, Val Loss: 0.0078, Val Acc: 1.0000\n",
      "Epoch [43/100], Train Loss: 0.0076, Train Acc: 1.0000, Val Loss: 0.0074, Val Acc: 1.0000\n",
      "Epoch [44/100], Train Loss: 0.0073, Train Acc: 1.0000, Val Loss: 0.0069, Val Acc: 1.0000\n",
      "Epoch [45/100], Train Loss: 0.0071, Train Acc: 1.0000, Val Loss: 0.0066, Val Acc: 1.0000\n",
      "Epoch [46/100], Train Loss: 0.0065, Train Acc: 1.0000, Val Loss: 0.0066, Val Acc: 1.0000\n",
      "Epoch [47/100], Train Loss: 0.0063, Train Acc: 1.0000, Val Loss: 0.0059, Val Acc: 1.0000\n",
      "Epoch [48/100], Train Loss: 0.0060, Train Acc: 1.0000, Val Loss: 0.0058, Val Acc: 1.0000\n",
      "Epoch [49/100], Train Loss: 0.0056, Train Acc: 1.0000, Val Loss: 0.0054, Val Acc: 1.0000\n",
      "Epoch [50/100], Train Loss: 0.0053, Train Acc: 1.0000, Val Loss: 0.0051, Val Acc: 1.0000\n",
      "Epoch [51/100], Train Loss: 0.0051, Train Acc: 1.0000, Val Loss: 0.0049, Val Acc: 1.0000\n",
      "Epoch [52/100], Train Loss: 0.0049, Train Acc: 1.0000, Val Loss: 0.0047, Val Acc: 1.0000\n",
      "Epoch [53/100], Train Loss: 0.0046, Train Acc: 1.0000, Val Loss: 0.0045, Val Acc: 1.0000\n",
      "Epoch [54/100], Train Loss: 0.0044, Train Acc: 1.0000, Val Loss: 0.0043, Val Acc: 1.0000\n",
      "Epoch [55/100], Train Loss: 0.0042, Train Acc: 1.0000, Val Loss: 0.0041, Val Acc: 1.0000\n",
      "Epoch [56/100], Train Loss: 0.0040, Train Acc: 1.0000, Val Loss: 0.0039, Val Acc: 1.0000\n",
      "Epoch [57/100], Train Loss: 0.0039, Train Acc: 1.0000, Val Loss: 0.0038, Val Acc: 1.0000\n",
      "Epoch [58/100], Train Loss: 0.0039, Train Acc: 1.0000, Val Loss: 0.0037, Val Acc: 1.0000\n",
      "Epoch [59/100], Train Loss: 0.0036, Train Acc: 1.0000, Val Loss: 0.0036, Val Acc: 1.0000\n",
      "Epoch [60/100], Train Loss: 0.0036, Train Acc: 1.0000, Val Loss: 0.0034, Val Acc: 1.0000\n",
      "Epoch [61/100], Train Loss: 0.0035, Train Acc: 1.0000, Val Loss: 0.0033, Val Acc: 1.0000\n",
      "Epoch [62/100], Train Loss: 0.0032, Train Acc: 1.0000, Val Loss: 0.0033, Val Acc: 1.0000\n",
      "Epoch [63/100], Train Loss: 0.0032, Train Acc: 1.0000, Val Loss: 0.0030, Val Acc: 1.0000\n",
      "Epoch [64/100], Train Loss: 0.0032, Train Acc: 1.0000, Val Loss: 0.0030, Val Acc: 1.0000\n",
      "Epoch [65/100], Train Loss: 0.0029, Train Acc: 1.0000, Val Loss: 0.0030, Val Acc: 1.0000\n",
      "Epoch [66/100], Train Loss: 0.0029, Train Acc: 1.0000, Val Loss: 0.0027, Val Acc: 1.0000\n",
      "Epoch [67/100], Train Loss: 0.0028, Train Acc: 1.0000, Val Loss: 0.0027, Val Acc: 1.0000\n",
      "Epoch [68/100], Train Loss: 0.0026, Train Acc: 1.0000, Val Loss: 0.0026, Val Acc: 1.0000\n",
      "Epoch [69/100], Train Loss: 0.0026, Train Acc: 1.0000, Val Loss: 0.0025, Val Acc: 1.0000\n",
      "Epoch [70/100], Train Loss: 0.0025, Train Acc: 1.0000, Val Loss: 0.0025, Val Acc: 1.0000\n",
      "Epoch [71/100], Train Loss: 0.0025, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch [72/100], Train Loss: 0.0025, Train Acc: 1.0000, Val Loss: 0.0024, Val Acc: 1.0000\n",
      "Epoch [73/100], Train Loss: 0.0023, Train Acc: 1.0000, Val Loss: 0.0023, Val Acc: 1.0000\n",
      "Epoch [74/100], Train Loss: 0.0023, Train Acc: 1.0000, Val Loss: 0.0022, Val Acc: 1.0000\n",
      "Epoch [75/100], Train Loss: 0.0021, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
      "Epoch [76/100], Train Loss: 0.0021, Train Acc: 1.0000, Val Loss: 0.0021, Val Acc: 1.0000\n",
      "Epoch [77/100], Train Loss: 0.0020, Train Acc: 1.0000, Val Loss: 0.0020, Val Acc: 1.0000\n",
      "Epoch [78/100], Train Loss: 0.0020, Train Acc: 1.0000, Val Loss: 0.0019, Val Acc: 1.0000\n",
      "Epoch [79/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0019, Val Acc: 1.0000\n",
      "Epoch [80/100], Train Loss: 0.0019, Train Acc: 1.0000, Val Loss: 0.0018, Val Acc: 1.0000\n",
      "Epoch [81/100], Train Loss: 0.0018, Train Acc: 1.0000, Val Loss: 0.0018, Val Acc: 1.0000\n",
      "Epoch [82/100], Train Loss: 0.0018, Train Acc: 1.0000, Val Loss: 0.0017, Val Acc: 1.0000\n",
      "Epoch [83/100], Train Loss: 0.0017, Train Acc: 1.0000, Val Loss: 0.0017, Val Acc: 1.0000\n",
      "Epoch [84/100], Train Loss: 0.0017, Train Acc: 1.0000, Val Loss: 0.0016, Val Acc: 1.0000\n",
      "Epoch [85/100], Train Loss: 0.0016, Train Acc: 1.0000, Val Loss: 0.0016, Val Acc: 1.0000\n",
      "Epoch [86/100], Train Loss: 0.0016, Train Acc: 1.0000, Val Loss: 0.0016, Val Acc: 1.0000\n",
      "Epoch [87/100], Train Loss: 0.0016, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [88/100], Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [89/100], Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0015, Val Acc: 1.0000\n",
      "Epoch [90/100], Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [91/100], Train Loss: 0.0015, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [92/100], Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0014, Val Acc: 1.0000\n",
      "Epoch [93/100], Train Loss: 0.0014, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [94/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [95/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0013, Val Acc: 1.0000\n",
      "Epoch [96/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [97/100], Train Loss: 0.0013, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [98/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [99/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Epoch [100/100], Train Loss: 0.0012, Train Acc: 1.0000, Val Loss: 0.0012, Val Acc: 1.0000\n",
      "Finished Training CNNModel\n",
      "Training Arm 2 (RNNModel) on Cluster 0\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.6637, Train Acc: 0.6775, Val Loss: 0.6582, Val Acc: 0.6775\n",
      "Epoch [2/100], Train Loss: 0.6548, Train Acc: 0.6775, Val Loss: 0.6501, Val Acc: 0.6775\n",
      "Epoch [3/100], Train Loss: 0.6463, Train Acc: 0.6775, Val Loss: 0.6403, Val Acc: 0.6775\n",
      "Epoch [4/100], Train Loss: 0.6372, Train Acc: 0.6775, Val Loss: 0.6287, Val Acc: 0.6775\n",
      "Epoch [5/100], Train Loss: 0.6310, Train Acc: 0.6775, Val Loss: 0.6293, Val Acc: 0.6775\n",
      "Epoch [6/100], Train Loss: 0.6291, Train Acc: 0.6775, Val Loss: 0.6300, Val Acc: 0.6775\n",
      "Epoch [7/100], Train Loss: 0.6302, Train Acc: 0.6775, Val Loss: 0.6294, Val Acc: 0.6775\n",
      "Epoch [8/100], Train Loss: 0.6292, Train Acc: 0.6775, Val Loss: 0.6285, Val Acc: 0.6775\n",
      "Epoch [9/100], Train Loss: 0.6288, Train Acc: 0.6775, Val Loss: 0.6285, Val Acc: 0.6775\n",
      "Epoch [10/100], Train Loss: 0.6290, Train Acc: 0.6775, Val Loss: 0.6283, Val Acc: 0.6775\n",
      "Epoch [11/100], Train Loss: 0.6289, Train Acc: 0.6775, Val Loss: 0.6284, Val Acc: 0.6775\n",
      "Epoch [12/100], Train Loss: 0.6285, Train Acc: 0.6775, Val Loss: 0.6282, Val Acc: 0.6775\n",
      "Epoch [13/100], Train Loss: 0.6285, Train Acc: 0.6775, Val Loss: 0.6282, Val Acc: 0.6775\n",
      "Epoch [14/100], Train Loss: 0.6281, Train Acc: 0.6775, Val Loss: 0.6282, Val Acc: 0.6775\n",
      "Epoch [15/100], Train Loss: 0.6282, Train Acc: 0.6775, Val Loss: 0.6284, Val Acc: 0.6775\n",
      "Epoch [16/100], Train Loss: 0.6290, Train Acc: 0.6775, Val Loss: 0.6283, Val Acc: 0.6775\n",
      "Epoch [17/100], Train Loss: 0.6281, Train Acc: 0.6775, Val Loss: 0.6286, Val Acc: 0.6775\n",
      "Epoch [18/100], Train Loss: 0.6287, Train Acc: 0.6775, Val Loss: 0.6286, Val Acc: 0.6775\n",
      "Epoch [19/100], Train Loss: 0.6285, Train Acc: 0.6775, Val Loss: 0.6280, Val Acc: 0.6775\n",
      "Epoch [20/100], Train Loss: 0.6285, Train Acc: 0.6775, Val Loss: 0.6279, Val Acc: 0.6775\n",
      "Epoch [21/100], Train Loss: 0.6281, Train Acc: 0.6775, Val Loss: 0.6278, Val Acc: 0.6775\n",
      "Epoch [22/100], Train Loss: 0.6279, Train Acc: 0.6775, Val Loss: 0.6277, Val Acc: 0.6775\n",
      "Epoch [23/100], Train Loss: 0.6277, Train Acc: 0.6775, Val Loss: 0.6275, Val Acc: 0.6775\n",
      "Epoch [24/100], Train Loss: 0.6278, Train Acc: 0.6775, Val Loss: 0.6274, Val Acc: 0.6775\n",
      "Epoch [25/100], Train Loss: 0.6277, Train Acc: 0.6775, Val Loss: 0.6272, Val Acc: 0.6775\n",
      "Epoch [26/100], Train Loss: 0.6280, Train Acc: 0.6775, Val Loss: 0.6270, Val Acc: 0.6775\n",
      "Epoch [27/100], Train Loss: 0.6275, Train Acc: 0.6775, Val Loss: 0.6270, Val Acc: 0.6775\n",
      "Epoch [28/100], Train Loss: 0.6272, Train Acc: 0.6775, Val Loss: 0.6266, Val Acc: 0.6775\n",
      "Epoch [29/100], Train Loss: 0.6269, Train Acc: 0.6775, Val Loss: 0.6262, Val Acc: 0.6775\n",
      "Epoch [30/100], Train Loss: 0.6262, Train Acc: 0.6775, Val Loss: 0.6256, Val Acc: 0.6775\n",
      "Epoch [31/100], Train Loss: 0.6259, Train Acc: 0.6775, Val Loss: 0.6249, Val Acc: 0.6775\n",
      "Epoch [32/100], Train Loss: 0.6267, Train Acc: 0.6775, Val Loss: 0.6256, Val Acc: 0.6775\n",
      "Epoch [33/100], Train Loss: 0.6274, Train Acc: 0.6775, Val Loss: 0.6284, Val Acc: 0.6775\n",
      "Epoch [34/100], Train Loss: 0.6266, Train Acc: 0.6775, Val Loss: 0.6231, Val Acc: 0.6775\n",
      "Epoch [35/100], Train Loss: 0.6253, Train Acc: 0.6775, Val Loss: 0.6239, Val Acc: 0.6775\n",
      "Epoch [36/100], Train Loss: 0.6247, Train Acc: 0.6775, Val Loss: 0.6223, Val Acc: 0.6775\n",
      "Epoch [37/100], Train Loss: 0.6217, Train Acc: 0.6775, Val Loss: 0.6201, Val Acc: 0.6775\n",
      "Epoch [38/100], Train Loss: 0.6230, Train Acc: 0.6775, Val Loss: 0.6248, Val Acc: 0.6775\n",
      "Epoch [39/100], Train Loss: 0.6254, Train Acc: 0.6775, Val Loss: 0.6195, Val Acc: 0.6775\n",
      "Epoch [40/100], Train Loss: 0.6265, Train Acc: 0.6775, Val Loss: 0.6294, Val Acc: 0.6775\n",
      "Epoch [41/100], Train Loss: 0.6290, Train Acc: 0.6775, Val Loss: 0.6270, Val Acc: 0.6775\n",
      "Epoch [42/100], Train Loss: 0.6253, Train Acc: 0.6775, Val Loss: 0.6233, Val Acc: 0.6775\n",
      "Epoch [43/100], Train Loss: 0.6237, Train Acc: 0.6775, Val Loss: 0.6231, Val Acc: 0.6775\n",
      "Epoch [44/100], Train Loss: 0.6226, Train Acc: 0.6775, Val Loss: 0.6207, Val Acc: 0.6775\n",
      "Epoch [45/100], Train Loss: 0.6206, Train Acc: 0.6775, Val Loss: 0.6177, Val Acc: 0.6775\n",
      "Epoch [46/100], Train Loss: 0.6189, Train Acc: 0.6775, Val Loss: 0.6129, Val Acc: 0.6775\n",
      "Epoch [47/100], Train Loss: 0.6174, Train Acc: 0.6775, Val Loss: 0.6079, Val Acc: 0.6775\n",
      "Epoch [48/100], Train Loss: 0.6203, Train Acc: 0.6775, Val Loss: 0.6318, Val Acc: 0.6775\n",
      "Epoch [49/100], Train Loss: 0.6325, Train Acc: 0.6775, Val Loss: 0.6318, Val Acc: 0.6775\n",
      "Epoch [50/100], Train Loss: 0.6310, Train Acc: 0.6775, Val Loss: 0.6278, Val Acc: 0.6775\n",
      "Epoch [51/100], Train Loss: 0.6266, Train Acc: 0.6775, Val Loss: 0.6234, Val Acc: 0.6775\n",
      "Epoch [52/100], Train Loss: 0.6223, Train Acc: 0.6775, Val Loss: 0.6195, Val Acc: 0.6775\n",
      "Epoch [53/100], Train Loss: 0.6190, Train Acc: 0.6775, Val Loss: 0.6169, Val Acc: 0.6775\n",
      "Epoch [54/100], Train Loss: 0.6156, Train Acc: 0.6775, Val Loss: 0.6128, Val Acc: 0.6775\n",
      "Epoch [55/100], Train Loss: 0.6102, Train Acc: 0.6775, Val Loss: 0.6041, Val Acc: 0.6775\n",
      "Epoch [56/100], Train Loss: 0.6013, Train Acc: 0.6775, Val Loss: 0.5946, Val Acc: 0.6775\n",
      "Epoch [57/100], Train Loss: 0.5944, Train Acc: 0.6775, Val Loss: 0.5859, Val Acc: 0.6775\n",
      "Epoch [58/100], Train Loss: 0.5810, Train Acc: 0.6775, Val Loss: 0.5772, Val Acc: 0.6775\n",
      "Epoch [59/100], Train Loss: 0.5678, Train Acc: 0.6775, Val Loss: 0.5489, Val Acc: 0.6775\n",
      "Epoch [60/100], Train Loss: 0.5389, Train Acc: 0.6775, Val Loss: 0.5248, Val Acc: 0.6789\n",
      "Epoch [61/100], Train Loss: 0.5115, Train Acc: 0.7454, Val Loss: 0.4867, Val Acc: 0.6959\n",
      "Epoch [62/100], Train Loss: 0.5133, Train Acc: 0.7482, Val Loss: 0.5147, Val Acc: 0.8939\n",
      "Epoch [63/100], Train Loss: 0.4888, Train Acc: 0.8812, Val Loss: 0.4643, Val Acc: 0.9095\n",
      "Epoch [64/100], Train Loss: 0.4417, Train Acc: 0.8925, Val Loss: 0.4187, Val Acc: 0.8953\n",
      "Epoch [65/100], Train Loss: 0.4082, Train Acc: 0.9024, Val Loss: 0.3902, Val Acc: 0.9081\n",
      "Epoch [66/100], Train Loss: 0.3835, Train Acc: 0.9066, Val Loss: 0.3687, Val Acc: 0.9038\n",
      "Epoch [67/100], Train Loss: 0.3521, Train Acc: 0.9081, Val Loss: 0.3202, Val Acc: 0.9123\n",
      "Epoch [68/100], Train Loss: 0.3347, Train Acc: 0.9081, Val Loss: 0.3195, Val Acc: 0.9038\n",
      "Epoch [69/100], Train Loss: 0.3441, Train Acc: 0.9010, Val Loss: 0.3263, Val Acc: 0.8996\n",
      "Epoch [70/100], Train Loss: 0.3223, Train Acc: 0.9038, Val Loss: 0.3095, Val Acc: 0.9180\n",
      "Epoch [71/100], Train Loss: 0.2964, Train Acc: 0.9109, Val Loss: 0.2930, Val Acc: 0.9066\n",
      "Epoch [72/100], Train Loss: 0.2855, Train Acc: 0.9066, Val Loss: 0.2697, Val Acc: 0.9180\n",
      "Epoch [73/100], Train Loss: 0.2618, Train Acc: 0.9137, Val Loss: 0.2485, Val Acc: 0.9109\n",
      "Epoch [74/100], Train Loss: 0.2482, Train Acc: 0.9137, Val Loss: 0.2250, Val Acc: 0.9180\n",
      "Epoch [75/100], Train Loss: 0.3102, Train Acc: 0.9010, Val Loss: 0.3325, Val Acc: 0.9010\n",
      "Epoch [76/100], Train Loss: 0.4111, Train Acc: 0.8557, Val Loss: 0.8288, Val Acc: 0.6096\n",
      "Epoch [77/100], Train Loss: 0.5214, Train Acc: 0.8204, Val Loss: 0.3978, Val Acc: 0.8670\n",
      "Epoch [78/100], Train Loss: 0.3604, Train Acc: 0.8897, Val Loss: 0.3258, Val Acc: 0.9222\n",
      "Epoch [79/100], Train Loss: 0.3525, Train Acc: 0.9222, Val Loss: 0.3196, Val Acc: 0.9222\n",
      "Epoch [80/100], Train Loss: 0.3080, Train Acc: 0.9222, Val Loss: 0.3017, Val Acc: 0.9165\n",
      "Epoch [81/100], Train Loss: 0.2924, Train Acc: 0.9151, Val Loss: 0.2759, Val Acc: 0.9208\n",
      "Epoch [82/100], Train Loss: 0.2688, Train Acc: 0.9208, Val Loss: 0.2524, Val Acc: 0.9236\n",
      "Epoch [83/100], Train Loss: 0.2469, Train Acc: 0.9236, Val Loss: 0.2392, Val Acc: 0.9236\n",
      "Epoch [84/100], Train Loss: 0.2357, Train Acc: 0.9236, Val Loss: 0.2264, Val Acc: 0.9250\n",
      "Epoch [85/100], Train Loss: 0.2208, Train Acc: 0.9264, Val Loss: 0.2081, Val Acc: 0.9321\n",
      "Epoch [86/100], Train Loss: 0.1994, Train Acc: 0.9335, Val Loss: 0.1698, Val Acc: 0.9519\n",
      "Epoch [87/100], Train Loss: 0.1654, Train Acc: 0.9533, Val Loss: 0.2744, Val Acc: 0.9151\n",
      "Epoch [88/100], Train Loss: 0.3531, Train Acc: 0.8543, Val Loss: 0.7413, Val Acc: 0.6648\n",
      "Epoch [89/100], Train Loss: 0.5823, Train Acc: 0.7369, Val Loss: 0.4613, Val Acc: 0.8303\n",
      "Epoch [90/100], Train Loss: 0.4883, Train Acc: 0.7963, Val Loss: 0.5053, Val Acc: 0.6931\n",
      "Epoch [91/100], Train Loss: 0.4562, Train Acc: 0.7949, Val Loss: 0.4598, Val Acc: 0.7086\n",
      "Epoch [92/100], Train Loss: 0.4050, Train Acc: 0.8274, Val Loss: 0.3489, Val Acc: 0.8883\n",
      "Epoch [93/100], Train Loss: 0.3087, Train Acc: 0.8868, Val Loss: 0.2687, Val Acc: 0.9137\n",
      "Epoch [94/100], Train Loss: 0.2437, Train Acc: 0.9293, Val Loss: 0.2167, Val Acc: 0.9349\n",
      "Epoch [95/100], Train Loss: 0.2289, Train Acc: 0.9321, Val Loss: 0.2167, Val Acc: 0.9406\n",
      "Epoch [96/100], Train Loss: 0.2114, Train Acc: 0.9378, Val Loss: 0.2130, Val Acc: 0.9321\n",
      "Epoch [97/100], Train Loss: 0.2005, Train Acc: 0.9392, Val Loss: 0.1817, Val Acc: 0.9491\n",
      "Epoch [98/100], Train Loss: 0.1849, Train Acc: 0.9491, Val Loss: 0.1695, Val Acc: 0.9519\n",
      "Epoch [99/100], Train Loss: 0.1737, Train Acc: 0.9519, Val Loss: 0.1595, Val Acc: 0.9533\n",
      "Epoch [100/100], Train Loss: 0.1572, Train Acc: 0.9519, Val Loss: 0.1476, Val Acc: 0.9547\n",
      "Finished Training RNNModel\n",
      "Cluster 1: 85 samples\n",
      "Training Arm 0 (MLPModel) on Cluster 1\n",
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/100], Train Loss: 3.4787, Train Acc: 0.3765, Val Loss: 3.1732, Val Acc: 0.3765\n",
      "Epoch [2/100], Train Loss: 3.1732, Train Acc: 0.3765, Val Loss: 2.8615, Val Acc: 0.3765\n",
      "Epoch [3/100], Train Loss: 2.8615, Train Acc: 0.3765, Val Loss: 2.5545, Val Acc: 0.3765\n",
      "Epoch [4/100], Train Loss: 2.5545, Train Acc: 0.3765, Val Loss: 2.2476, Val Acc: 0.3765\n",
      "Epoch [5/100], Train Loss: 2.2476, Train Acc: 0.3765, Val Loss: 1.9413, Val Acc: 0.3765\n",
      "Epoch [6/100], Train Loss: 1.9413, Train Acc: 0.3765, Val Loss: 1.6417, Val Acc: 0.3765\n",
      "Epoch [7/100], Train Loss: 1.6417, Train Acc: 0.3765, Val Loss: 1.3594, Val Acc: 0.3765\n",
      "Epoch [8/100], Train Loss: 1.3594, Train Acc: 0.3765, Val Loss: 1.1023, Val Acc: 0.3765\n",
      "Epoch [9/100], Train Loss: 1.1023, Train Acc: 0.3765, Val Loss: 0.8876, Val Acc: 0.3765\n",
      "Epoch [10/100], Train Loss: 0.8876, Train Acc: 0.3765, Val Loss: 0.7285, Val Acc: 0.3765\n",
      "Epoch [11/100], Train Loss: 0.7285, Train Acc: 0.3765, Val Loss: 0.6286, Val Acc: 0.7412\n",
      "Epoch [12/100], Train Loss: 0.6286, Train Acc: 0.7412, Val Loss: 0.5830, Val Acc: 0.7294\n",
      "Epoch [13/100], Train Loss: 0.5830, Train Acc: 0.7294, Val Loss: 0.5811, Val Acc: 0.7059\n",
      "Epoch [14/100], Train Loss: 0.5811, Train Acc: 0.7059, Val Loss: 0.6066, Val Acc: 0.7059\n",
      "Epoch [15/100], Train Loss: 0.6066, Train Acc: 0.7059, Val Loss: 0.6446, Val Acc: 0.7059\n",
      "Epoch [16/100], Train Loss: 0.6446, Train Acc: 0.7059, Val Loss: 0.6841, Val Acc: 0.6941\n",
      "Epoch [17/100], Train Loss: 0.6841, Train Acc: 0.6941, Val Loss: 0.7182, Val Acc: 0.6941\n",
      "Epoch [18/100], Train Loss: 0.7182, Train Acc: 0.6941, Val Loss: 0.7432, Val Acc: 0.6941\n",
      "Epoch [19/100], Train Loss: 0.7432, Train Acc: 0.6941, Val Loss: 0.7576, Val Acc: 0.7059\n",
      "Epoch [20/100], Train Loss: 0.7576, Train Acc: 0.7059, Val Loss: 0.7620, Val Acc: 0.7059\n",
      "Epoch [21/100], Train Loss: 0.7620, Train Acc: 0.7059, Val Loss: 0.7573, Val Acc: 0.7059\n",
      "Epoch [22/100], Train Loss: 0.7573, Train Acc: 0.7059, Val Loss: 0.7447, Val Acc: 0.7059\n",
      "Epoch [23/100], Train Loss: 0.7447, Train Acc: 0.7059, Val Loss: 0.7257, Val Acc: 0.7059\n",
      "Epoch [24/100], Train Loss: 0.7257, Train Acc: 0.7059, Val Loss: 0.7005, Val Acc: 0.7059\n",
      "Epoch [25/100], Train Loss: 0.7005, Train Acc: 0.7059, Val Loss: 0.6723, Val Acc: 0.7176\n",
      "Epoch [26/100], Train Loss: 0.6723, Train Acc: 0.7176, Val Loss: 0.6430, Val Acc: 0.7294\n",
      "Epoch [27/100], Train Loss: 0.6430, Train Acc: 0.7294, Val Loss: 0.6144, Val Acc: 0.7294\n",
      "Epoch [28/100], Train Loss: 0.6144, Train Acc: 0.7294, Val Loss: 0.5884, Val Acc: 0.7294\n",
      "Epoch [29/100], Train Loss: 0.5884, Train Acc: 0.7294, Val Loss: 0.5664, Val Acc: 0.7294\n",
      "Epoch [30/100], Train Loss: 0.5664, Train Acc: 0.7294, Val Loss: 0.5497, Val Acc: 0.7412\n",
      "Epoch [31/100], Train Loss: 0.5497, Train Acc: 0.7412, Val Loss: 0.5390, Val Acc: 0.7412\n",
      "Epoch [32/100], Train Loss: 0.5390, Train Acc: 0.7412, Val Loss: 0.5343, Val Acc: 0.7412\n",
      "Epoch [33/100], Train Loss: 0.5343, Train Acc: 0.7412, Val Loss: 0.5350, Val Acc: 0.7412\n",
      "Epoch [34/100], Train Loss: 0.5350, Train Acc: 0.7412, Val Loss: 0.5396, Val Acc: 0.7529\n",
      "Epoch [35/100], Train Loss: 0.5396, Train Acc: 0.7529, Val Loss: 0.5464, Val Acc: 0.7529\n",
      "Epoch [36/100], Train Loss: 0.5464, Train Acc: 0.7529, Val Loss: 0.5534, Val Acc: 0.7647\n",
      "Epoch [37/100], Train Loss: 0.5534, Train Acc: 0.7647, Val Loss: 0.5592, Val Acc: 0.7647\n",
      "Epoch [38/100], Train Loss: 0.5592, Train Acc: 0.7647, Val Loss: 0.5625, Val Acc: 0.7647\n",
      "Epoch [39/100], Train Loss: 0.5625, Train Acc: 0.7647, Val Loss: 0.5628, Val Acc: 0.7647\n",
      "Epoch [40/100], Train Loss: 0.5628, Train Acc: 0.7647, Val Loss: 0.5603, Val Acc: 0.7647\n",
      "Epoch [41/100], Train Loss: 0.5603, Train Acc: 0.7647, Val Loss: 0.5555, Val Acc: 0.7647\n",
      "Epoch [42/100], Train Loss: 0.5555, Train Acc: 0.7647, Val Loss: 0.5495, Val Acc: 0.7647\n",
      "Epoch [43/100], Train Loss: 0.5495, Train Acc: 0.7647, Val Loss: 0.5431, Val Acc: 0.7647\n",
      "Epoch [44/100], Train Loss: 0.5431, Train Acc: 0.7647, Val Loss: 0.5369, Val Acc: 0.7647\n",
      "Epoch [45/100], Train Loss: 0.5369, Train Acc: 0.7647, Val Loss: 0.5319, Val Acc: 0.7529\n",
      "Epoch [46/100], Train Loss: 0.5319, Train Acc: 0.7529, Val Loss: 0.5284, Val Acc: 0.7529\n",
      "Epoch [47/100], Train Loss: 0.5284, Train Acc: 0.7529, Val Loss: 0.5263, Val Acc: 0.7529\n",
      "Epoch [48/100], Train Loss: 0.5263, Train Acc: 0.7529, Val Loss: 0.5256, Val Acc: 0.7529\n",
      "Epoch [49/100], Train Loss: 0.5256, Train Acc: 0.7529, Val Loss: 0.5258, Val Acc: 0.7529\n",
      "Epoch [50/100], Train Loss: 0.5258, Train Acc: 0.7529, Val Loss: 0.5267, Val Acc: 0.7412\n",
      "Epoch [51/100], Train Loss: 0.5267, Train Acc: 0.7412, Val Loss: 0.5278, Val Acc: 0.7412\n",
      "Epoch [52/100], Train Loss: 0.5278, Train Acc: 0.7412, Val Loss: 0.5287, Val Acc: 0.7412\n",
      "Epoch [53/100], Train Loss: 0.5287, Train Acc: 0.7412, Val Loss: 0.5293, Val Acc: 0.7412\n",
      "Epoch [54/100], Train Loss: 0.5293, Train Acc: 0.7412, Val Loss: 0.5295, Val Acc: 0.7412\n",
      "Epoch [55/100], Train Loss: 0.5295, Train Acc: 0.7412, Val Loss: 0.5291, Val Acc: 0.7412\n",
      "Epoch [56/100], Train Loss: 0.5291, Train Acc: 0.7412, Val Loss: 0.5282, Val Acc: 0.7412\n",
      "Epoch [57/100], Train Loss: 0.5282, Train Acc: 0.7412, Val Loss: 0.5270, Val Acc: 0.7529\n",
      "Epoch [58/100], Train Loss: 0.5270, Train Acc: 0.7529, Val Loss: 0.5256, Val Acc: 0.7529\n",
      "Epoch [59/100], Train Loss: 0.5256, Train Acc: 0.7529, Val Loss: 0.5242, Val Acc: 0.7529\n",
      "Epoch [60/100], Train Loss: 0.5242, Train Acc: 0.7529, Val Loss: 0.5230, Val Acc: 0.7529\n",
      "Epoch [61/100], Train Loss: 0.5230, Train Acc: 0.7529, Val Loss: 0.5221, Val Acc: 0.7529\n",
      "Epoch [62/100], Train Loss: 0.5221, Train Acc: 0.7529, Val Loss: 0.5216, Val Acc: 0.7529\n",
      "Epoch [63/100], Train Loss: 0.5216, Train Acc: 0.7529, Val Loss: 0.5214, Val Acc: 0.7529\n",
      "Epoch [64/100], Train Loss: 0.5214, Train Acc: 0.7529, Val Loss: 0.5214, Val Acc: 0.7529\n",
      "Epoch [65/100], Train Loss: 0.5214, Train Acc: 0.7529, Val Loss: 0.5216, Val Acc: 0.7529\n",
      "Epoch [66/100], Train Loss: 0.5216, Train Acc: 0.7529, Val Loss: 0.5217, Val Acc: 0.7529\n",
      "Epoch [67/100], Train Loss: 0.5217, Train Acc: 0.7529, Val Loss: 0.5218, Val Acc: 0.7647\n",
      "Epoch [68/100], Train Loss: 0.5218, Train Acc: 0.7647, Val Loss: 0.5216, Val Acc: 0.7647\n",
      "Epoch [69/100], Train Loss: 0.5216, Train Acc: 0.7647, Val Loss: 0.5213, Val Acc: 0.7647\n",
      "Epoch [70/100], Train Loss: 0.5213, Train Acc: 0.7647, Val Loss: 0.5209, Val Acc: 0.7647\n",
      "Epoch [71/100], Train Loss: 0.5209, Train Acc: 0.7647, Val Loss: 0.5203, Val Acc: 0.7647\n",
      "Epoch [72/100], Train Loss: 0.5203, Train Acc: 0.7647, Val Loss: 0.5198, Val Acc: 0.7647\n",
      "Epoch [73/100], Train Loss: 0.5198, Train Acc: 0.7647, Val Loss: 0.5193, Val Acc: 0.7529\n",
      "Epoch [74/100], Train Loss: 0.5193, Train Acc: 0.7529, Val Loss: 0.5189, Val Acc: 0.7529\n",
      "Epoch [75/100], Train Loss: 0.5189, Train Acc: 0.7529, Val Loss: 0.5187, Val Acc: 0.7529\n",
      "Epoch [76/100], Train Loss: 0.5187, Train Acc: 0.7529, Val Loss: 0.5185, Val Acc: 0.7529\n",
      "Epoch [77/100], Train Loss: 0.5185, Train Acc: 0.7529, Val Loss: 0.5184, Val Acc: 0.7529\n",
      "Epoch [78/100], Train Loss: 0.5184, Train Acc: 0.7529, Val Loss: 0.5183, Val Acc: 0.7529\n",
      "Epoch [79/100], Train Loss: 0.5183, Train Acc: 0.7529, Val Loss: 0.5183, Val Acc: 0.7529\n",
      "Epoch [80/100], Train Loss: 0.5183, Train Acc: 0.7529, Val Loss: 0.5181, Val Acc: 0.7529\n",
      "Epoch [81/100], Train Loss: 0.5181, Train Acc: 0.7529, Val Loss: 0.5180, Val Acc: 0.7529\n",
      "Epoch [82/100], Train Loss: 0.5180, Train Acc: 0.7529, Val Loss: 0.5178, Val Acc: 0.7529\n",
      "Epoch [83/100], Train Loss: 0.5178, Train Acc: 0.7529, Val Loss: 0.5175, Val Acc: 0.7529\n",
      "Epoch [84/100], Train Loss: 0.5175, Train Acc: 0.7529, Val Loss: 0.5173, Val Acc: 0.7529\n",
      "Epoch [85/100], Train Loss: 0.5173, Train Acc: 0.7529, Val Loss: 0.5170, Val Acc: 0.7529\n",
      "Epoch [86/100], Train Loss: 0.5170, Train Acc: 0.7529, Val Loss: 0.5168, Val Acc: 0.7529\n",
      "Epoch [87/100], Train Loss: 0.5168, Train Acc: 0.7529, Val Loss: 0.5166, Val Acc: 0.7647\n",
      "Epoch [88/100], Train Loss: 0.5166, Train Acc: 0.7647, Val Loss: 0.5165, Val Acc: 0.7647\n",
      "Epoch [89/100], Train Loss: 0.5165, Train Acc: 0.7647, Val Loss: 0.5163, Val Acc: 0.7647\n",
      "Epoch [90/100], Train Loss: 0.5163, Train Acc: 0.7647, Val Loss: 0.5162, Val Acc: 0.7647\n",
      "Epoch [91/100], Train Loss: 0.5162, Train Acc: 0.7647, Val Loss: 0.5160, Val Acc: 0.7647\n",
      "Epoch [92/100], Train Loss: 0.5160, Train Acc: 0.7647, Val Loss: 0.5159, Val Acc: 0.7647\n",
      "Epoch [93/100], Train Loss: 0.5159, Train Acc: 0.7647, Val Loss: 0.5157, Val Acc: 0.7647\n",
      "Epoch [94/100], Train Loss: 0.5157, Train Acc: 0.7647, Val Loss: 0.5156, Val Acc: 0.7647\n",
      "Epoch [95/100], Train Loss: 0.5156, Train Acc: 0.7647, Val Loss: 0.5154, Val Acc: 0.7647\n",
      "Epoch [96/100], Train Loss: 0.5154, Train Acc: 0.7647, Val Loss: 0.5152, Val Acc: 0.7647\n",
      "Epoch [97/100], Train Loss: 0.5152, Train Acc: 0.7647, Val Loss: 0.5150, Val Acc: 0.7647\n",
      "Epoch [98/100], Train Loss: 0.5150, Train Acc: 0.7647, Val Loss: 0.5149, Val Acc: 0.7647\n",
      "Epoch [99/100], Train Loss: 0.5149, Train Acc: 0.7647, Val Loss: 0.5147, Val Acc: 0.7647\n",
      "Epoch [100/100], Train Loss: 0.5147, Train Acc: 0.7647, Val Loss: 0.5146, Val Acc: 0.7647\n",
      "Finished Training MLPModel\n",
      "Training Arm 1 (CNNModel) on Cluster 1\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/100], Train Loss: 7.2518, Train Acc: 0.3765, Val Loss: 6.2860, Val Acc: 0.3765\n",
      "Epoch [2/100], Train Loss: 6.2860, Train Acc: 0.3765, Val Loss: 5.3323, Val Acc: 0.3765\n",
      "Epoch [3/100], Train Loss: 5.3323, Train Acc: 0.3765, Val Loss: 4.3696, Val Acc: 0.3765\n",
      "Epoch [4/100], Train Loss: 4.3696, Train Acc: 0.3765, Val Loss: 3.3951, Val Acc: 0.3765\n",
      "Epoch [5/100], Train Loss: 3.3951, Train Acc: 0.3765, Val Loss: 2.4304, Val Acc: 0.3529\n",
      "Epoch [6/100], Train Loss: 2.4304, Train Acc: 0.3529, Val Loss: 1.5453, Val Acc: 0.3176\n",
      "Epoch [7/100], Train Loss: 1.5453, Train Acc: 0.3176, Val Loss: 0.9546, Val Acc: 0.2353\n",
      "Epoch [8/100], Train Loss: 0.9546, Train Acc: 0.2353, Val Loss: 0.9491, Val Acc: 0.6235\n",
      "Epoch [9/100], Train Loss: 0.9491, Train Acc: 0.6235, Val Loss: 1.2562, Val Acc: 0.6235\n",
      "Epoch [10/100], Train Loss: 1.2562, Train Acc: 0.6235, Val Loss: 1.5270, Val Acc: 0.6235\n",
      "Epoch [11/100], Train Loss: 1.5270, Train Acc: 0.6235, Val Loss: 1.6817, Val Acc: 0.6235\n",
      "Epoch [12/100], Train Loss: 1.6817, Train Acc: 0.6235, Val Loss: 1.7249, Val Acc: 0.6235\n",
      "Epoch [13/100], Train Loss: 1.7249, Train Acc: 0.6235, Val Loss: 1.6782, Val Acc: 0.6235\n",
      "Epoch [14/100], Train Loss: 1.6782, Train Acc: 0.6235, Val Loss: 1.5620, Val Acc: 0.6235\n",
      "Epoch [15/100], Train Loss: 1.5620, Train Acc: 0.6235, Val Loss: 1.3969, Val Acc: 0.6235\n",
      "Epoch [16/100], Train Loss: 1.3969, Train Acc: 0.6235, Val Loss: 1.2059, Val Acc: 0.6235\n",
      "Epoch [17/100], Train Loss: 1.2059, Train Acc: 0.6235, Val Loss: 1.0121, Val Acc: 0.6706\n",
      "Epoch [18/100], Train Loss: 1.0121, Train Acc: 0.6706, Val Loss: 0.8417, Val Acc: 0.6941\n",
      "Epoch [19/100], Train Loss: 0.8417, Train Acc: 0.6941, Val Loss: 0.7178, Val Acc: 0.6941\n",
      "Epoch [20/100], Train Loss: 0.7178, Train Acc: 0.6941, Val Loss: 0.6574, Val Acc: 0.7059\n",
      "Epoch [21/100], Train Loss: 0.6574, Train Acc: 0.7059, Val Loss: 0.6640, Val Acc: 0.7059\n",
      "Epoch [22/100], Train Loss: 0.6640, Train Acc: 0.7059, Val Loss: 0.7152, Val Acc: 0.3176\n",
      "Epoch [23/100], Train Loss: 0.7152, Train Acc: 0.3176, Val Loss: 0.7786, Val Acc: 0.3294\n",
      "Epoch [24/100], Train Loss: 0.7786, Train Acc: 0.3294, Val Loss: 0.8263, Val Acc: 0.3412\n",
      "Epoch [25/100], Train Loss: 0.8263, Train Acc: 0.3412, Val Loss: 0.8434, Val Acc: 0.3412\n",
      "Epoch [26/100], Train Loss: 0.8434, Train Acc: 0.3412, Val Loss: 0.8273, Val Acc: 0.3412\n",
      "Epoch [27/100], Train Loss: 0.8273, Train Acc: 0.3412, Val Loss: 0.7847, Val Acc: 0.3412\n",
      "Epoch [28/100], Train Loss: 0.7847, Train Acc: 0.3412, Val Loss: 0.7280, Val Acc: 0.3412\n",
      "Epoch [29/100], Train Loss: 0.7280, Train Acc: 0.3412, Val Loss: 0.6717, Val Acc: 0.3412\n",
      "Epoch [30/100], Train Loss: 0.6717, Train Acc: 0.3412, Val Loss: 0.6285, Val Acc: 0.7176\n",
      "Epoch [31/100], Train Loss: 0.6285, Train Acc: 0.7176, Val Loss: 0.6051, Val Acc: 0.7176\n",
      "Epoch [32/100], Train Loss: 0.6051, Train Acc: 0.7176, Val Loss: 0.6014, Val Acc: 0.7176\n",
      "Epoch [33/100], Train Loss: 0.6014, Train Acc: 0.7176, Val Loss: 0.6111, Val Acc: 0.7059\n",
      "Epoch [34/100], Train Loss: 0.6111, Train Acc: 0.7059, Val Loss: 0.6265, Val Acc: 0.7059\n",
      "Epoch [35/100], Train Loss: 0.6265, Train Acc: 0.7059, Val Loss: 0.6409, Val Acc: 0.7059\n",
      "Epoch [36/100], Train Loss: 0.6409, Train Acc: 0.7059, Val Loss: 0.6502, Val Acc: 0.7059\n",
      "Epoch [37/100], Train Loss: 0.6502, Train Acc: 0.7059, Val Loss: 0.6521, Val Acc: 0.7059\n",
      "Epoch [38/100], Train Loss: 0.6521, Train Acc: 0.7059, Val Loss: 0.6467, Val Acc: 0.7059\n",
      "Epoch [39/100], Train Loss: 0.6467, Train Acc: 0.7059, Val Loss: 0.6354, Val Acc: 0.7176\n",
      "Epoch [40/100], Train Loss: 0.6354, Train Acc: 0.7176, Val Loss: 0.6206, Val Acc: 0.7176\n",
      "Epoch [41/100], Train Loss: 0.6206, Train Acc: 0.7176, Val Loss: 0.6053, Val Acc: 0.7176\n",
      "Epoch [42/100], Train Loss: 0.6053, Train Acc: 0.7176, Val Loss: 0.5924, Val Acc: 0.7176\n",
      "Epoch [43/100], Train Loss: 0.5924, Train Acc: 0.7176, Val Loss: 0.5838, Val Acc: 0.7294\n",
      "Epoch [44/100], Train Loss: 0.5838, Train Acc: 0.7294, Val Loss: 0.5806, Val Acc: 0.7294\n",
      "Epoch [45/100], Train Loss: 0.5806, Train Acc: 0.7294, Val Loss: 0.5820, Val Acc: 0.7294\n",
      "Epoch [46/100], Train Loss: 0.5820, Train Acc: 0.7294, Val Loss: 0.5862, Val Acc: 0.7294\n",
      "Epoch [47/100], Train Loss: 0.5862, Train Acc: 0.7294, Val Loss: 0.5909, Val Acc: 0.7294\n",
      "Epoch [48/100], Train Loss: 0.5909, Train Acc: 0.7294, Val Loss: 0.5940, Val Acc: 0.7294\n",
      "Epoch [49/100], Train Loss: 0.5940, Train Acc: 0.7294, Val Loss: 0.5942, Val Acc: 0.7294\n",
      "Epoch [50/100], Train Loss: 0.5942, Train Acc: 0.7294, Val Loss: 0.5913, Val Acc: 0.7294\n",
      "Epoch [51/100], Train Loss: 0.5913, Train Acc: 0.7294, Val Loss: 0.5863, Val Acc: 0.7294\n",
      "Epoch [52/100], Train Loss: 0.5863, Train Acc: 0.7294, Val Loss: 0.5805, Val Acc: 0.7294\n",
      "Epoch [53/100], Train Loss: 0.5805, Train Acc: 0.7294, Val Loss: 0.5754, Val Acc: 0.7294\n",
      "Epoch [54/100], Train Loss: 0.5754, Train Acc: 0.7294, Val Loss: 0.5719, Val Acc: 0.7294\n",
      "Epoch [55/100], Train Loss: 0.5719, Train Acc: 0.7294, Val Loss: 0.5704, Val Acc: 0.7294\n",
      "Epoch [56/100], Train Loss: 0.5704, Train Acc: 0.7294, Val Loss: 0.5705, Val Acc: 0.7294\n",
      "Epoch [57/100], Train Loss: 0.5705, Train Acc: 0.7294, Val Loss: 0.5715, Val Acc: 0.7294\n",
      "Epoch [58/100], Train Loss: 0.5715, Train Acc: 0.7294, Val Loss: 0.5726, Val Acc: 0.7294\n",
      "Epoch [59/100], Train Loss: 0.5726, Train Acc: 0.7294, Val Loss: 0.5731, Val Acc: 0.7294\n",
      "Epoch [60/100], Train Loss: 0.5731, Train Acc: 0.7294, Val Loss: 0.5728, Val Acc: 0.7294\n",
      "Epoch [61/100], Train Loss: 0.5728, Train Acc: 0.7294, Val Loss: 0.5715, Val Acc: 0.7294\n",
      "Epoch [62/100], Train Loss: 0.5715, Train Acc: 0.7294, Val Loss: 0.5695, Val Acc: 0.7294\n",
      "Epoch [63/100], Train Loss: 0.5695, Train Acc: 0.7294, Val Loss: 0.5673, Val Acc: 0.7294\n",
      "Epoch [64/100], Train Loss: 0.5673, Train Acc: 0.7294, Val Loss: 0.5652, Val Acc: 0.7294\n",
      "Epoch [65/100], Train Loss: 0.5652, Train Acc: 0.7294, Val Loss: 0.5637, Val Acc: 0.7294\n",
      "Epoch [66/100], Train Loss: 0.5637, Train Acc: 0.7294, Val Loss: 0.5629, Val Acc: 0.7294\n",
      "Epoch [67/100], Train Loss: 0.5629, Train Acc: 0.7294, Val Loss: 0.5627, Val Acc: 0.7294\n",
      "Epoch [68/100], Train Loss: 0.5627, Train Acc: 0.7294, Val Loss: 0.5627, Val Acc: 0.7294\n",
      "Epoch [69/100], Train Loss: 0.5627, Train Acc: 0.7294, Val Loss: 0.5627, Val Acc: 0.7294\n",
      "Epoch [70/100], Train Loss: 0.5627, Train Acc: 0.7294, Val Loss: 0.5623, Val Acc: 0.7294\n",
      "Epoch [71/100], Train Loss: 0.5623, Train Acc: 0.7294, Val Loss: 0.5614, Val Acc: 0.7294\n",
      "Epoch [72/100], Train Loss: 0.5614, Train Acc: 0.7294, Val Loss: 0.5603, Val Acc: 0.7294\n",
      "Epoch [73/100], Train Loss: 0.5603, Train Acc: 0.7294, Val Loss: 0.5591, Val Acc: 0.7294\n",
      "Epoch [74/100], Train Loss: 0.5591, Train Acc: 0.7294, Val Loss: 0.5582, Val Acc: 0.7294\n",
      "Epoch [75/100], Train Loss: 0.5582, Train Acc: 0.7294, Val Loss: 0.5575, Val Acc: 0.7294\n",
      "Epoch [76/100], Train Loss: 0.5575, Train Acc: 0.7294, Val Loss: 0.5570, Val Acc: 0.7294\n",
      "Epoch [77/100], Train Loss: 0.5570, Train Acc: 0.7294, Val Loss: 0.5566, Val Acc: 0.7294\n",
      "Epoch [78/100], Train Loss: 0.5566, Train Acc: 0.7294, Val Loss: 0.5563, Val Acc: 0.7294\n",
      "Epoch [79/100], Train Loss: 0.5563, Train Acc: 0.7294, Val Loss: 0.5560, Val Acc: 0.7294\n",
      "Epoch [80/100], Train Loss: 0.5560, Train Acc: 0.7294, Val Loss: 0.5557, Val Acc: 0.7294\n",
      "Epoch [81/100], Train Loss: 0.5557, Train Acc: 0.7294, Val Loss: 0.5553, Val Acc: 0.7294\n",
      "Epoch [82/100], Train Loss: 0.5553, Train Acc: 0.7294, Val Loss: 0.5548, Val Acc: 0.7294\n",
      "Epoch [83/100], Train Loss: 0.5548, Train Acc: 0.7294, Val Loss: 0.5543, Val Acc: 0.7294\n",
      "Epoch [84/100], Train Loss: 0.5543, Train Acc: 0.7294, Val Loss: 0.5538, Val Acc: 0.7294\n",
      "Epoch [85/100], Train Loss: 0.5538, Train Acc: 0.7294, Val Loss: 0.5534, Val Acc: 0.7294\n",
      "Epoch [86/100], Train Loss: 0.5534, Train Acc: 0.7294, Val Loss: 0.5530, Val Acc: 0.7294\n",
      "Epoch [87/100], Train Loss: 0.5530, Train Acc: 0.7294, Val Loss: 0.5526, Val Acc: 0.7294\n",
      "Epoch [88/100], Train Loss: 0.5526, Train Acc: 0.7294, Val Loss: 0.5523, Val Acc: 0.7294\n",
      "Epoch [89/100], Train Loss: 0.5523, Train Acc: 0.7294, Val Loss: 0.5520, Val Acc: 0.7294\n",
      "Epoch [90/100], Train Loss: 0.5520, Train Acc: 0.7294, Val Loss: 0.5517, Val Acc: 0.7294\n",
      "Epoch [91/100], Train Loss: 0.5517, Train Acc: 0.7294, Val Loss: 0.5514, Val Acc: 0.7294\n",
      "Epoch [92/100], Train Loss: 0.5514, Train Acc: 0.7294, Val Loss: 0.5510, Val Acc: 0.7294\n",
      "Epoch [93/100], Train Loss: 0.5510, Train Acc: 0.7294, Val Loss: 0.5506, Val Acc: 0.7294\n",
      "Epoch [94/100], Train Loss: 0.5506, Train Acc: 0.7294, Val Loss: 0.5502, Val Acc: 0.7294\n",
      "Epoch [95/100], Train Loss: 0.5502, Train Acc: 0.7294, Val Loss: 0.5499, Val Acc: 0.7294\n",
      "Epoch [96/100], Train Loss: 0.5499, Train Acc: 0.7294, Val Loss: 0.5495, Val Acc: 0.7294\n",
      "Epoch [97/100], Train Loss: 0.5495, Train Acc: 0.7294, Val Loss: 0.5492, Val Acc: 0.7294\n",
      "Epoch [98/100], Train Loss: 0.5492, Train Acc: 0.7294, Val Loss: 0.5489, Val Acc: 0.7294\n",
      "Epoch [99/100], Train Loss: 0.5489, Train Acc: 0.7294, Val Loss: 0.5486, Val Acc: 0.7294\n",
      "Epoch [100/100], Train Loss: 0.5486, Train Acc: 0.7294, Val Loss: 0.5483, Val Acc: 0.7294\n",
      "Finished Training CNNModel\n",
      "Training Arm 2 (RNNModel) on Cluster 1\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/100], Train Loss: 1.6537, Train Acc: 0.3765, Val Loss: 1.3149, Val Acc: 0.3765\n",
      "Epoch [2/100], Train Loss: 1.3149, Train Acc: 0.3765, Val Loss: 1.0853, Val Acc: 0.3765\n",
      "Epoch [3/100], Train Loss: 1.0853, Train Acc: 0.3765, Val Loss: 0.8921, Val Acc: 0.3765\n",
      "Epoch [4/100], Train Loss: 0.8921, Train Acc: 0.3765, Val Loss: 0.7741, Val Acc: 0.3765\n",
      "Epoch [5/100], Train Loss: 0.7741, Train Acc: 0.3765, Val Loss: 0.7300, Val Acc: 0.3765\n",
      "Epoch [6/100], Train Loss: 0.7300, Train Acc: 0.3765, Val Loss: 0.7044, Val Acc: 0.3765\n",
      "Epoch [7/100], Train Loss: 0.7044, Train Acc: 0.3765, Val Loss: 0.6838, Val Acc: 0.3765\n",
      "Epoch [8/100], Train Loss: 0.6838, Train Acc: 0.3765, Val Loss: 0.6659, Val Acc: 0.7647\n",
      "Epoch [9/100], Train Loss: 0.6659, Train Acc: 0.7647, Val Loss: 0.6510, Val Acc: 0.7412\n",
      "Epoch [10/100], Train Loss: 0.6510, Train Acc: 0.7412, Val Loss: 0.6394, Val Acc: 0.7294\n",
      "Epoch [11/100], Train Loss: 0.6394, Train Acc: 0.7294, Val Loss: 0.6310, Val Acc: 0.7294\n",
      "Epoch [12/100], Train Loss: 0.6310, Train Acc: 0.7294, Val Loss: 0.6255, Val Acc: 0.7294\n",
      "Epoch [13/100], Train Loss: 0.6255, Train Acc: 0.7294, Val Loss: 0.6225, Val Acc: 0.7294\n",
      "Epoch [14/100], Train Loss: 0.6225, Train Acc: 0.7294, Val Loss: 0.6213, Val Acc: 0.7176\n",
      "Epoch [15/100], Train Loss: 0.6213, Train Acc: 0.7176, Val Loss: 0.6211, Val Acc: 0.6941\n",
      "Epoch [16/100], Train Loss: 0.6211, Train Acc: 0.6941, Val Loss: 0.6209, Val Acc: 0.6824\n",
      "Epoch [17/100], Train Loss: 0.6209, Train Acc: 0.6824, Val Loss: 0.6205, Val Acc: 0.6824\n",
      "Epoch [18/100], Train Loss: 0.6205, Train Acc: 0.6824, Val Loss: 0.6194, Val Acc: 0.6824\n",
      "Epoch [19/100], Train Loss: 0.6194, Train Acc: 0.6824, Val Loss: 0.6177, Val Acc: 0.6824\n",
      "Epoch [20/100], Train Loss: 0.6177, Train Acc: 0.6824, Val Loss: 0.6154, Val Acc: 0.7059\n",
      "Epoch [21/100], Train Loss: 0.6154, Train Acc: 0.7059, Val Loss: 0.6125, Val Acc: 0.7059\n",
      "Epoch [22/100], Train Loss: 0.6125, Train Acc: 0.7059, Val Loss: 0.6090, Val Acc: 0.7176\n",
      "Epoch [23/100], Train Loss: 0.6090, Train Acc: 0.7176, Val Loss: 0.6051, Val Acc: 0.7176\n",
      "Epoch [24/100], Train Loss: 0.6051, Train Acc: 0.7176, Val Loss: 0.6009, Val Acc: 0.7294\n",
      "Epoch [25/100], Train Loss: 0.6009, Train Acc: 0.7294, Val Loss: 0.5965, Val Acc: 0.7294\n",
      "Epoch [26/100], Train Loss: 0.5965, Train Acc: 0.7294, Val Loss: 0.5921, Val Acc: 0.7294\n",
      "Epoch [27/100], Train Loss: 0.5921, Train Acc: 0.7294, Val Loss: 0.5879, Val Acc: 0.7294\n",
      "Epoch [28/100], Train Loss: 0.5879, Train Acc: 0.7294, Val Loss: 0.5839, Val Acc: 0.7412\n",
      "Epoch [29/100], Train Loss: 0.5839, Train Acc: 0.7412, Val Loss: 0.5799, Val Acc: 0.7412\n",
      "Epoch [30/100], Train Loss: 0.5799, Train Acc: 0.7412, Val Loss: 0.5761, Val Acc: 0.7412\n",
      "Epoch [31/100], Train Loss: 0.5761, Train Acc: 0.7412, Val Loss: 0.5726, Val Acc: 0.7412\n",
      "Epoch [32/100], Train Loss: 0.5726, Train Acc: 0.7412, Val Loss: 0.5694, Val Acc: 0.7412\n",
      "Epoch [33/100], Train Loss: 0.5694, Train Acc: 0.7412, Val Loss: 0.5661, Val Acc: 0.7412\n",
      "Epoch [34/100], Train Loss: 0.5661, Train Acc: 0.7412, Val Loss: 0.5630, Val Acc: 0.7412\n",
      "Epoch [35/100], Train Loss: 0.5630, Train Acc: 0.7412, Val Loss: 0.5602, Val Acc: 0.7412\n",
      "Epoch [36/100], Train Loss: 0.5602, Train Acc: 0.7412, Val Loss: 0.5575, Val Acc: 0.7412\n",
      "Epoch [37/100], Train Loss: 0.5575, Train Acc: 0.7412, Val Loss: 0.5549, Val Acc: 0.7412\n",
      "Epoch [38/100], Train Loss: 0.5549, Train Acc: 0.7412, Val Loss: 0.5526, Val Acc: 0.7412\n",
      "Epoch [39/100], Train Loss: 0.5526, Train Acc: 0.7412, Val Loss: 0.5503, Val Acc: 0.7412\n",
      "Epoch [40/100], Train Loss: 0.5503, Train Acc: 0.7412, Val Loss: 0.5480, Val Acc: 0.7412\n",
      "Epoch [41/100], Train Loss: 0.5480, Train Acc: 0.7412, Val Loss: 0.5460, Val Acc: 0.7529\n",
      "Epoch [42/100], Train Loss: 0.5460, Train Acc: 0.7529, Val Loss: 0.5440, Val Acc: 0.7529\n",
      "Epoch [43/100], Train Loss: 0.5440, Train Acc: 0.7529, Val Loss: 0.5421, Val Acc: 0.7412\n",
      "Epoch [44/100], Train Loss: 0.5421, Train Acc: 0.7412, Val Loss: 0.5402, Val Acc: 0.7529\n",
      "Epoch [45/100], Train Loss: 0.5402, Train Acc: 0.7529, Val Loss: 0.5386, Val Acc: 0.7529\n",
      "Epoch [46/100], Train Loss: 0.5386, Train Acc: 0.7529, Val Loss: 0.5368, Val Acc: 0.7529\n",
      "Epoch [47/100], Train Loss: 0.5368, Train Acc: 0.7529, Val Loss: 0.5353, Val Acc: 0.7529\n",
      "Epoch [48/100], Train Loss: 0.5353, Train Acc: 0.7529, Val Loss: 0.5337, Val Acc: 0.7529\n",
      "Epoch [49/100], Train Loss: 0.5337, Train Acc: 0.7529, Val Loss: 0.5321, Val Acc: 0.7529\n",
      "Epoch [50/100], Train Loss: 0.5321, Train Acc: 0.7529, Val Loss: 0.5307, Val Acc: 0.7529\n",
      "Epoch [51/100], Train Loss: 0.5307, Train Acc: 0.7529, Val Loss: 0.5293, Val Acc: 0.7529\n",
      "Epoch [52/100], Train Loss: 0.5293, Train Acc: 0.7529, Val Loss: 0.5281, Val Acc: 0.7529\n",
      "Epoch [53/100], Train Loss: 0.5281, Train Acc: 0.7529, Val Loss: 0.5270, Val Acc: 0.7647\n",
      "Epoch [54/100], Train Loss: 0.5270, Train Acc: 0.7647, Val Loss: 0.5276, Val Acc: 0.7529\n",
      "Epoch [55/100], Train Loss: 0.5276, Train Acc: 0.7529, Val Loss: 0.5312, Val Acc: 0.7647\n",
      "Epoch [56/100], Train Loss: 0.5312, Train Acc: 0.7647, Val Loss: 0.5448, Val Acc: 0.7412\n",
      "Epoch [57/100], Train Loss: 0.5448, Train Acc: 0.7412, Val Loss: 0.5450, Val Acc: 0.7412\n",
      "Epoch [58/100], Train Loss: 0.5450, Train Acc: 0.7412, Val Loss: 0.5217, Val Acc: 0.7647\n",
      "Epoch [59/100], Train Loss: 0.5217, Train Acc: 0.7647, Val Loss: 0.5533, Val Acc: 0.7647\n",
      "Epoch [60/100], Train Loss: 0.5533, Train Acc: 0.7647, Val Loss: 0.5537, Val Acc: 0.7412\n",
      "Epoch [61/100], Train Loss: 0.5537, Train Acc: 0.7412, Val Loss: 0.6121, Val Acc: 0.7294\n",
      "Epoch [62/100], Train Loss: 0.6121, Train Acc: 0.7294, Val Loss: 0.5938, Val Acc: 0.7176\n",
      "Epoch [63/100], Train Loss: 0.5938, Train Acc: 0.7176, Val Loss: 0.5941, Val Acc: 0.7294\n",
      "Epoch [64/100], Train Loss: 0.5941, Train Acc: 0.7294, Val Loss: 0.5925, Val Acc: 0.7412\n",
      "Epoch [65/100], Train Loss: 0.5925, Train Acc: 0.7412, Val Loss: 0.5892, Val Acc: 0.7412\n",
      "Epoch [66/100], Train Loss: 0.5892, Train Acc: 0.7412, Val Loss: 0.5838, Val Acc: 0.7529\n",
      "Epoch [67/100], Train Loss: 0.5838, Train Acc: 0.7529, Val Loss: 0.5772, Val Acc: 0.7529\n",
      "Epoch [68/100], Train Loss: 0.5772, Train Acc: 0.7529, Val Loss: 0.5704, Val Acc: 0.7529\n",
      "Epoch [69/100], Train Loss: 0.5704, Train Acc: 0.7529, Val Loss: 0.5639, Val Acc: 0.7412\n",
      "Epoch [70/100], Train Loss: 0.5639, Train Acc: 0.7412, Val Loss: 0.5582, Val Acc: 0.7412\n",
      "Epoch [71/100], Train Loss: 0.5582, Train Acc: 0.7412, Val Loss: 0.5536, Val Acc: 0.7412\n",
      "Epoch [72/100], Train Loss: 0.5536, Train Acc: 0.7412, Val Loss: 0.5503, Val Acc: 0.7412\n",
      "Epoch [73/100], Train Loss: 0.5503, Train Acc: 0.7412, Val Loss: 0.5485, Val Acc: 0.7412\n",
      "Epoch [74/100], Train Loss: 0.5485, Train Acc: 0.7412, Val Loss: 0.5478, Val Acc: 0.7412\n",
      "Epoch [75/100], Train Loss: 0.5478, Train Acc: 0.7412, Val Loss: 0.5481, Val Acc: 0.7412\n",
      "Epoch [76/100], Train Loss: 0.5481, Train Acc: 0.7412, Val Loss: 0.5488, Val Acc: 0.7412\n",
      "Epoch [77/100], Train Loss: 0.5488, Train Acc: 0.7412, Val Loss: 0.5496, Val Acc: 0.7412\n",
      "Epoch [78/100], Train Loss: 0.5496, Train Acc: 0.7412, Val Loss: 0.5501, Val Acc: 0.7412\n",
      "Epoch [79/100], Train Loss: 0.5501, Train Acc: 0.7412, Val Loss: 0.5501, Val Acc: 0.7412\n",
      "Epoch [80/100], Train Loss: 0.5501, Train Acc: 0.7412, Val Loss: 0.5494, Val Acc: 0.7412\n",
      "Epoch [81/100], Train Loss: 0.5494, Train Acc: 0.7412, Val Loss: 0.5482, Val Acc: 0.7412\n",
      "Epoch [82/100], Train Loss: 0.5482, Train Acc: 0.7412, Val Loss: 0.5465, Val Acc: 0.7412\n",
      "Epoch [83/100], Train Loss: 0.5465, Train Acc: 0.7412, Val Loss: 0.5447, Val Acc: 0.7412\n",
      "Epoch [84/100], Train Loss: 0.5447, Train Acc: 0.7412, Val Loss: 0.5428, Val Acc: 0.7412\n",
      "Epoch [85/100], Train Loss: 0.5428, Train Acc: 0.7412, Val Loss: 0.5411, Val Acc: 0.7412\n",
      "Epoch [86/100], Train Loss: 0.5411, Train Acc: 0.7412, Val Loss: 0.5398, Val Acc: 0.7412\n",
      "Epoch [87/100], Train Loss: 0.5398, Train Acc: 0.7412, Val Loss: 0.5390, Val Acc: 0.7412\n",
      "Epoch [88/100], Train Loss: 0.5390, Train Acc: 0.7412, Val Loss: 0.5386, Val Acc: 0.7412\n",
      "Epoch [89/100], Train Loss: 0.5386, Train Acc: 0.7412, Val Loss: 0.5385, Val Acc: 0.7529\n",
      "Epoch [90/100], Train Loss: 0.5385, Train Acc: 0.7529, Val Loss: 0.5385, Val Acc: 0.7529\n",
      "Epoch [91/100], Train Loss: 0.5385, Train Acc: 0.7529, Val Loss: 0.5384, Val Acc: 0.7529\n",
      "Epoch [92/100], Train Loss: 0.5384, Train Acc: 0.7529, Val Loss: 0.5381, Val Acc: 0.7529\n",
      "Epoch [93/100], Train Loss: 0.5381, Train Acc: 0.7529, Val Loss: 0.5374, Val Acc: 0.7529\n",
      "Epoch [94/100], Train Loss: 0.5374, Train Acc: 0.7529, Val Loss: 0.5363, Val Acc: 0.7529\n",
      "Epoch [95/100], Train Loss: 0.5363, Train Acc: 0.7529, Val Loss: 0.5349, Val Acc: 0.7529\n",
      "Epoch [96/100], Train Loss: 0.5349, Train Acc: 0.7529, Val Loss: 0.5335, Val Acc: 0.7529\n",
      "Epoch [97/100], Train Loss: 0.5335, Train Acc: 0.7529, Val Loss: 0.5322, Val Acc: 0.7529\n",
      "Epoch [98/100], Train Loss: 0.5322, Train Acc: 0.7529, Val Loss: 0.5311, Val Acc: 0.7529\n",
      "Epoch [99/100], Train Loss: 0.5311, Train Acc: 0.7529, Val Loss: 0.5302, Val Acc: 0.7529\n",
      "Epoch [100/100], Train Loss: 0.5302, Train Acc: 0.7529, Val Loss: 0.5294, Val Acc: 0.7529\n",
      "Finished Training RNNModel\n",
      "Cluster 2: 208 samples\n",
      "Training Arm 0 (MLPModel) on Cluster 2\n",
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/100], Train Loss: 5.6009, Train Acc: 0.5817, Val Loss: 5.3523, Val Acc: 0.5865\n",
      "Epoch [2/100], Train Loss: 5.2932, Train Acc: 0.5865, Val Loss: 5.0461, Val Acc: 0.5865\n",
      "Epoch [3/100], Train Loss: 4.9955, Train Acc: 0.5913, Val Loss: 4.7445, Val Acc: 0.5913\n",
      "Epoch [4/100], Train Loss: 4.6967, Train Acc: 0.5913, Val Loss: 4.4463, Val Acc: 0.5913\n",
      "Epoch [5/100], Train Loss: 4.3949, Train Acc: 0.5913, Val Loss: 4.1551, Val Acc: 0.5865\n",
      "Epoch [6/100], Train Loss: 4.1015, Train Acc: 0.5865, Val Loss: 3.8696, Val Acc: 0.5913\n",
      "Epoch [7/100], Train Loss: 3.8143, Train Acc: 0.5913, Val Loss: 3.5894, Val Acc: 0.5913\n",
      "Epoch [8/100], Train Loss: 3.5412, Train Acc: 0.5913, Val Loss: 3.3173, Val Acc: 0.5962\n",
      "Epoch [9/100], Train Loss: 3.2491, Train Acc: 0.5962, Val Loss: 3.0601, Val Acc: 0.6058\n",
      "Epoch [10/100], Train Loss: 3.0089, Train Acc: 0.6058, Val Loss: 2.8206, Val Acc: 0.6106\n",
      "Epoch [11/100], Train Loss: 2.7833, Train Acc: 0.6154, Val Loss: 2.6096, Val Acc: 0.6587\n",
      "Epoch [12/100], Train Loss: 2.5700, Train Acc: 0.6587, Val Loss: 2.4330, Val Acc: 0.6923\n",
      "Epoch [13/100], Train Loss: 2.4029, Train Acc: 0.7019, Val Loss: 2.2848, Val Acc: 0.7452\n",
      "Epoch [14/100], Train Loss: 2.2620, Train Acc: 0.7548, Val Loss: 2.1544, Val Acc: 0.7837\n",
      "Epoch [15/100], Train Loss: 2.1321, Train Acc: 0.7837, Val Loss: 2.0337, Val Acc: 0.7837\n",
      "Epoch [16/100], Train Loss: 2.0074, Train Acc: 0.7837, Val Loss: 1.9174, Val Acc: 0.7837\n",
      "Epoch [17/100], Train Loss: 1.8945, Train Acc: 0.7837, Val Loss: 1.8019, Val Acc: 0.7837\n",
      "Epoch [18/100], Train Loss: 1.7778, Train Acc: 0.7837, Val Loss: 1.6878, Val Acc: 0.7837\n",
      "Epoch [19/100], Train Loss: 1.6583, Train Acc: 0.7837, Val Loss: 1.5759, Val Acc: 0.7837\n",
      "Epoch [20/100], Train Loss: 1.5554, Train Acc: 0.7837, Val Loss: 1.4655, Val Acc: 0.7837\n",
      "Epoch [21/100], Train Loss: 1.4443, Train Acc: 0.7837, Val Loss: 1.3583, Val Acc: 0.7837\n",
      "Epoch [22/100], Train Loss: 1.3350, Train Acc: 0.7837, Val Loss: 1.2545, Val Acc: 0.7837\n",
      "Epoch [23/100], Train Loss: 1.2387, Train Acc: 0.7837, Val Loss: 1.1535, Val Acc: 0.7837\n",
      "Epoch [24/100], Train Loss: 1.1327, Train Acc: 0.7837, Val Loss: 1.0574, Val Acc: 0.7837\n",
      "Epoch [25/100], Train Loss: 1.0419, Train Acc: 0.7837, Val Loss: 0.9647, Val Acc: 0.7837\n",
      "Epoch [26/100], Train Loss: 0.9471, Train Acc: 0.7837, Val Loss: 0.8775, Val Acc: 0.7837\n",
      "Epoch [27/100], Train Loss: 0.8656, Train Acc: 0.7837, Val Loss: 0.7946, Val Acc: 0.7837\n",
      "Epoch [28/100], Train Loss: 0.7800, Train Acc: 0.7837, Val Loss: 0.7170, Val Acc: 0.7933\n",
      "Epoch [29/100], Train Loss: 0.7041, Train Acc: 0.7933, Val Loss: 0.6444, Val Acc: 0.7933\n",
      "Epoch [30/100], Train Loss: 0.6335, Train Acc: 0.7933, Val Loss: 0.5766, Val Acc: 0.7933\n",
      "Epoch [31/100], Train Loss: 0.5620, Train Acc: 0.7933, Val Loss: 0.5146, Val Acc: 0.7933\n",
      "Epoch [32/100], Train Loss: 0.4994, Train Acc: 0.7933, Val Loss: 0.4581, Val Acc: 0.7981\n",
      "Epoch [33/100], Train Loss: 0.4481, Train Acc: 0.7981, Val Loss: 0.4083, Val Acc: 0.7981\n",
      "Epoch [34/100], Train Loss: 0.4011, Train Acc: 0.7981, Val Loss: 0.3656, Val Acc: 0.7981\n",
      "Epoch [35/100], Train Loss: 0.3594, Train Acc: 0.7981, Val Loss: 0.3303, Val Acc: 0.7981\n",
      "Epoch [36/100], Train Loss: 0.3235, Train Acc: 0.8029, Val Loss: 0.3031, Val Acc: 0.8125\n",
      "Epoch [37/100], Train Loss: 0.2992, Train Acc: 0.8125, Val Loss: 0.2820, Val Acc: 0.8317\n",
      "Epoch [38/100], Train Loss: 0.2793, Train Acc: 0.8365, Val Loss: 0.2650, Val Acc: 0.9038\n",
      "Epoch [39/100], Train Loss: 0.2618, Train Acc: 0.9327, Val Loss: 0.2507, Val Acc: 0.9712\n",
      "Epoch [40/100], Train Loss: 0.2483, Train Acc: 0.9712, Val Loss: 0.2383, Val Acc: 0.9712\n",
      "Epoch [41/100], Train Loss: 0.2361, Train Acc: 0.9712, Val Loss: 0.2277, Val Acc: 0.9712\n",
      "Epoch [42/100], Train Loss: 0.2257, Train Acc: 0.9712, Val Loss: 0.2185, Val Acc: 0.9712\n",
      "Epoch [43/100], Train Loss: 0.2170, Train Acc: 0.9712, Val Loss: 0.2105, Val Acc: 0.9712\n",
      "Epoch [44/100], Train Loss: 0.2092, Train Acc: 0.9712, Val Loss: 0.2037, Val Acc: 0.9712\n",
      "Epoch [45/100], Train Loss: 0.2023, Train Acc: 0.9712, Val Loss: 0.1978, Val Acc: 0.9712\n",
      "Epoch [46/100], Train Loss: 0.1970, Train Acc: 0.9712, Val Loss: 0.1924, Val Acc: 0.9712\n",
      "Epoch [47/100], Train Loss: 0.1917, Train Acc: 0.9712, Val Loss: 0.1876, Val Acc: 0.9712\n",
      "Epoch [48/100], Train Loss: 0.1870, Train Acc: 0.9663, Val Loss: 0.1832, Val Acc: 0.9663\n",
      "Epoch [49/100], Train Loss: 0.1824, Train Acc: 0.9663, Val Loss: 0.1790, Val Acc: 0.9663\n",
      "Epoch [50/100], Train Loss: 0.1782, Train Acc: 0.9663, Val Loss: 0.1751, Val Acc: 0.9663\n",
      "Epoch [51/100], Train Loss: 0.1742, Train Acc: 0.9663, Val Loss: 0.1714, Val Acc: 0.9663\n",
      "Epoch [52/100], Train Loss: 0.1707, Train Acc: 0.9663, Val Loss: 0.1678, Val Acc: 0.9663\n",
      "Epoch [53/100], Train Loss: 0.1671, Train Acc: 0.9663, Val Loss: 0.1644, Val Acc: 0.9663\n",
      "Epoch [54/100], Train Loss: 0.1637, Train Acc: 0.9663, Val Loss: 0.1610, Val Acc: 0.9663\n",
      "Epoch [55/100], Train Loss: 0.1603, Train Acc: 0.9663, Val Loss: 0.1577, Val Acc: 0.9663\n",
      "Epoch [56/100], Train Loss: 0.1571, Train Acc: 0.9663, Val Loss: 0.1546, Val Acc: 0.9663\n",
      "Epoch [57/100], Train Loss: 0.1540, Train Acc: 0.9663, Val Loss: 0.1515, Val Acc: 0.9663\n",
      "Epoch [58/100], Train Loss: 0.1509, Train Acc: 0.9663, Val Loss: 0.1485, Val Acc: 0.9663\n",
      "Epoch [59/100], Train Loss: 0.1480, Train Acc: 0.9663, Val Loss: 0.1455, Val Acc: 0.9712\n",
      "Epoch [60/100], Train Loss: 0.1450, Train Acc: 0.9712, Val Loss: 0.1427, Val Acc: 0.9712\n",
      "Epoch [61/100], Train Loss: 0.1420, Train Acc: 0.9712, Val Loss: 0.1399, Val Acc: 0.9712\n",
      "Epoch [62/100], Train Loss: 0.1393, Train Acc: 0.9760, Val Loss: 0.1372, Val Acc: 0.9760\n",
      "Epoch [63/100], Train Loss: 0.1367, Train Acc: 0.9760, Val Loss: 0.1344, Val Acc: 0.9760\n",
      "Epoch [64/100], Train Loss: 0.1339, Train Acc: 0.9760, Val Loss: 0.1318, Val Acc: 0.9760\n",
      "Epoch [65/100], Train Loss: 0.1314, Train Acc: 0.9760, Val Loss: 0.1292, Val Acc: 0.9760\n",
      "Epoch [66/100], Train Loss: 0.1286, Train Acc: 0.9760, Val Loss: 0.1265, Val Acc: 0.9760\n",
      "Epoch [67/100], Train Loss: 0.1258, Train Acc: 0.9760, Val Loss: 0.1239, Val Acc: 0.9760\n",
      "Epoch [68/100], Train Loss: 0.1235, Train Acc: 0.9760, Val Loss: 0.1213, Val Acc: 0.9760\n",
      "Epoch [69/100], Train Loss: 0.1206, Train Acc: 0.9760, Val Loss: 0.1189, Val Acc: 0.9760\n",
      "Epoch [70/100], Train Loss: 0.1184, Train Acc: 0.9760, Val Loss: 0.1165, Val Acc: 0.9760\n",
      "Epoch [71/100], Train Loss: 0.1160, Train Acc: 0.9760, Val Loss: 0.1142, Val Acc: 0.9760\n",
      "Epoch [72/100], Train Loss: 0.1139, Train Acc: 0.9760, Val Loss: 0.1120, Val Acc: 0.9760\n",
      "Epoch [73/100], Train Loss: 0.1116, Train Acc: 0.9760, Val Loss: 0.1099, Val Acc: 0.9760\n",
      "Epoch [74/100], Train Loss: 0.1096, Train Acc: 0.9760, Val Loss: 0.1078, Val Acc: 0.9760\n",
      "Epoch [75/100], Train Loss: 0.1075, Train Acc: 0.9760, Val Loss: 0.1059, Val Acc: 0.9760\n",
      "Epoch [76/100], Train Loss: 0.1056, Train Acc: 0.9760, Val Loss: 0.1041, Val Acc: 0.9760\n",
      "Epoch [77/100], Train Loss: 0.1038, Train Acc: 0.9760, Val Loss: 0.1023, Val Acc: 0.9760\n",
      "Epoch [78/100], Train Loss: 0.1020, Train Acc: 0.9760, Val Loss: 0.1006, Val Acc: 0.9760\n",
      "Epoch [79/100], Train Loss: 0.1004, Train Acc: 0.9760, Val Loss: 0.0991, Val Acc: 0.9760\n",
      "Epoch [80/100], Train Loss: 0.0988, Train Acc: 0.9760, Val Loss: 0.0976, Val Acc: 0.9760\n",
      "Epoch [81/100], Train Loss: 0.0972, Train Acc: 0.9760, Val Loss: 0.0961, Val Acc: 0.9760\n",
      "Epoch [82/100], Train Loss: 0.0958, Train Acc: 0.9760, Val Loss: 0.0947, Val Acc: 0.9760\n",
      "Epoch [83/100], Train Loss: 0.0945, Train Acc: 0.9760, Val Loss: 0.0933, Val Acc: 0.9760\n",
      "Epoch [84/100], Train Loss: 0.0930, Train Acc: 0.9760, Val Loss: 0.0920, Val Acc: 0.9760\n",
      "Epoch [85/100], Train Loss: 0.0918, Train Acc: 0.9760, Val Loss: 0.0908, Val Acc: 0.9760\n",
      "Epoch [86/100], Train Loss: 0.0907, Train Acc: 0.9760, Val Loss: 0.0896, Val Acc: 0.9760\n",
      "Epoch [87/100], Train Loss: 0.0895, Train Acc: 0.9760, Val Loss: 0.0884, Val Acc: 0.9760\n",
      "Epoch [88/100], Train Loss: 0.0882, Train Acc: 0.9760, Val Loss: 0.0873, Val Acc: 0.9760\n",
      "Epoch [89/100], Train Loss: 0.0871, Train Acc: 0.9760, Val Loss: 0.0862, Val Acc: 0.9760\n",
      "Epoch [90/100], Train Loss: 0.0861, Train Acc: 0.9760, Val Loss: 0.0851, Val Acc: 0.9760\n",
      "Epoch [91/100], Train Loss: 0.0852, Train Acc: 0.9760, Val Loss: 0.0841, Val Acc: 0.9760\n",
      "Epoch [92/100], Train Loss: 0.0840, Train Acc: 0.9760, Val Loss: 0.0831, Val Acc: 0.9760\n",
      "Epoch [93/100], Train Loss: 0.0829, Train Acc: 0.9760, Val Loss: 0.0821, Val Acc: 0.9760\n",
      "Epoch [94/100], Train Loss: 0.0819, Train Acc: 0.9760, Val Loss: 0.0811, Val Acc: 0.9760\n",
      "Epoch [95/100], Train Loss: 0.0810, Train Acc: 0.9760, Val Loss: 0.0801, Val Acc: 0.9760\n",
      "Epoch [96/100], Train Loss: 0.0800, Train Acc: 0.9760, Val Loss: 0.0792, Val Acc: 0.9760\n",
      "Epoch [97/100], Train Loss: 0.0792, Train Acc: 0.9760, Val Loss: 0.0783, Val Acc: 0.9760\n",
      "Epoch [98/100], Train Loss: 0.0782, Train Acc: 0.9760, Val Loss: 0.0774, Val Acc: 0.9760\n",
      "Epoch [99/100], Train Loss: 0.0773, Train Acc: 0.9760, Val Loss: 0.0765, Val Acc: 0.9760\n",
      "Epoch [100/100], Train Loss: 0.0763, Train Acc: 0.9760, Val Loss: 0.0756, Val Acc: 0.9760\n",
      "Finished Training MLPModel\n",
      "Training Arm 1 (CNNModel) on Cluster 2\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/100], Train Loss: 3.8651, Train Acc: 0.1490, Val Loss: 2.8740, Val Acc: 0.4567\n",
      "Epoch [2/100], Train Loss: 2.7879, Train Acc: 0.4904, Val Loss: 2.2960, Val Acc: 0.5577\n",
      "Epoch [3/100], Train Loss: 2.2628, Train Acc: 0.5673, Val Loss: 2.0655, Val Acc: 0.7356\n",
      "Epoch [4/100], Train Loss: 2.0363, Train Acc: 0.7500, Val Loss: 1.9476, Val Acc: 0.7837\n",
      "Epoch [5/100], Train Loss: 1.9222, Train Acc: 0.7885, Val Loss: 1.8021, Val Acc: 0.7885\n",
      "Epoch [6/100], Train Loss: 1.7625, Train Acc: 0.7885, Val Loss: 1.6191, Val Acc: 0.7885\n",
      "Epoch [7/100], Train Loss: 1.5779, Train Acc: 0.7885, Val Loss: 1.4142, Val Acc: 0.7885\n",
      "Epoch [8/100], Train Loss: 1.3776, Train Acc: 0.7885, Val Loss: 1.2055, Val Acc: 0.7837\n",
      "Epoch [9/100], Train Loss: 1.1735, Train Acc: 0.7837, Val Loss: 1.0082, Val Acc: 0.7740\n",
      "Epoch [10/100], Train Loss: 0.9728, Train Acc: 0.7740, Val Loss: 0.8342, Val Acc: 0.7644\n",
      "Epoch [11/100], Train Loss: 0.8040, Train Acc: 0.7644, Val Loss: 0.6905, Val Acc: 0.7019\n",
      "Epoch [12/100], Train Loss: 0.6745, Train Acc: 0.6779, Val Loss: 0.5830, Val Acc: 0.6058\n",
      "Epoch [13/100], Train Loss: 0.5679, Train Acc: 0.5913, Val Loss: 0.5028, Val Acc: 0.6010\n",
      "Epoch [14/100], Train Loss: 0.4907, Train Acc: 0.6154, Val Loss: 0.4254, Val Acc: 0.7644\n",
      "Epoch [15/100], Train Loss: 0.4115, Train Acc: 0.8173, Val Loss: 0.3491, Val Acc: 0.9231\n",
      "Epoch [16/100], Train Loss: 0.3393, Train Acc: 0.9231, Val Loss: 0.2874, Val Acc: 0.9375\n",
      "Epoch [17/100], Train Loss: 0.2773, Train Acc: 0.9375, Val Loss: 0.2439, Val Acc: 0.9519\n",
      "Epoch [18/100], Train Loss: 0.2382, Train Acc: 0.9519, Val Loss: 0.2173, Val Acc: 0.9567\n",
      "Epoch [19/100], Train Loss: 0.2172, Train Acc: 0.9567, Val Loss: 0.2016, Val Acc: 0.9471\n",
      "Epoch [20/100], Train Loss: 0.1990, Train Acc: 0.9471, Val Loss: 0.1913, Val Acc: 0.9423\n",
      "Epoch [21/100], Train Loss: 0.1905, Train Acc: 0.9423, Val Loss: 0.1841, Val Acc: 0.9471\n",
      "Epoch [22/100], Train Loss: 0.1829, Train Acc: 0.9471, Val Loss: 0.1789, Val Acc: 0.9519\n",
      "Epoch [23/100], Train Loss: 0.1781, Train Acc: 0.9519, Val Loss: 0.1751, Val Acc: 0.9519\n",
      "Epoch [24/100], Train Loss: 0.1747, Train Acc: 0.9519, Val Loss: 0.1729, Val Acc: 0.9519\n",
      "Epoch [25/100], Train Loss: 0.1734, Train Acc: 0.9519, Val Loss: 0.1717, Val Acc: 0.9519\n",
      "Epoch [26/100], Train Loss: 0.1714, Train Acc: 0.9519, Val Loss: 0.1709, Val Acc: 0.9519\n",
      "Epoch [27/100], Train Loss: 0.1707, Train Acc: 0.9519, Val Loss: 0.1703, Val Acc: 0.9519\n",
      "Epoch [28/100], Train Loss: 0.1704, Train Acc: 0.9519, Val Loss: 0.1695, Val Acc: 0.9519\n",
      "Epoch [29/100], Train Loss: 0.1695, Train Acc: 0.9519, Val Loss: 0.1687, Val Acc: 0.9519\n",
      "Epoch [30/100], Train Loss: 0.1685, Train Acc: 0.9519, Val Loss: 0.1678, Val Acc: 0.9519\n",
      "Epoch [31/100], Train Loss: 0.1676, Train Acc: 0.9519, Val Loss: 0.1666, Val Acc: 0.9519\n",
      "Epoch [32/100], Train Loss: 0.1663, Train Acc: 0.9519, Val Loss: 0.1654, Val Acc: 0.9519\n",
      "Epoch [33/100], Train Loss: 0.1653, Train Acc: 0.9519, Val Loss: 0.1640, Val Acc: 0.9519\n",
      "Epoch [34/100], Train Loss: 0.1642, Train Acc: 0.9519, Val Loss: 0.1628, Val Acc: 0.9519\n",
      "Epoch [35/100], Train Loss: 0.1627, Train Acc: 0.9519, Val Loss: 0.1616, Val Acc: 0.9519\n",
      "Epoch [36/100], Train Loss: 0.1615, Train Acc: 0.9519, Val Loss: 0.1605, Val Acc: 0.9519\n",
      "Epoch [37/100], Train Loss: 0.1602, Train Acc: 0.9519, Val Loss: 0.1593, Val Acc: 0.9519\n",
      "Epoch [38/100], Train Loss: 0.1590, Train Acc: 0.9567, Val Loss: 0.1582, Val Acc: 0.9567\n",
      "Epoch [39/100], Train Loss: 0.1582, Train Acc: 0.9567, Val Loss: 0.1572, Val Acc: 0.9567\n",
      "Epoch [40/100], Train Loss: 0.1570, Train Acc: 0.9567, Val Loss: 0.1563, Val Acc: 0.9567\n",
      "Epoch [41/100], Train Loss: 0.1560, Train Acc: 0.9567, Val Loss: 0.1554, Val Acc: 0.9567\n",
      "Epoch [42/100], Train Loss: 0.1552, Train Acc: 0.9567, Val Loss: 0.1546, Val Acc: 0.9567\n",
      "Epoch [43/100], Train Loss: 0.1542, Train Acc: 0.9567, Val Loss: 0.1538, Val Acc: 0.9567\n",
      "Epoch [44/100], Train Loss: 0.1537, Train Acc: 0.9567, Val Loss: 0.1530, Val Acc: 0.9567\n",
      "Epoch [45/100], Train Loss: 0.1533, Train Acc: 0.9567, Val Loss: 0.1523, Val Acc: 0.9567\n",
      "Epoch [46/100], Train Loss: 0.1524, Train Acc: 0.9567, Val Loss: 0.1516, Val Acc: 0.9567\n",
      "Epoch [47/100], Train Loss: 0.1515, Train Acc: 0.9567, Val Loss: 0.1508, Val Acc: 0.9567\n",
      "Epoch [48/100], Train Loss: 0.1508, Train Acc: 0.9567, Val Loss: 0.1500, Val Acc: 0.9567\n",
      "Epoch [49/100], Train Loss: 0.1500, Train Acc: 0.9567, Val Loss: 0.1491, Val Acc: 0.9567\n",
      "Epoch [50/100], Train Loss: 0.1491, Train Acc: 0.9567, Val Loss: 0.1483, Val Acc: 0.9567\n",
      "Epoch [51/100], Train Loss: 0.1481, Train Acc: 0.9567, Val Loss: 0.1474, Val Acc: 0.9567\n",
      "Epoch [52/100], Train Loss: 0.1473, Train Acc: 0.9567, Val Loss: 0.1465, Val Acc: 0.9567\n",
      "Epoch [53/100], Train Loss: 0.1464, Train Acc: 0.9567, Val Loss: 0.1456, Val Acc: 0.9567\n",
      "Epoch [54/100], Train Loss: 0.1454, Train Acc: 0.9567, Val Loss: 0.1447, Val Acc: 0.9567\n",
      "Epoch [55/100], Train Loss: 0.1446, Train Acc: 0.9567, Val Loss: 0.1437, Val Acc: 0.9615\n",
      "Epoch [56/100], Train Loss: 0.1435, Train Acc: 0.9615, Val Loss: 0.1428, Val Acc: 0.9615\n",
      "Epoch [57/100], Train Loss: 0.1426, Train Acc: 0.9615, Val Loss: 0.1420, Val Acc: 0.9615\n",
      "Epoch [58/100], Train Loss: 0.1421, Train Acc: 0.9615, Val Loss: 0.1413, Val Acc: 0.9615\n",
      "Epoch [59/100], Train Loss: 0.1414, Train Acc: 0.9615, Val Loss: 0.1407, Val Acc: 0.9615\n",
      "Epoch [60/100], Train Loss: 0.1408, Train Acc: 0.9615, Val Loss: 0.1401, Val Acc: 0.9615\n",
      "Epoch [61/100], Train Loss: 0.1401, Train Acc: 0.9615, Val Loss: 0.1396, Val Acc: 0.9615\n",
      "Epoch [62/100], Train Loss: 0.1395, Train Acc: 0.9615, Val Loss: 0.1390, Val Acc: 0.9615\n",
      "Epoch [63/100], Train Loss: 0.1392, Train Acc: 0.9615, Val Loss: 0.1383, Val Acc: 0.9615\n",
      "Epoch [64/100], Train Loss: 0.1383, Train Acc: 0.9615, Val Loss: 0.1378, Val Acc: 0.9615\n",
      "Epoch [65/100], Train Loss: 0.1378, Train Acc: 0.9615, Val Loss: 0.1372, Val Acc: 0.9615\n",
      "Epoch [66/100], Train Loss: 0.1373, Train Acc: 0.9615, Val Loss: 0.1367, Val Acc: 0.9615\n",
      "Epoch [67/100], Train Loss: 0.1371, Train Acc: 0.9615, Val Loss: 0.1362, Val Acc: 0.9615\n",
      "Epoch [68/100], Train Loss: 0.1364, Train Acc: 0.9615, Val Loss: 0.1357, Val Acc: 0.9615\n",
      "Epoch [69/100], Train Loss: 0.1356, Train Acc: 0.9615, Val Loss: 0.1351, Val Acc: 0.9615\n",
      "Epoch [70/100], Train Loss: 0.1352, Train Acc: 0.9615, Val Loss: 0.1347, Val Acc: 0.9615\n",
      "Epoch [71/100], Train Loss: 0.1351, Train Acc: 0.9615, Val Loss: 0.1342, Val Acc: 0.9615\n",
      "Epoch [72/100], Train Loss: 0.1344, Train Acc: 0.9615, Val Loss: 0.1337, Val Acc: 0.9615\n",
      "Epoch [73/100], Train Loss: 0.1337, Train Acc: 0.9615, Val Loss: 0.1332, Val Acc: 0.9615\n",
      "Epoch [74/100], Train Loss: 0.1336, Train Acc: 0.9615, Val Loss: 0.1327, Val Acc: 0.9615\n",
      "Epoch [75/100], Train Loss: 0.1326, Train Acc: 0.9615, Val Loss: 0.1322, Val Acc: 0.9615\n",
      "Epoch [76/100], Train Loss: 0.1321, Train Acc: 0.9615, Val Loss: 0.1317, Val Acc: 0.9615\n",
      "Epoch [77/100], Train Loss: 0.1317, Train Acc: 0.9615, Val Loss: 0.1312, Val Acc: 0.9615\n",
      "Epoch [78/100], Train Loss: 0.1313, Train Acc: 0.9615, Val Loss: 0.1308, Val Acc: 0.9615\n",
      "Epoch [79/100], Train Loss: 0.1309, Train Acc: 0.9615, Val Loss: 0.1303, Val Acc: 0.9615\n",
      "Epoch [80/100], Train Loss: 0.1303, Train Acc: 0.9615, Val Loss: 0.1299, Val Acc: 0.9615\n",
      "Epoch [81/100], Train Loss: 0.1299, Train Acc: 0.9615, Val Loss: 0.1294, Val Acc: 0.9615\n",
      "Epoch [82/100], Train Loss: 0.1297, Train Acc: 0.9615, Val Loss: 0.1290, Val Acc: 0.9615\n",
      "Epoch [83/100], Train Loss: 0.1290, Train Acc: 0.9615, Val Loss: 0.1286, Val Acc: 0.9615\n",
      "Epoch [84/100], Train Loss: 0.1285, Train Acc: 0.9615, Val Loss: 0.1281, Val Acc: 0.9615\n",
      "Epoch [85/100], Train Loss: 0.1280, Train Acc: 0.9615, Val Loss: 0.1276, Val Acc: 0.9615\n",
      "Epoch [86/100], Train Loss: 0.1276, Train Acc: 0.9615, Val Loss: 0.1270, Val Acc: 0.9615\n",
      "Epoch [87/100], Train Loss: 0.1274, Train Acc: 0.9615, Val Loss: 0.1265, Val Acc: 0.9615\n",
      "Epoch [88/100], Train Loss: 0.1264, Train Acc: 0.9615, Val Loss: 0.1261, Val Acc: 0.9615\n",
      "Epoch [89/100], Train Loss: 0.1261, Train Acc: 0.9615, Val Loss: 0.1256, Val Acc: 0.9615\n",
      "Epoch [90/100], Train Loss: 0.1256, Train Acc: 0.9615, Val Loss: 0.1251, Val Acc: 0.9615\n",
      "Epoch [91/100], Train Loss: 0.1251, Train Acc: 0.9615, Val Loss: 0.1245, Val Acc: 0.9615\n",
      "Epoch [92/100], Train Loss: 0.1245, Train Acc: 0.9615, Val Loss: 0.1239, Val Acc: 0.9615\n",
      "Epoch [93/100], Train Loss: 0.1239, Train Acc: 0.9615, Val Loss: 0.1234, Val Acc: 0.9663\n",
      "Epoch [94/100], Train Loss: 0.1234, Train Acc: 0.9663, Val Loss: 0.1229, Val Acc: 0.9663\n",
      "Epoch [95/100], Train Loss: 0.1229, Train Acc: 0.9663, Val Loss: 0.1223, Val Acc: 0.9663\n",
      "Epoch [96/100], Train Loss: 0.1227, Train Acc: 0.9663, Val Loss: 0.1219, Val Acc: 0.9663\n",
      "Epoch [97/100], Train Loss: 0.1218, Train Acc: 0.9663, Val Loss: 0.1213, Val Acc: 0.9663\n",
      "Epoch [98/100], Train Loss: 0.1212, Train Acc: 0.9663, Val Loss: 0.1208, Val Acc: 0.9663\n",
      "Epoch [99/100], Train Loss: 0.1209, Train Acc: 0.9663, Val Loss: 0.1203, Val Acc: 0.9663\n",
      "Epoch [100/100], Train Loss: 0.1203, Train Acc: 0.9663, Val Loss: 0.1197, Val Acc: 0.9663\n",
      "Finished Training CNNModel\n",
      "Training Arm 2 (RNNModel) on Cluster 2\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/100], Train Loss: 0.8675, Train Acc: 0.7837, Val Loss: 0.7307, Val Acc: 0.7837\n",
      "Epoch [2/100], Train Loss: 0.7134, Train Acc: 0.7740, Val Loss: 0.6553, Val Acc: 0.7740\n",
      "Epoch [3/100], Train Loss: 0.9233, Train Acc: 0.6587, Val Loss: 0.6935, Val Acc: 0.7260\n",
      "Epoch [4/100], Train Loss: 0.6906, Train Acc: 0.7308, Val Loss: 0.5780, Val Acc: 0.7548\n",
      "Epoch [5/100], Train Loss: 0.5656, Train Acc: 0.7548, Val Loss: 0.5572, Val Acc: 0.7308\n",
      "Epoch [6/100], Train Loss: 0.5591, Train Acc: 0.7212, Val Loss: 0.5287, Val Acc: 0.6971\n",
      "Epoch [7/100], Train Loss: 0.5242, Train Acc: 0.6923, Val Loss: 0.5005, Val Acc: 0.6875\n",
      "Epoch [8/100], Train Loss: 0.4938, Train Acc: 0.6875, Val Loss: 0.4680, Val Acc: 0.6971\n",
      "Epoch [9/100], Train Loss: 0.4653, Train Acc: 0.6923, Val Loss: 0.4359, Val Acc: 0.8510\n",
      "Epoch [10/100], Train Loss: 0.4330, Train Acc: 0.8606, Val Loss: 0.4104, Val Acc: 0.8654\n",
      "Epoch [11/100], Train Loss: 0.4090, Train Acc: 0.8654, Val Loss: 0.3937, Val Acc: 0.8750\n",
      "Epoch [12/100], Train Loss: 0.3902, Train Acc: 0.8750, Val Loss: 0.3830, Val Acc: 0.8750\n",
      "Epoch [13/100], Train Loss: 0.3812, Train Acc: 0.8750, Val Loss: 0.3763, Val Acc: 0.8798\n",
      "Epoch [14/100], Train Loss: 0.3754, Train Acc: 0.8798, Val Loss: 0.3721, Val Acc: 0.8894\n",
      "Epoch [15/100], Train Loss: 0.3717, Train Acc: 0.8894, Val Loss: 0.3692, Val Acc: 0.8894\n",
      "Epoch [16/100], Train Loss: 0.3686, Train Acc: 0.8894, Val Loss: 0.3668, Val Acc: 0.8894\n",
      "Epoch [17/100], Train Loss: 0.3665, Train Acc: 0.8894, Val Loss: 0.3645, Val Acc: 0.8894\n",
      "Epoch [18/100], Train Loss: 0.3638, Train Acc: 0.8894, Val Loss: 0.3621, Val Acc: 0.8894\n",
      "Epoch [19/100], Train Loss: 0.3618, Train Acc: 0.8894, Val Loss: 0.3594, Val Acc: 0.8894\n",
      "Epoch [20/100], Train Loss: 0.3590, Train Acc: 0.8894, Val Loss: 0.3568, Val Acc: 0.8894\n",
      "Epoch [21/100], Train Loss: 0.3565, Train Acc: 0.8894, Val Loss: 0.3540, Val Acc: 0.8894\n",
      "Epoch [22/100], Train Loss: 0.3536, Train Acc: 0.8894, Val Loss: 0.3511, Val Acc: 0.8894\n",
      "Epoch [23/100], Train Loss: 0.3503, Train Acc: 0.8894, Val Loss: 0.3483, Val Acc: 0.8894\n",
      "Epoch [24/100], Train Loss: 0.3475, Train Acc: 0.8894, Val Loss: 0.3453, Val Acc: 0.8894\n",
      "Epoch [25/100], Train Loss: 0.3447, Train Acc: 0.8894, Val Loss: 0.3425, Val Acc: 0.8894\n",
      "Epoch [26/100], Train Loss: 0.3424, Train Acc: 0.8894, Val Loss: 0.3399, Val Acc: 0.8894\n",
      "Epoch [27/100], Train Loss: 0.3393, Train Acc: 0.8894, Val Loss: 0.3375, Val Acc: 0.8894\n",
      "Epoch [28/100], Train Loss: 0.3368, Train Acc: 0.8894, Val Loss: 0.3352, Val Acc: 0.8894\n",
      "Epoch [29/100], Train Loss: 0.3350, Train Acc: 0.8894, Val Loss: 0.3330, Val Acc: 0.8894\n",
      "Epoch [30/100], Train Loss: 0.3326, Train Acc: 0.8894, Val Loss: 0.3309, Val Acc: 0.8894\n",
      "Epoch [31/100], Train Loss: 0.3305, Train Acc: 0.8894, Val Loss: 0.3288, Val Acc: 0.8894\n",
      "Epoch [32/100], Train Loss: 0.3286, Train Acc: 0.8894, Val Loss: 0.3267, Val Acc: 0.8894\n",
      "Epoch [33/100], Train Loss: 0.3265, Train Acc: 0.8894, Val Loss: 0.3243, Val Acc: 0.8894\n",
      "Epoch [34/100], Train Loss: 0.3238, Train Acc: 0.8894, Val Loss: 0.3217, Val Acc: 0.8894\n",
      "Epoch [35/100], Train Loss: 0.3211, Train Acc: 0.8894, Val Loss: 0.3190, Val Acc: 0.8894\n",
      "Epoch [36/100], Train Loss: 0.3184, Train Acc: 0.8894, Val Loss: 0.3161, Val Acc: 0.8894\n",
      "Epoch [37/100], Train Loss: 0.3154, Train Acc: 0.8894, Val Loss: 0.3131, Val Acc: 0.8894\n",
      "Epoch [38/100], Train Loss: 0.3127, Train Acc: 0.8894, Val Loss: 0.3105, Val Acc: 0.8894\n",
      "Epoch [39/100], Train Loss: 0.3100, Train Acc: 0.8894, Val Loss: 0.3081, Val Acc: 0.8894\n",
      "Epoch [40/100], Train Loss: 0.3078, Train Acc: 0.8894, Val Loss: 0.3057, Val Acc: 0.8894\n",
      "Epoch [41/100], Train Loss: 0.3051, Train Acc: 0.8894, Val Loss: 0.3032, Val Acc: 0.8894\n",
      "Epoch [42/100], Train Loss: 0.3027, Train Acc: 0.8894, Val Loss: 0.3007, Val Acc: 0.8894\n",
      "Epoch [43/100], Train Loss: 0.3003, Train Acc: 0.8894, Val Loss: 0.2981, Val Acc: 0.8894\n",
      "Epoch [44/100], Train Loss: 0.2977, Train Acc: 0.8894, Val Loss: 0.2955, Val Acc: 0.8894\n",
      "Epoch [45/100], Train Loss: 0.2950, Train Acc: 0.8894, Val Loss: 0.2929, Val Acc: 0.8894\n",
      "Epoch [46/100], Train Loss: 0.2926, Train Acc: 0.8894, Val Loss: 0.2902, Val Acc: 0.8894\n",
      "Epoch [47/100], Train Loss: 0.2894, Train Acc: 0.8894, Val Loss: 0.2876, Val Acc: 0.8894\n",
      "Epoch [48/100], Train Loss: 0.2869, Train Acc: 0.8894, Val Loss: 0.2848, Val Acc: 0.8894\n",
      "Epoch [49/100], Train Loss: 0.2844, Train Acc: 0.8894, Val Loss: 0.2820, Val Acc: 0.8894\n",
      "Epoch [50/100], Train Loss: 0.2815, Train Acc: 0.8894, Val Loss: 0.2792, Val Acc: 0.8894\n",
      "Epoch [51/100], Train Loss: 0.2785, Train Acc: 0.8894, Val Loss: 0.2763, Val Acc: 0.8894\n",
      "Epoch [52/100], Train Loss: 0.2758, Train Acc: 0.8894, Val Loss: 0.2734, Val Acc: 0.8894\n",
      "Epoch [53/100], Train Loss: 0.2729, Train Acc: 0.8894, Val Loss: 0.2705, Val Acc: 0.8894\n",
      "Epoch [54/100], Train Loss: 0.2700, Train Acc: 0.8894, Val Loss: 0.2676, Val Acc: 0.8894\n",
      "Epoch [55/100], Train Loss: 0.2670, Train Acc: 0.8894, Val Loss: 0.2647, Val Acc: 0.8894\n",
      "Epoch [56/100], Train Loss: 0.2641, Train Acc: 0.8894, Val Loss: 0.2619, Val Acc: 0.8894\n",
      "Epoch [57/100], Train Loss: 0.2616, Train Acc: 0.8894, Val Loss: 0.2589, Val Acc: 0.8894\n",
      "Epoch [58/100], Train Loss: 0.2584, Train Acc: 0.8894, Val Loss: 0.2561, Val Acc: 0.8894\n",
      "Epoch [59/100], Train Loss: 0.2555, Train Acc: 0.8894, Val Loss: 0.2532, Val Acc: 0.8894\n",
      "Epoch [60/100], Train Loss: 0.2529, Train Acc: 0.8894, Val Loss: 0.2504, Val Acc: 0.8894\n",
      "Epoch [61/100], Train Loss: 0.2500, Train Acc: 0.8894, Val Loss: 0.2476, Val Acc: 0.8942\n",
      "Epoch [62/100], Train Loss: 0.2473, Train Acc: 0.8942, Val Loss: 0.2449, Val Acc: 0.8942\n",
      "Epoch [63/100], Train Loss: 0.2443, Train Acc: 0.8942, Val Loss: 0.2424, Val Acc: 0.8942\n",
      "Epoch [64/100], Train Loss: 0.2420, Train Acc: 0.8942, Val Loss: 0.2398, Val Acc: 0.9038\n",
      "Epoch [65/100], Train Loss: 0.2391, Train Acc: 0.9135, Val Loss: 0.2373, Val Acc: 0.9279\n",
      "Epoch [66/100], Train Loss: 0.2368, Train Acc: 0.9327, Val Loss: 0.2348, Val Acc: 0.9327\n",
      "Epoch [67/100], Train Loss: 0.2343, Train Acc: 0.9327, Val Loss: 0.2324, Val Acc: 0.9375\n",
      "Epoch [68/100], Train Loss: 0.2323, Train Acc: 0.9375, Val Loss: 0.2301, Val Acc: 0.9423\n",
      "Epoch [69/100], Train Loss: 0.2297, Train Acc: 0.9423, Val Loss: 0.2279, Val Acc: 0.9423\n",
      "Epoch [70/100], Train Loss: 0.2275, Train Acc: 0.9423, Val Loss: 0.2257, Val Acc: 0.9423\n",
      "Epoch [71/100], Train Loss: 0.2253, Train Acc: 0.9423, Val Loss: 0.2237, Val Acc: 0.9471\n",
      "Epoch [72/100], Train Loss: 0.2231, Train Acc: 0.9471, Val Loss: 0.2218, Val Acc: 0.9471\n",
      "Epoch [73/100], Train Loss: 0.2218, Train Acc: 0.9471, Val Loss: 0.2200, Val Acc: 0.9471\n",
      "Epoch [74/100], Train Loss: 0.2195, Train Acc: 0.9471, Val Loss: 0.2182, Val Acc: 0.9471\n",
      "Epoch [75/100], Train Loss: 0.2179, Train Acc: 0.9471, Val Loss: 0.2165, Val Acc: 0.9471\n",
      "Epoch [76/100], Train Loss: 0.2162, Train Acc: 0.9471, Val Loss: 0.2147, Val Acc: 0.9471\n",
      "Epoch [77/100], Train Loss: 0.2145, Train Acc: 0.9471, Val Loss: 0.2131, Val Acc: 0.9471\n",
      "Epoch [78/100], Train Loss: 0.2130, Train Acc: 0.9471, Val Loss: 0.2116, Val Acc: 0.9471\n",
      "Epoch [79/100], Train Loss: 0.2115, Train Acc: 0.9471, Val Loss: 0.2103, Val Acc: 0.9471\n",
      "Epoch [80/100], Train Loss: 0.2101, Train Acc: 0.9471, Val Loss: 0.2090, Val Acc: 0.9471\n",
      "Epoch [81/100], Train Loss: 0.2087, Train Acc: 0.9471, Val Loss: 0.2078, Val Acc: 0.9471\n",
      "Epoch [82/100], Train Loss: 0.2076, Train Acc: 0.9471, Val Loss: 0.2065, Val Acc: 0.9471\n",
      "Epoch [83/100], Train Loss: 0.2064, Train Acc: 0.9471, Val Loss: 0.2054, Val Acc: 0.9471\n",
      "Epoch [84/100], Train Loss: 0.2052, Train Acc: 0.9471, Val Loss: 0.2042, Val Acc: 0.9471\n",
      "Epoch [85/100], Train Loss: 0.2040, Train Acc: 0.9471, Val Loss: 0.2030, Val Acc: 0.9471\n",
      "Epoch [86/100], Train Loss: 0.2027, Train Acc: 0.9471, Val Loss: 0.2019, Val Acc: 0.9471\n",
      "Epoch [87/100], Train Loss: 0.2020, Train Acc: 0.9471, Val Loss: 0.2010, Val Acc: 0.9471\n",
      "Epoch [88/100], Train Loss: 0.2008, Train Acc: 0.9471, Val Loss: 0.2000, Val Acc: 0.9471\n",
      "Epoch [89/100], Train Loss: 0.1998, Train Acc: 0.9471, Val Loss: 0.1992, Val Acc: 0.9471\n",
      "Epoch [90/100], Train Loss: 0.1991, Train Acc: 0.9471, Val Loss: 0.1982, Val Acc: 0.9471\n",
      "Epoch [91/100], Train Loss: 0.1981, Train Acc: 0.9471, Val Loss: 0.1973, Val Acc: 0.9471\n",
      "Epoch [92/100], Train Loss: 0.1973, Train Acc: 0.9471, Val Loss: 0.1965, Val Acc: 0.9471\n",
      "Epoch [93/100], Train Loss: 0.1965, Train Acc: 0.9471, Val Loss: 0.1957, Val Acc: 0.9471\n",
      "Epoch [94/100], Train Loss: 0.1956, Train Acc: 0.9471, Val Loss: 0.1950, Val Acc: 0.9471\n",
      "Epoch [95/100], Train Loss: 0.1952, Train Acc: 0.9471, Val Loss: 0.1944, Val Acc: 0.9471\n",
      "Epoch [96/100], Train Loss: 0.1946, Train Acc: 0.9471, Val Loss: 0.1937, Val Acc: 0.9471\n",
      "Epoch [97/100], Train Loss: 0.1936, Train Acc: 0.9471, Val Loss: 0.1930, Val Acc: 0.9471\n",
      "Epoch [98/100], Train Loss: 0.1929, Train Acc: 0.9471, Val Loss: 0.1923, Val Acc: 0.9471\n",
      "Epoch [99/100], Train Loss: 0.1928, Train Acc: 0.9471, Val Loss: 0.1917, Val Acc: 0.9471\n",
      "Epoch [100/100], Train Loss: 0.1916, Train Acc: 0.9471, Val Loss: 0.1912, Val Acc: 0.9471\n",
      "Finished Training RNNModel\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.92      0.79       855\n",
      "           1       0.92      0.70      0.80      1145\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.81      0.81      0.79      2000\n",
      "weighted avg       0.83      0.80      0.80      2000\n",
      "\n",
      "Accuracy: 0.795\n",
      "Recall: 0.7004366812227074\n",
      "F1 Score: 0.7964250248262166\n",
      "ROC AUC Score: 0.8110370540616462\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# MAB Training and Evaluation\n",
    "# =====================\n",
    "arms = [mlp_model(input_dim), cnn_model(input_dim), rnn_model(input_dim)]\n",
    "mab = MultiArmedBanditDLThompsonSampling(\n",
    "    arms=arms,\n",
    "    n_clusters=3,\n",
    "    train_fn=train_dl_model,\n",
    "    eval_fn=evaluate_dl_model,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "mab.train(X_train, y_train)  \n",
    "\n",
    "y_pred_mab, arm_selected = mab.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_mab))\n",
    "accuracy = accuracy_score(y_test, y_pred_mab)\n",
    "recall = recall_score(y_test, y_pred_mab)\n",
    "f1 = f1_score(y_test, y_pred_mab)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_mab)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC Score: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "124b4d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38408, 68) (29316, 68)\n",
      "19\n",
      "[0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66] 56\n",
      "[3, 7, 13, 32, 48, 49, 50, 52, 53, 57, 59] 11\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "attacks_data = X_test_full[y_test_full == 1]\n",
    "normal_data = X_test_full[y_test_full == 0]\n",
    "print(attacks_data.shape, normal_data.shape)\n",
    "\n",
    "FUNCTIONAL_FEATURES = [\n",
    " ' min_seg_size_forward',' Bwd Header Length',' Destination Port'\n",
    " 'Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s'\n",
    " 'Total Length of Fwd Packets',' Subflow Fwd Bytes',' Max Packet Length'\n",
    " 'Bwd Packet Length Max',' Avg Bwd Segment Size',' Bwd Packet Length Mean'\n",
    " ' Fwd Packet Length Max',' Average Packet Size',' Packet Length Std'\n",
    " ' Packet Length Mean',' Bwd Packet Length Std',' Bwd Packet Length Min'\n",
    " ' Fwd Packet Length Std',' Fwd Packet Length Min',' Min Packet Length'\n",
    " ' Fwd Packet Length Mean',' Avg Fwd Segment Size',' act_data_pkt_fwd'\n",
    " ' Total Fwd Packets','Subflow Fwd Packets',' Total Backward Packets']\n",
    "print(len(FUNCTIONAL_FEATURES))\n",
    "FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c not in FUNCTIONAL_FEATURES][:-1]\n",
    "print(FUNCTIONAL_FEATURES_IDEXES, len(FUNCTIONAL_FEATURES_IDEXES))\n",
    "NON_FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c in FUNCTIONAL_FEATURES]\n",
    "print(NON_FUNCTIONAL_FEATURES_IDEXES, len(NON_FUNCTIONAL_FEATURES_IDEXES))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fc5354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier\n",
    "class Classifier(ScikitlearnClassifier):\n",
    "    \n",
    "    def __init__(self, model, clip_values=None, preprocessing=(0, 1), attacks=[]):\n",
    "        super(Classifier, self).__init__(model=model, clip_values=clip_values, preprocessing=preprocessing)\n",
    "        self._attacks = attacks\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        # Set attacks features to X\n",
    "        for i in FUNCTIONAL_FEATURES_IDEXES:\n",
    "            for j in range(len(x)):\n",
    "                x[j][i] = self._attacks[j][i]\n",
    "        predictions = self._model.predict(x)\n",
    "        return to_categorical(predictions, nb_classes=self._get_nb_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d26523df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:16<00:00, 29.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  GaussianNB()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 354 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 264 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 382 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       500\n",
      "           1       0.92      0.99      0.95       500\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.96      0.95      0.95      1000\n",
      "weighted avg       0.96      0.95      0.95      1000\n",
      "\n",
      "Accuracy:  0.952\n",
      "Detection Rate:  0.994\n",
      "F1 Score:  0.9539347408829174\n",
      "ROC AUC Score:  0.9520000000000001\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.84       500\n",
      "           1       0.90      0.71      0.80       500\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.83      0.82      0.82      1000\n",
      "weighted avg       0.83      0.82      0.82      1000\n",
      "\n",
      "Accuracy:  0.819\n",
      "Detection Rate:  0.714\n",
      "F1 Score:  0.7977653631284917\n",
      "ROC AUC Score:  0.8190000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:10<00:00, 49.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  DecisionTreeClassifier()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 408 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 128 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 464 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94       500\n",
      "           1       0.91      0.97      0.94       500\n",
      "\n",
      "    accuracy                           0.94      1000\n",
      "   macro avg       0.94      0.94      0.94      1000\n",
      "weighted avg       0.94      0.94      0.94      1000\n",
      "\n",
      "Accuracy:  0.938\n",
      "Detection Rate:  0.966\n",
      "F1 Score:  0.9396887159533074\n",
      "ROC AUC Score:  0.9380000000000001\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83       500\n",
      "           1       0.89      0.71      0.79       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n",
      "Accuracy:  0.811\n",
      "Detection Rate:  0.708\n",
      "F1 Score:  0.7892976588628762\n",
      "ROC AUC Score:  0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:10<00:00, 49.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  LogisticRegression()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 439 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 160 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 401 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78       500\n",
      "           1       0.86      0.57      0.69       500\n",
      "\n",
      "    accuracy                           0.74      1000\n",
      "   macro avg       0.77      0.74      0.73      1000\n",
      "weighted avg       0.77      0.74      0.73      1000\n",
      "\n",
      "Accuracy:  0.74\n",
      "Detection Rate:  0.57\n",
      "F1 Score:  0.6867469879518072\n",
      "ROC AUC Score:  0.7399999999999999\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.92      0.81       500\n",
      "           1       0.89      0.65      0.75       500\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.81      0.79      0.78      1000\n",
      "weighted avg       0.81      0.79      0.78      1000\n",
      "\n",
      "Accuracy:  0.785\n",
      "Detection Rate:  0.654\n",
      "F1 Score:  0.75258918296893\n",
      "ROC AUC Score:  0.785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [04:26<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  RandomForestClassifier(random_state=42)\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 369 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 153 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 478 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       500\n",
      "           1       0.91      0.91      0.91       500\n",
      "\n",
      "    accuracy                           0.91      1000\n",
      "   macro avg       0.91      0.91      0.91      1000\n",
      "weighted avg       0.91      0.91      0.91      1000\n",
      "\n",
      "Accuracy:  0.909\n",
      "Detection Rate:  0.908\n",
      "F1 Score:  0.908908908908909\n",
      "ROC AUC Score:  0.909\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.89      0.81       500\n",
      "           1       0.86      0.70      0.78       500\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.81      0.80      0.80      1000\n",
      "weighted avg       0.81      0.80      0.80      1000\n",
      "\n",
      "Accuracy:  0.797\n",
      "Detection Rate:  0.704\n",
      "F1 Score:  0.7761852260198457\n",
      "ROC AUC Score:  0.7969999999999999\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.8847499999999999\n",
      "Detection Rate:  0.8594999999999999\n",
      "F1 Score:  0.8723198384242352\n",
      "ROC AUC Score:  0.8847499999999999\n",
      "=== MAB ===\n",
      "Accuracy:  0.803\n",
      "Detection Rate:  0.6950000000000001\n",
      "F1 Score:  0.7789593577450359\n",
      "ROC AUC Score:  0.8029999999999999\n"
     ]
    }
   ],
   "source": [
    "models = [nb, dt, lr, rf]\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "\n",
    "for model in models:\n",
    "    classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=10,  max_eval=1000, init_eval=10, init_size=20)\n",
    "    \n",
    "    x_test_adv = attack.generate(attacks_data[:500], np.zeros((attacks_data[:500].shape[0], 1)))\n",
    "\n",
    "    non_adv_x_test = np.concatenate((attacks_data[:500], normal_data[:500]))\n",
    "    non_adv_y_test = np.concatenate((np.ones((attacks_data[:500].shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data[:500]))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    y_pred = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4583190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======> Attacking model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:05<00:00, 97.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 429 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 271 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 300 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       500\n",
      "           1       0.92      1.00      0.96       500\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.96      0.96      0.95      1000\n",
      "weighted avg       0.96      0.95      0.95      1000\n",
      "\n",
      "Accuracy:  0.955\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.9569377990430622\n",
      "ROC AUC Score:  0.9550000000000001\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.92      0.83       500\n",
      "           1       0.90      0.69      0.78       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.80      1000\n",
      "weighted avg       0.82      0.81      0.80      1000\n",
      "\n",
      "Accuracy:  0.806\n",
      "Detection Rate:  0.692\n",
      "F1 Score:  0.781038374717833\n",
      "ROC AUC Score:  0.806\n",
      "\n",
      "======> Attacking model: CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [01:09<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  CNNModel(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1792, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 442 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 147 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 411 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.79       500\n",
      "           1       0.87      0.59      0.70       500\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.78      0.75      0.74      1000\n",
      "weighted avg       0.78      0.75      0.74      1000\n",
      "\n",
      "Accuracy:  0.751\n",
      "Detection Rate:  0.592\n",
      "F1 Score:  0.703923900118906\n",
      "ROC AUC Score:  0.7510000000000001\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.92      0.81       500\n",
      "           1       0.89      0.64      0.75       500\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.81      0.78      0.78      1000\n",
      "weighted avg       0.81      0.78      0.78      1000\n",
      "\n",
      "Accuracy:  0.782\n",
      "Detection Rate:  0.64\n",
      "F1 Score:  0.7459207459207459\n",
      "ROC AUC Score:  0.7820000000000001\n",
      "\n",
      "======> Attacking model: RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:13<00:00, 36.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  RNNModel(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 429 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 271 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 300 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       500\n",
      "           1       0.92      1.00      0.96       500\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.96      0.96      0.95      1000\n",
      "weighted avg       0.96      0.95      0.95      1000\n",
      "\n",
      "Accuracy:  0.955\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.9569377990430622\n",
      "ROC AUC Score:  0.9550000000000001\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       500\n",
      "           1       0.89      0.72      0.80       500\n",
      "\n",
      "    accuracy                           0.82      1000\n",
      "   macro avg       0.83      0.82      0.82      1000\n",
      "weighted avg       0.83      0.82      0.82      1000\n",
      "\n",
      "Accuracy:  0.817\n",
      "Detection Rate:  0.722\n",
      "F1 Score:  0.7977900552486188\n",
      "ROC AUC Score:  0.8170000000000001\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.887\n",
      "Detection Rate:  0.864\n",
      "F1 Score:  0.8725998327350101\n",
      "ROC AUC Score:  0.8870000000000001\n",
      "=== MAB ===\n",
      "Accuracy:  0.8016666666666667\n",
      "Detection Rate:  0.6846666666666666\n",
      "F1 Score:  0.7749163919623993\n",
      "ROC AUC Score:  0.8016666666666667\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with multiple models\n",
    "models = [mlp_target, cnn_target, rnn_target]\n",
    "criterions = [criterion_mlp_model_target, criterion_cnn_model_target, criterion_rnn_model_target]\n",
    "optimizers = [optimizer_mlp_model_target, optimizer_cnn_model_target, optimizer_rnn_model_target]\n",
    "input_shapes = [(input_dim,), (input_dim, 1), (input_dim, 1)]\n",
    "model_types = ['mlp', 'cnn', 'rnn']\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "attacks_data = attacks_data.astype(np.float32)\n",
    "normal_data = normal_data.astype(np.float32)\n",
    "for i, model in enumerate(models):\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        loss=criterions[i],\n",
    "        optimizer=optimizers[i],\n",
    "        input_shape=input_shapes[i],\n",
    "        nb_classes=2,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n======> Attacking model: {model_types[i].upper()}\")\n",
    "    # Reshape d·ªØ li·ªáu theo lo·∫°i model\n",
    "    if model_types[i] == 'cnn':\n",
    "        x_input = attacks_data[:500].reshape((500, input_dim, 1))\n",
    "        normal_data_reshaped = normal_data[:500].reshape((500, input_dim, 1))\n",
    "    elif model_types[i] == 'rnn':\n",
    "        x_input = attacks_data[:500].reshape((500, input_dim, 1))\n",
    "        normal_data_reshaped = normal_data[:500].reshape((500, input_dim, 1))\n",
    "    else:\n",
    "        x_input = attacks_data[:500]\n",
    "        normal_data_reshaped = normal_data[:500]\n",
    "\n",
    "    # Sinh m·∫´u t·∫•n c√¥ng\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=10, max_eval=1000, init_eval=10, init_size=20)\n",
    "    x_test_adv = attack.generate(x_input, np.zeros((x_input.shape[0], 1)))\n",
    "\n",
    "    # G·ªôp v·ªõi d·ªØ li·ªáu b√¨nh th∆∞·ªùng\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data_reshaped))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data_reshaped.shape[0], 1))))\n",
    "    adv_x_test = adv_x_test.astype(np.float64)\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    if adv_x_test.ndim == 3:\n",
    "        adv_x_test = adv_x_test.reshape((adv_x_test.shape[0], -1))\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_pred_dqn  = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn )\n",
    "    recall = recall_score(y_true, y_pred_dqn )\n",
    "    f1 = f1_score(y_true, y_pred_dqn )\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn )\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39DQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
