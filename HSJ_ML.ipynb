{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327a3708",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset\n",
    "from intrusion_detection_systems.models import cnn_model, mlp_model, rnn_model\n",
    "from intrusion_detection_systems import train_dl_model, evaluate_dl_model\n",
    "from agent.DQN_ML_Pool import DQNModelSelector\n",
    "from agent.MAB_ML_Pool import MultiArmedBanditThompsonSampling\n",
    "\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnClassifier\n",
    "from art.utils import to_categorical\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4627c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Loading new data\n",
      "labels: {'DDoS'}\n",
      "Dataset preprocessed\n",
      "Train full shape: (158021, 68), labels distribution: (array(['0', '1'], dtype=object), array([68402, 89619], dtype=int64))\n",
      "Test full shape: (67724, 68), labels distribution: (array(['0', '1'], dtype=object), array([29316, 38408], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "name = \"CIC-IDS_2017_2\"\n",
    "df = load_data(\n",
    "            [\n",
    "                \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "            ],\n",
    "            42\n",
    "        )\n",
    "print(\"Dataset loaded\")\n",
    "df_preprocessed = preprocess_dataset(\n",
    "    df, save=True, dataset_type=\"CIC_2017\", seed=42, load=False, name_save=name, name_load=name)\n",
    "print(\"Dataset preprocessed\")\n",
    "\n",
    "X_train_full, y_train_full = df_preprocessed.x_train, df_preprocessed.y_train\n",
    "X_test_full, y_test_full = df_preprocessed.x_test, df_preprocessed.y_test\n",
    "print(f\"Train full shape: {X_train_full.shape}, labels distribution: {np.unique(y_train_full, return_counts=True)}\")\n",
    "print(f\"Test full shape: {X_test_full.shape}, labels distribution: {np.unique(y_test_full, return_counts=True)}\")\n",
    "y_train_full = np.array([int(str(x).strip()) for x in y_train_full])\n",
    "y_test_full = np.array([int(str(x).strip()) for x in y_test_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879586db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a NB Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_full, y_train_full)\n",
    "# Train a RF Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_full, y_train_full)\n",
    "# Train a DT Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_full, y_train_full)\n",
    "# Train a LR Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be17b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MLP Model ---\n",
      "MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "--- CNN Model ---\n",
      "CNNModel(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1792, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "--- RNN Model (LSTM) ---\n",
      "RNNModel(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_full.shape[1]\n",
    "#MLP Model\n",
    "mlp_model_pt = mlp_model(input_dim)\n",
    "criterion_mlp_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_pt = optim.Adam(mlp_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- MLP Model ---\")\n",
    "print(mlp_model_pt)\n",
    "print(f\"Criterion: {criterion_mlp_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_mlp_model_pt}\")\n",
    "# CNN Model\n",
    "cnn_model_pt = cnn_model(input_dim)\n",
    "criterion_cnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_pt = optim.Adam(cnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- CNN Model ---\")\n",
    "print(cnn_model_pt)\n",
    "print(f\"Criterion: {criterion_cnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_cnn_model_pt}\")\n",
    "# RNN Model\n",
    "rnn_model_pt = rnn_model(input_dim) \n",
    "criterion_rnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_pt = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- RNN Model (LSTM) ---\")\n",
    "print(rnn_model_pt)\n",
    "print(f\"Criterion: {criterion_rnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_rnn_model_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68967f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train DL models for attack\n",
    "# Chia t·∫≠p train -> train v√† validation\n",
    "X_small = X_train_full[:1000]\n",
    "y_small = y_train_full[:1000]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_small, y_small, test_size=0.2, random_state=42, stratify=y_small\n",
    ")\n",
    "\n",
    "# Chuy·ªÉn sang tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_full[:1000], dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_full[:1000], dtype=torch.long)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7fe4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/50], Train Loss: 0.6812, Train Acc: 0.5775, Val Loss: 0.6698, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6663, Train Acc: 0.5775, Val Loss: 0.6517, Val Acc: 0.5900\n",
      "Epoch [3/50], Train Loss: 0.6494, Train Acc: 0.6250, Val Loss: 0.6278, Val Acc: 0.7100\n",
      "Epoch [4/50], Train Loss: 0.6262, Train Acc: 0.6900, Val Loss: 0.5961, Val Acc: 0.7650\n",
      "Epoch [5/50], Train Loss: 0.5961, Train Acc: 0.7238, Val Loss: 0.5562, Val Acc: 0.7700\n",
      "Epoch [6/50], Train Loss: 0.5595, Train Acc: 0.7338, Val Loss: 0.5098, Val Acc: 0.7750\n",
      "Epoch [7/50], Train Loss: 0.5172, Train Acc: 0.7450, Val Loss: 0.4597, Val Acc: 0.7900\n",
      "Epoch [8/50], Train Loss: 0.4674, Train Acc: 0.7638, Val Loss: 0.4028, Val Acc: 0.8100\n",
      "Epoch [9/50], Train Loss: 0.4116, Train Acc: 0.7812, Val Loss: 0.3479, Val Acc: 0.8500\n",
      "Epoch [10/50], Train Loss: 0.3548, Train Acc: 0.8975, Val Loss: 0.2865, Val Acc: 0.9500\n",
      "Epoch [11/50], Train Loss: 0.2973, Train Acc: 0.9450, Val Loss: 0.2325, Val Acc: 0.9700\n",
      "Epoch [12/50], Train Loss: 0.2473, Train Acc: 0.9537, Val Loss: 0.1867, Val Acc: 0.9750\n",
      "Epoch [13/50], Train Loss: 0.2046, Train Acc: 0.9563, Val Loss: 0.1487, Val Acc: 0.9700\n",
      "Epoch [14/50], Train Loss: 0.1719, Train Acc: 0.9600, Val Loss: 0.1248, Val Acc: 0.9850\n",
      "Epoch [15/50], Train Loss: 0.1496, Train Acc: 0.9637, Val Loss: 0.1027, Val Acc: 0.9850\n",
      "Epoch [16/50], Train Loss: 0.1344, Train Acc: 0.9600, Val Loss: 0.0879, Val Acc: 0.9900\n",
      "Epoch [17/50], Train Loss: 0.1224, Train Acc: 0.9637, Val Loss: 0.0794, Val Acc: 0.9900\n",
      "Epoch [18/50], Train Loss: 0.1115, Train Acc: 0.9650, Val Loss: 0.0698, Val Acc: 0.9900\n",
      "Epoch [19/50], Train Loss: 0.1059, Train Acc: 0.9650, Val Loss: 0.0652, Val Acc: 0.9900\n",
      "Epoch [20/50], Train Loss: 0.0993, Train Acc: 0.9663, Val Loss: 0.0617, Val Acc: 0.9900\n",
      "Epoch [21/50], Train Loss: 0.0952, Train Acc: 0.9675, Val Loss: 0.0608, Val Acc: 0.9900\n",
      "Epoch [22/50], Train Loss: 0.0913, Train Acc: 0.9675, Val Loss: 0.0594, Val Acc: 0.9900\n",
      "Epoch [23/50], Train Loss: 0.0892, Train Acc: 0.9675, Val Loss: 0.0556, Val Acc: 0.9900\n",
      "Epoch [24/50], Train Loss: 0.0857, Train Acc: 0.9700, Val Loss: 0.0544, Val Acc: 0.9900\n",
      "Epoch [25/50], Train Loss: 0.0836, Train Acc: 0.9688, Val Loss: 0.0527, Val Acc: 0.9900\n",
      "Epoch [26/50], Train Loss: 0.0814, Train Acc: 0.9700, Val Loss: 0.0515, Val Acc: 0.9900\n",
      "Epoch [27/50], Train Loss: 0.0792, Train Acc: 0.9712, Val Loss: 0.0480, Val Acc: 0.9900\n",
      "Epoch [28/50], Train Loss: 0.0777, Train Acc: 0.9712, Val Loss: 0.0465, Val Acc: 0.9900\n",
      "Epoch [29/50], Train Loss: 0.0758, Train Acc: 0.9712, Val Loss: 0.0461, Val Acc: 0.9900\n",
      "Epoch [30/50], Train Loss: 0.0742, Train Acc: 0.9712, Val Loss: 0.0478, Val Acc: 0.9900\n",
      "Epoch [31/50], Train Loss: 0.0749, Train Acc: 0.9725, Val Loss: 0.0490, Val Acc: 0.9900\n",
      "Epoch [32/50], Train Loss: 0.0736, Train Acc: 0.9712, Val Loss: 0.0450, Val Acc: 0.9900\n",
      "Epoch [33/50], Train Loss: 0.0717, Train Acc: 0.9712, Val Loss: 0.0472, Val Acc: 0.9900\n",
      "Epoch [34/50], Train Loss: 0.0710, Train Acc: 0.9712, Val Loss: 0.0454, Val Acc: 0.9900\n",
      "Epoch [35/50], Train Loss: 0.0699, Train Acc: 0.9725, Val Loss: 0.0456, Val Acc: 0.9900\n",
      "Epoch [36/50], Train Loss: 0.0683, Train Acc: 0.9725, Val Loss: 0.0457, Val Acc: 0.9900\n",
      "Epoch [37/50], Train Loss: 0.0684, Train Acc: 0.9725, Val Loss: 0.0450, Val Acc: 0.9900\n",
      "Epoch [38/50], Train Loss: 0.0670, Train Acc: 0.9738, Val Loss: 0.0430, Val Acc: 0.9900\n",
      "Epoch [39/50], Train Loss: 0.0653, Train Acc: 0.9725, Val Loss: 0.0434, Val Acc: 0.9900\n",
      "Epoch [40/50], Train Loss: 0.0659, Train Acc: 0.9725, Val Loss: 0.0428, Val Acc: 0.9900\n",
      "Epoch [41/50], Train Loss: 0.0643, Train Acc: 0.9725, Val Loss: 0.0460, Val Acc: 0.9900\n",
      "Epoch [42/50], Train Loss: 0.0668, Train Acc: 0.9738, Val Loss: 0.0493, Val Acc: 0.9900\n",
      "Epoch [43/50], Train Loss: 0.0668, Train Acc: 0.9738, Val Loss: 0.0440, Val Acc: 0.9900\n",
      "Epoch [44/50], Train Loss: 0.0667, Train Acc: 0.9750, Val Loss: 0.0447, Val Acc: 0.9900\n",
      "Epoch [45/50], Train Loss: 0.0635, Train Acc: 0.9750, Val Loss: 0.0428, Val Acc: 0.9900\n",
      "Epoch [46/50], Train Loss: 0.0657, Train Acc: 0.9725, Val Loss: 0.0426, Val Acc: 0.9900\n",
      "Epoch [47/50], Train Loss: 0.0638, Train Acc: 0.9725, Val Loss: 0.0397, Val Acc: 0.9900\n",
      "Epoch [48/50], Train Loss: 0.0628, Train Acc: 0.9750, Val Loss: 0.0426, Val Acc: 0.9900\n",
      "Epoch [49/50], Train Loss: 0.0613, Train Acc: 0.9738, Val Loss: 0.0452, Val Acc: 0.9900\n",
      "Epoch [50/50], Train Loss: 0.0622, Train Acc: 0.9738, Val Loss: 0.0412, Val Acc: 0.9900\n",
      "Finished Training MLPModel\n",
      "\n",
      "---------- Test data (MLPModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       428\n",
      "           1       0.94      1.00      0.97       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.97      0.96      0.96      1000\n",
      "weighted avg       0.97      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.965\n",
      "Detection Rate (Recall):  1.0\n",
      "F1 Score:  0.9703138252756573\n",
      "ROC AUC Score:  0.9591121495327103\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6871, Train Acc: 0.5387, Val Loss: 0.6689, Val Acc: 0.7550\n",
      "Epoch [2/50], Train Loss: 0.6675, Train Acc: 0.6787, Val Loss: 0.6452, Val Acc: 0.6550\n",
      "Epoch [3/50], Train Loss: 0.6406, Train Acc: 0.6550, Val Loss: 0.6154, Val Acc: 0.7500\n",
      "Epoch [4/50], Train Loss: 0.6123, Train Acc: 0.7200, Val Loss: 0.5778, Val Acc: 0.7550\n",
      "Epoch [5/50], Train Loss: 0.5745, Train Acc: 0.7175, Val Loss: 0.5420, Val Acc: 0.7400\n",
      "Epoch [6/50], Train Loss: 0.5448, Train Acc: 0.7238, Val Loss: 0.5101, Val Acc: 0.7450\n",
      "Epoch [7/50], Train Loss: 0.5143, Train Acc: 0.7262, Val Loss: 0.5037, Val Acc: 0.8250\n",
      "Epoch [8/50], Train Loss: 0.4956, Train Acc: 0.8150, Val Loss: 0.4681, Val Acc: 0.7450\n",
      "Epoch [9/50], Train Loss: 0.4660, Train Acc: 0.7575, Val Loss: 0.4396, Val Acc: 0.8050\n",
      "Epoch [10/50], Train Loss: 0.4336, Train Acc: 0.8013, Val Loss: 0.4122, Val Acc: 0.8400\n",
      "Epoch [11/50], Train Loss: 0.4023, Train Acc: 0.8838, Val Loss: 0.3803, Val Acc: 0.8650\n",
      "Epoch [12/50], Train Loss: 0.3689, Train Acc: 0.9100, Val Loss: 0.3480, Val Acc: 0.8750\n",
      "Epoch [13/50], Train Loss: 0.3378, Train Acc: 0.9175, Val Loss: 0.3163, Val Acc: 0.8800\n",
      "Epoch [14/50], Train Loss: 0.3099, Train Acc: 0.9125, Val Loss: 0.2866, Val Acc: 0.9250\n",
      "Epoch [15/50], Train Loss: 0.2845, Train Acc: 0.9213, Val Loss: 0.2513, Val Acc: 0.9200\n",
      "Epoch [16/50], Train Loss: 0.2557, Train Acc: 0.9350, Val Loss: 0.2248, Val Acc: 0.9250\n",
      "Epoch [17/50], Train Loss: 0.2313, Train Acc: 0.9387, Val Loss: 0.1988, Val Acc: 0.9300\n",
      "Epoch [18/50], Train Loss: 0.2179, Train Acc: 0.9375, Val Loss: 0.1801, Val Acc: 0.9400\n",
      "Epoch [19/50], Train Loss: 0.1952, Train Acc: 0.9425, Val Loss: 0.1657, Val Acc: 0.9350\n",
      "Epoch [20/50], Train Loss: 0.1844, Train Acc: 0.9463, Val Loss: 0.1501, Val Acc: 0.9450\n",
      "Epoch [21/50], Train Loss: 0.1697, Train Acc: 0.9475, Val Loss: 0.1406, Val Acc: 0.9500\n",
      "Epoch [22/50], Train Loss: 0.1606, Train Acc: 0.9525, Val Loss: 0.1322, Val Acc: 0.9550\n",
      "Epoch [23/50], Train Loss: 0.1504, Train Acc: 0.9513, Val Loss: 0.1291, Val Acc: 0.9650\n",
      "Epoch [24/50], Train Loss: 0.1470, Train Acc: 0.9563, Val Loss: 0.1201, Val Acc: 0.9550\n",
      "Epoch [25/50], Train Loss: 0.1366, Train Acc: 0.9537, Val Loss: 0.1221, Val Acc: 0.9700\n",
      "Epoch [26/50], Train Loss: 0.1319, Train Acc: 0.9587, Val Loss: 0.1128, Val Acc: 0.9500\n",
      "Epoch [27/50], Train Loss: 0.1271, Train Acc: 0.9537, Val Loss: 0.1191, Val Acc: 0.9750\n",
      "Epoch [28/50], Train Loss: 0.1272, Train Acc: 0.9600, Val Loss: 0.1057, Val Acc: 0.9600\n",
      "Epoch [29/50], Train Loss: 0.1248, Train Acc: 0.9613, Val Loss: 0.1048, Val Acc: 0.9650\n",
      "Epoch [30/50], Train Loss: 0.1181, Train Acc: 0.9575, Val Loss: 0.1006, Val Acc: 0.9650\n",
      "Epoch [31/50], Train Loss: 0.1159, Train Acc: 0.9575, Val Loss: 0.1037, Val Acc: 0.9550\n",
      "Epoch [32/50], Train Loss: 0.1130, Train Acc: 0.9587, Val Loss: 0.0993, Val Acc: 0.9650\n",
      "Epoch [33/50], Train Loss: 0.1125, Train Acc: 0.9587, Val Loss: 0.0967, Val Acc: 0.9650\n",
      "Epoch [34/50], Train Loss: 0.1106, Train Acc: 0.9625, Val Loss: 0.0945, Val Acc: 0.9650\n",
      "Epoch [35/50], Train Loss: 0.1061, Train Acc: 0.9625, Val Loss: 0.0935, Val Acc: 0.9650\n",
      "Epoch [36/50], Train Loss: 0.1055, Train Acc: 0.9625, Val Loss: 0.0943, Val Acc: 0.9700\n",
      "Epoch [37/50], Train Loss: 0.1057, Train Acc: 0.9637, Val Loss: 0.0898, Val Acc: 0.9700\n",
      "Epoch [38/50], Train Loss: 0.1044, Train Acc: 0.9625, Val Loss: 0.0878, Val Acc: 0.9650\n",
      "Epoch [39/50], Train Loss: 0.1081, Train Acc: 0.9613, Val Loss: 0.0880, Val Acc: 0.9700\n",
      "Epoch [40/50], Train Loss: 0.1040, Train Acc: 0.9650, Val Loss: 0.0834, Val Acc: 0.9700\n",
      "Epoch [41/50], Train Loss: 0.1022, Train Acc: 0.9613, Val Loss: 0.0848, Val Acc: 0.9700\n",
      "Epoch [42/50], Train Loss: 0.0995, Train Acc: 0.9637, Val Loss: 0.0805, Val Acc: 0.9700\n",
      "Epoch [43/50], Train Loss: 0.0995, Train Acc: 0.9637, Val Loss: 0.0803, Val Acc: 0.9750\n",
      "Epoch [44/50], Train Loss: 0.1016, Train Acc: 0.9675, Val Loss: 0.0807, Val Acc: 0.9650\n",
      "Epoch [45/50], Train Loss: 0.1078, Train Acc: 0.9600, Val Loss: 0.0778, Val Acc: 0.9700\n",
      "Epoch [46/50], Train Loss: 0.0980, Train Acc: 0.9663, Val Loss: 0.0751, Val Acc: 0.9750\n",
      "Epoch [47/50], Train Loss: 0.0975, Train Acc: 0.9625, Val Loss: 0.0758, Val Acc: 0.9650\n",
      "Epoch [48/50], Train Loss: 0.0953, Train Acc: 0.9675, Val Loss: 0.0756, Val Acc: 0.9800\n",
      "Epoch [49/50], Train Loss: 0.0946, Train Acc: 0.9663, Val Loss: 0.0764, Val Acc: 0.9650\n",
      "Epoch [50/50], Train Loss: 0.0942, Train Acc: 0.9625, Val Loss: 0.0731, Val Acc: 0.9700\n",
      "Finished Training CNNModel\n",
      "\n",
      "---------- Test data (CNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       428\n",
      "           1       0.94      0.99      0.97       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.96      0.95      0.96      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.959\n",
      "Detection Rate (Recall):  0.9947552447552448\n",
      "F1 Score:  0.9652247667514843\n",
      "ROC AUC Score:  0.9529850990131364\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [3/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [4/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [5/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [6/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [7/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [8/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [9/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [10/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [11/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [12/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [13/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [14/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [15/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [16/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [17/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [18/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [19/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [20/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [21/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [22/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [23/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [24/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [25/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [26/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [27/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [28/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [29/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [30/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [31/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [32/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [33/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [34/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [35/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [36/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [37/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [38/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [39/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [40/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [41/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [42/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [43/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [44/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [45/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [46/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [47/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [48/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [49/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Epoch [50/50], Train Loss: 0.6820, Train Acc: 0.5775, Val Loss: 0.6825, Val Acc: 0.5750\n",
      "Finished Training RNNModel\n",
      "\n",
      "---------- Test data (RNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       428\n",
      "           1       0.57      1.00      0.73       572\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Accuracy:  0.572\n",
      "Detection Rate (Recall):  1.0\n",
      "F1 Score:  0.727735368956743\n",
      "ROC AUC Score:  0.5\n"
     ]
    }
   ],
   "source": [
    "#MLP Target Model \n",
    "mlp_model_target = mlp_model(input_dim)\n",
    "criterion_mlp_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_target = optim.Adam(mlp_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# CNN Target Model\n",
    "cnn_model_target = cnn_model(input_dim)\n",
    "criterion_cnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_target = optim.Adam(cnn_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# RNN Target Model\n",
    "rnn_model_target = rnn_model(input_dim) \n",
    "criterion_rnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_target = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "# ----- MLP -----\n",
    "mlp_target = train_dl_model(mlp_model_target, train_loader, val_loader, criterion_mlp_model_target, optimizer_mlp_model_target, device, num_epochs=50)\n",
    "evaluate_dl_model(mlp_target, test_loader, device,model_type='mlp', name=\"Test\")\n",
    "\n",
    "# ----- CNN -----\n",
    "cnn_target = train_dl_model(cnn_model_target, train_loader, val_loader, criterion_cnn_model_target, optimizer_cnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(cnn_target, test_loader, device,model_type='cnn', name=\"Test\")\n",
    "\n",
    "# ----- RNN -----\n",
    "rnn_target = train_dl_model(rnn_model_target, train_loader, val_loader, criterion_rnn_model_target, optimizer_rnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(rnn_target, test_loader, device,model_type='rnn', name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23575f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train): (array([0, 1]), array([423, 577], dtype=int64))\n",
      "üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test): (array([0, 1]), array([ 855, 1145], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "SUB_TRAIN = min(1000, len(X_train_full))\n",
    "SUB_TEST = min(2000, len(X_test_full))\n",
    "# S·ª≠ d·ª•ng m·∫´u nh·ªè ho·∫∑c to√†n b·ªô d·ªØ li·ªáu\n",
    "X_train, y_train = X_train_full[:SUB_TRAIN], y_train_full[:SUB_TRAIN]\n",
    "X_test, y_test = X_test_full[:SUB_TEST], y_test_full[:SUB_TEST]\n",
    "# N·∫øu mu·ªën d√πng to√†n b·ªô d·ªØ li·ªáu, b·ªè d√≤ng tr√™n v√† d√πng:\n",
    "# X_train, y_train = X_train_full, y_train_full\n",
    "# X_test, y_test = X_test_full, y_test_full\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train):\", np.unique(y_train, return_counts=True))\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test):\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "097c39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN-based selector with cluster-specific DQNs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training models for cluster 0\n",
      "Cluster 0, Epoch 1/30, Avg Reward: 0.9942\n",
      "Cluster 0, Epoch 2/30, Avg Reward: 1.0000\n",
      "Cluster 0, Epoch 3/30, Avg Reward: 0.9885\n",
      "Cluster 0, Epoch 4/30, Avg Reward: 1.0041\n",
      "Cluster 0, Epoch 5/30, Avg Reward: 0.9964\n",
      "Cluster 0, Epoch 6/30, Avg Reward: 0.9996\n",
      "Cluster 0, Epoch 7/30, Avg Reward: 1.0099\n",
      "Cluster 0, Epoch 8/30, Avg Reward: 0.9985\n",
      "Cluster 0, Epoch 9/30, Avg Reward: 0.9983\n",
      "Cluster 0, Epoch 10/30, Avg Reward: 0.9918\n",
      "Cluster 0, Epoch 11/30, Avg Reward: 1.0030\n",
      "Cluster 0, Epoch 12/30, Avg Reward: 1.0046\n",
      "Cluster 0, Epoch 13/30, Avg Reward: 0.9922\n",
      "Cluster 0, Epoch 14/30, Avg Reward: 0.9983\n",
      "Cluster 0, Epoch 15/30, Avg Reward: 0.9923\n",
      "Cluster 0, Epoch 16/30, Avg Reward: 0.9955\n",
      "Cluster 0, Epoch 17/30, Avg Reward: 1.0072\n",
      "Cluster 0, Epoch 18/30, Avg Reward: 1.0002\n",
      "Cluster 0, Epoch 19/30, Avg Reward: 0.9945\n",
      "Cluster 0, Epoch 20/30, Avg Reward: 0.9997\n",
      "Cluster 0, Epoch 21/30, Avg Reward: 0.9991\n",
      "Cluster 0, Epoch 22/30, Avg Reward: 0.9989\n",
      "Cluster 0, Epoch 23/30, Avg Reward: 0.9921\n",
      "Cluster 0, Epoch 24/30, Avg Reward: 1.0052\n",
      "Cluster 0, Epoch 25/30, Avg Reward: 1.0068\n",
      "Cluster 0, Epoch 26/30, Avg Reward: 1.0063\n",
      "Cluster 0, Epoch 27/30, Avg Reward: 1.0017\n",
      "Cluster 0, Epoch 28/30, Avg Reward: 1.0067\n",
      "Cluster 0, Epoch 29/30, Avg Reward: 0.9931\n",
      "Cluster 0, Epoch 30/30, Avg Reward: 1.0066\n",
      "\n",
      " Training models for cluster 1\n",
      "Cluster 1, Epoch 1/30, Avg Reward: 0.9708\n",
      "Cluster 1, Epoch 2/30, Avg Reward: 0.9779\n",
      "Cluster 1, Epoch 3/30, Avg Reward: 0.9943\n",
      "Cluster 1, Epoch 4/30, Avg Reward: 0.9784\n",
      "Cluster 1, Epoch 5/30, Avg Reward: 0.9840\n",
      "Cluster 1, Epoch 6/30, Avg Reward: 0.9715\n",
      "Cluster 1, Epoch 7/30, Avg Reward: 0.9861\n",
      "Cluster 1, Epoch 8/30, Avg Reward: 0.9756\n",
      "Cluster 1, Epoch 9/30, Avg Reward: 0.9905\n",
      "Cluster 1, Epoch 10/30, Avg Reward: 0.9963\n",
      "Cluster 1, Epoch 11/30, Avg Reward: 0.9791\n",
      "Cluster 1, Epoch 12/30, Avg Reward: 0.9766\n",
      "Cluster 1, Epoch 13/30, Avg Reward: 0.9626\n",
      "Cluster 1, Epoch 14/30, Avg Reward: 0.9781\n",
      "Cluster 1, Epoch 15/30, Avg Reward: 0.9814\n",
      "Cluster 1, Epoch 16/30, Avg Reward: 0.9780\n",
      "Cluster 1, Epoch 17/30, Avg Reward: 0.9909\n",
      "Cluster 1, Epoch 18/30, Avg Reward: 0.9782\n",
      "Cluster 1, Epoch 19/30, Avg Reward: 0.9777\n",
      "Cluster 1, Epoch 20/30, Avg Reward: 0.9998\n",
      "Cluster 1, Epoch 21/30, Avg Reward: 0.9998\n",
      "Cluster 1, Epoch 22/30, Avg Reward: 0.9973\n",
      "Cluster 1, Epoch 23/30, Avg Reward: 0.9861\n",
      "Cluster 1, Epoch 24/30, Avg Reward: 0.9945\n",
      "Cluster 1, Epoch 25/30, Avg Reward: 0.9754\n",
      "Cluster 1, Epoch 26/30, Avg Reward: 0.9749\n",
      "Cluster 1, Epoch 27/30, Avg Reward: 0.9990\n",
      "Cluster 1, Epoch 28/30, Avg Reward: 0.9939\n",
      "Cluster 1, Epoch 29/30, Avg Reward: 0.9866\n",
      "Cluster 1, Epoch 30/30, Avg Reward: 0.9954\n",
      "\n",
      " Training models for cluster 2\n",
      "Cluster 2, Epoch 1/30, Avg Reward: 1.0006\n",
      "Cluster 2, Epoch 2/30, Avg Reward: 1.0053\n",
      "Cluster 2, Epoch 3/30, Avg Reward: 0.9965\n",
      "Cluster 2, Epoch 4/30, Avg Reward: 0.9969\n",
      "Cluster 2, Epoch 5/30, Avg Reward: 1.0037\n",
      "Cluster 2, Epoch 6/30, Avg Reward: 1.0033\n",
      "Cluster 2, Epoch 7/30, Avg Reward: 1.0002\n",
      "Cluster 2, Epoch 8/30, Avg Reward: 1.0065\n",
      "Cluster 2, Epoch 9/30, Avg Reward: 1.0032\n",
      "Cluster 2, Epoch 10/30, Avg Reward: 1.0070\n",
      "Cluster 2, Epoch 11/30, Avg Reward: 1.0025\n",
      "Cluster 2, Epoch 12/30, Avg Reward: 0.9999\n",
      "Cluster 2, Epoch 13/30, Avg Reward: 1.0140\n",
      "Cluster 2, Epoch 14/30, Avg Reward: 0.9946\n",
      "Cluster 2, Epoch 15/30, Avg Reward: 0.9964\n",
      "Cluster 2, Epoch 16/30, Avg Reward: 0.9812\n",
      "Cluster 2, Epoch 17/30, Avg Reward: 0.9950\n",
      "Cluster 2, Epoch 18/30, Avg Reward: 1.0049\n",
      "Cluster 2, Epoch 19/30, Avg Reward: 1.0116\n",
      "Cluster 2, Epoch 20/30, Avg Reward: 1.0024\n",
      "Cluster 2, Epoch 21/30, Avg Reward: 0.9985\n",
      "Cluster 2, Epoch 22/30, Avg Reward: 0.9884\n",
      "Cluster 2, Epoch 23/30, Avg Reward: 0.9909\n",
      "Cluster 2, Epoch 24/30, Avg Reward: 1.0010\n",
      "Cluster 2, Epoch 25/30, Avg Reward: 0.9930\n",
      "Cluster 2, Epoch 26/30, Avg Reward: 1.0030\n",
      "Cluster 2, Epoch 27/30, Avg Reward: 1.0073\n",
      "Cluster 2, Epoch 28/30, Avg Reward: 1.0049\n",
      "Cluster 2, Epoch 29/30, Avg Reward: 1.0027\n",
      "Cluster 2, Epoch 30/30, Avg Reward: 1.0134\n",
      "Predicting on test set...\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 477 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 571 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 952 l·∫ßn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       855\n",
      "           1       1.00      1.00      1.00      1145\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Accuracy: 0.9975\n",
      "Recall (macro): 0.9970760233918128\n",
      "F1 Score (macro): 0.9974443997214395\n",
      "ROC AUC: 0.9970760233918129\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# DQN Training and Evaluation\n",
    "# =====================\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "dqn = DQNModelSelector(models, n_clusters=3)\n",
    "\n",
    "print(\"Training DQN-based selector with cluster-specific DQNs...\")\n",
    "dqn.train(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_dqn, arms = dqn.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_dqn = np.array([int(x) for x in y_pred_dqn])\n",
    "\n",
    "print(classification_report(y_test, y_pred_dqn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dqn))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dqn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26381ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 713 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training arm 0 on cluster 0\n",
      "cluster_X_train shape: (713, 68)\n",
      "cluster_y_train shape: (713,)\n",
      "arm_mask shape: (713,)\n",
      "Training arm 1 on cluster 0\n",
      "cluster_X_train shape: (713, 68)\n",
      "cluster_y_train shape: (713,)\n",
      "arm_mask shape: (713,)\n",
      "Training arm 2 on cluster 0\n",
      "cluster_X_train shape: (713, 68)\n",
      "cluster_y_train shape: (713,)\n",
      "arm_mask shape: (713,)\n",
      "Cluster 1: 287 samples\n",
      "Training arm 0 on cluster 1\n",
      "cluster_X_train shape: (287, 68)\n",
      "cluster_y_train shape: (287,)\n",
      "arm_mask shape: (287,)\n",
      "Training arm 1 on cluster 1\n",
      "cluster_X_train shape: (287, 68)\n",
      "cluster_y_train shape: (287,)\n",
      "arm_mask shape: (287,)\n",
      "Training arm 2 on cluster 1\n",
      "cluster_X_train shape: (287, 68)\n",
      "cluster_y_train shape: (287,)\n",
      "arm_mask shape: (287,)\n",
      "Setting reward_sums arm 0 on cluster 0\n",
      "Setting reward_sums arm 1 on cluster 0\n",
      "Setting reward_sums arm 2 on cluster 0\n",
      "Setting reward_sums arm 0 on cluster 1\n",
      "Setting reward_sums arm 1 on cluster 1\n",
      "Setting reward_sums arm 2 on cluster 1\n"
     ]
    }
   ],
   "source": [
    "# Train the MAB\n",
    "mab = MultiArmedBanditThompsonSampling(n_arms=3, n_clusters=2)\n",
    "mab.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd7bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       855\n",
      "           1       1.00      0.99      1.00      1145\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      1.00      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Accuracy: 0.9945\n",
      "Recall (macro): 0.9950483924512883\n",
      "F1 Score (macro): 0.9943892422391105\n",
      "ROC AUC: 0.9950483924512884\n"
     ]
    }
   ],
   "source": [
    "y_pred_mab, selected_arms = mab.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_mab = np.array([int(x) for x in y_pred_mab])\n",
    "\n",
    "print(classification_report(y_test, y_pred_mab))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mab))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_mab, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_mab, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_mab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a9f3812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38408, 68) (29316, 68)\n",
      "19\n",
      "[0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66] 56\n",
      "[3, 7, 13, 32, 48, 49, 50, 52, 53, 57, 59] 11\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "attacks_data = X_test_full[y_test_full == 1]\n",
    "normal_data = X_test_full[y_test_full == 0]\n",
    "print(attacks_data.shape, normal_data.shape)\n",
    "\n",
    "FUNCTIONAL_FEATURES = [\n",
    " ' min_seg_size_forward',' Bwd Header Length',' Destination Port'\n",
    " 'Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s'\n",
    " 'Total Length of Fwd Packets',' Subflow Fwd Bytes',' Max Packet Length'\n",
    " 'Bwd Packet Length Max',' Avg Bwd Segment Size',' Bwd Packet Length Mean'\n",
    " ' Fwd Packet Length Max',' Average Packet Size',' Packet Length Std'\n",
    " ' Packet Length Mean',' Bwd Packet Length Std',' Bwd Packet Length Min'\n",
    " ' Fwd Packet Length Std',' Fwd Packet Length Min',' Min Packet Length'\n",
    " ' Fwd Packet Length Mean',' Avg Fwd Segment Size',' act_data_pkt_fwd'\n",
    " ' Total Fwd Packets','Subflow Fwd Packets',' Total Backward Packets']\n",
    "print(len(FUNCTIONAL_FEATURES))\n",
    "FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c not in FUNCTIONAL_FEATURES][:-1]\n",
    "print(FUNCTIONAL_FEATURES_IDEXES, len(FUNCTIONAL_FEATURES_IDEXES))\n",
    "NON_FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c in FUNCTIONAL_FEATURES]\n",
    "print(NON_FUNCTIONAL_FEATURES_IDEXES, len(NON_FUNCTIONAL_FEATURES_IDEXES))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f091fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier\n",
    "class Classifier(ScikitlearnClassifier):\n",
    "    \n",
    "    def __init__(self, model, clip_values=None, preprocessing=(0, 1), attacks=[]):\n",
    "        super(Classifier, self).__init__(model=model, clip_values=clip_values, preprocessing=preprocessing)\n",
    "        self._attacks = attacks\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        # Set attacks features to X\n",
    "        for i in FUNCTIONAL_FEATURES_IDEXES:\n",
    "            for j in range(len(x)):\n",
    "                x[j][i] = self._attacks[j][i]\n",
    "        predictions = self._model.predict(x)\n",
    "        return to_categorical(predictions, nb_classes=self._get_nb_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fe9575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:13<00:00, 36.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  GaussianNB()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 422 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 356 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 222 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       500\n",
      "           1       0.99      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.996\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.9960159362549801\n",
      "ROC AUC Score:  0.996\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       500\n",
      "           1       1.00      0.98      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.99\n",
      "Detection Rate:  0.982\n",
      "F1 Score:  0.9899193548387097\n",
      "ROC AUC Score:  0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:09<00:00, 53.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  DecisionTreeClassifier()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 478 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 278 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 244 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93       500\n",
      "           1       0.99      0.86      0.92       500\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n",
      "Accuracy:  0.926\n",
      "Detection Rate:  0.86\n",
      "F1 Score:  0.9207708779443254\n",
      "ROC AUC Score:  0.9259999999999999\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       500\n",
      "           1       1.00      0.96      0.98       500\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Accuracy:  0.979\n",
      "Detection Rate:  0.958\n",
      "F1 Score:  0.9785495403472931\n",
      "ROC AUC Score:  0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:10<00:00, 49.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  LogisticRegression()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 488 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 156 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 356 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.99      0.78       500\n",
      "           1       0.98      0.46      0.62       500\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.81      0.72      0.70      1000\n",
      "weighted avg       0.81      0.72      0.70      1000\n",
      "\n",
      "Accuracy:  0.725\n",
      "Detection Rate:  0.458\n",
      "F1 Score:  0.6248294679399727\n",
      "ROC AUC Score:  0.7249999999999999\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77       500\n",
      "           1       1.00      0.39      0.56       500\n",
      "\n",
      "    accuracy                           0.70      1000\n",
      "   macro avg       0.81      0.70      0.67      1000\n",
      "weighted avg       0.81      0.70      0.67      1000\n",
      "\n",
      "Accuracy:  0.696\n",
      "Detection Rate:  0.392\n",
      "F1 Score:  0.5632183908045978\n",
      "ROC AUC Score:  0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [04:18<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  RandomForestClassifier(random_state=42)\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 523 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 239 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 238 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       500\n",
      "           1       0.99      0.95      0.97       500\n",
      "\n",
      "    accuracy                           0.97      1000\n",
      "   macro avg       0.97      0.97      0.97      1000\n",
      "weighted avg       0.97      0.97      0.97      1000\n",
      "\n",
      "Accuracy:  0.97\n",
      "Detection Rate:  0.948\n",
      "F1 Score:  0.969325153374233\n",
      "ROC AUC Score:  0.97\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95       500\n",
      "           1       0.99      0.91      0.95       500\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.96      0.95      0.95      1000\n",
      "weighted avg       0.96      0.95      0.95      1000\n",
      "\n",
      "Accuracy:  0.952\n",
      "Detection Rate:  0.91\n",
      "F1 Score:  0.9498956158663884\n",
      "ROC AUC Score:  0.9520000000000001\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.90425\n",
      "Detection Rate:  0.8165\n",
      "F1 Score:  0.8777353588783777\n",
      "ROC AUC Score:  0.90425\n",
      "=== MAB ===\n",
      "Accuracy:  0.90425\n",
      "Detection Rate:  0.8105\n",
      "F1 Score:  0.8703957254642473\n",
      "ROC AUC Score:  0.90425\n"
     ]
    }
   ],
   "source": [
    "models = [nb, dt, lr, rf]\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "\n",
    "for model in models:\n",
    "    classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=10,  max_eval=1000, init_eval=10, init_size=20)\n",
    "    \n",
    "    x_test_adv = attack.generate(attacks_data[:500], np.zeros((attacks_data[:500].shape[0], 1)))\n",
    "\n",
    "    non_adv_x_test = np.concatenate((attacks_data[:500], normal_data[:500]))\n",
    "    non_adv_y_test = np.concatenate((np.ones((attacks_data[:500].shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data[:500]))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    y_pred_dqn = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn)\n",
    "    recall = recall_score(y_true, y_pred_dqn)\n",
    "    f1 = f1_score(y_true, y_pred_dqn)\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28efb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======> Attacking model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:04<00:00, 102.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 269 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 262 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 469 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       500\n",
      "           1       0.99      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.996\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.9960159362549801\n",
      "ROC AUC Score:  0.996\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       500\n",
      "           1       1.00      0.99      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.996\n",
      "Detection Rate:  0.994\n",
      "F1 Score:  0.9959919839679359\n",
      "ROC AUC Score:  0.996\n",
      "\n",
      "======> Attacking model: CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [01:10<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  CNNModel(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1792, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 469 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 166 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 365 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.99      0.80       500\n",
      "           1       0.98      0.50      0.66       500\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.82      0.75      0.73      1000\n",
      "weighted avg       0.82      0.75      0.73      1000\n",
      "\n",
      "Accuracy:  0.746\n",
      "Detection Rate:  0.5\n",
      "F1 Score:  0.6631299734748011\n",
      "ROC AUC Score:  0.746\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.75       500\n",
      "           1       0.99      0.35      0.52       500\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.80      0.68      0.64      1000\n",
      "weighted avg       0.80      0.68      0.64      1000\n",
      "\n",
      "Accuracy:  0.675\n",
      "Detection Rate:  0.352\n",
      "F1 Score:  0.5199409158050221\n",
      "ROC AUC Score:  0.6749999999999999\n",
      "\n",
      "======> Attacking model: RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:14<00:00, 34.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  RNNModel(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 269 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 262 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 469 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       500\n",
      "           1       0.99      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.996\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.9960159362549801\n",
      "ROC AUC Score:  0.996\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       500\n",
      "           1       1.00      0.99      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.997\n",
      "Detection Rate:  0.994\n",
      "F1 Score:  0.9969909729187563\n",
      "ROC AUC Score:  0.997\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.9126666666666666\n",
      "Detection Rate:  0.8333333333333334\n",
      "F1 Score:  0.885053948661587\n",
      "ROC AUC Score:  0.9126666666666666\n",
      "=== MAB ===\n",
      "Accuracy:  0.8893333333333334\n",
      "Detection Rate:  0.7799999999999999\n",
      "F1 Score:  0.837641290897238\n",
      "ROC AUC Score:  0.8893333333333332\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with multiple models\n",
    "models = [mlp_target, cnn_target, rnn_target]\n",
    "criterions = [criterion_mlp_model_target, criterion_cnn_model_target, criterion_rnn_model_target]\n",
    "optimizers = [optimizer_mlp_model_target, optimizer_cnn_model_target, optimizer_rnn_model_target]\n",
    "input_shapes = [(input_dim,), (input_dim, 1), (input_dim, 1)]\n",
    "model_types = ['mlp', 'cnn', 'rnn']\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "attacks_data = attacks_data.astype(np.float32)\n",
    "normal_data = normal_data.astype(np.float32)\n",
    "for i, model in enumerate(models):\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        loss=criterions[i],\n",
    "        optimizer=optimizers[i],\n",
    "        input_shape=input_shapes[i],\n",
    "        nb_classes=2,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n======> Attacking model: {model_types[i].upper()}\")\n",
    "    # Reshape d·ªØ li·ªáu theo lo·∫°i model\n",
    "    if model_types[i] == 'cnn':\n",
    "        x_input = attacks_data[:500].reshape((500, input_dim, 1))\n",
    "        normal_data_reshaped = normal_data[:500].reshape((500, input_dim, 1))\n",
    "    elif model_types[i] == 'rnn':\n",
    "        x_input = attacks_data[:500].reshape((500, input_dim, 1))\n",
    "        normal_data_reshaped = normal_data[:500].reshape((500, input_dim, 1))\n",
    "    else:\n",
    "        x_input = attacks_data[:500]\n",
    "        normal_data_reshaped = normal_data[:500]\n",
    "\n",
    "    # Sinh m·∫´u t·∫•n c√¥ng\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=10, max_eval=1000, init_eval=10, init_size=20)\n",
    "    x_test_adv = attack.generate(x_input, np.zeros((x_input.shape[0], 1)))\n",
    "\n",
    "    # G·ªôp v·ªõi d·ªØ li·ªáu b√¨nh th∆∞·ªùng\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data_reshaped))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data_reshaped.shape[0], 1))))\n",
    "    adv_x_test = adv_x_test.astype(np.float64)\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    if adv_x_test.ndim == 3:\n",
    "        adv_x_test = adv_x_test.reshape((adv_x_test.shape[0], -1))\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_pred_dqn  = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn )\n",
    "    recall = recall_score(y_true, y_pred_dqn )\n",
    "    f1 = f1_score(y_true, y_pred_dqn )\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn )\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39DQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
