{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327a3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from shared.utils import load_data\n",
    "from datasets import preprocess_dataset\n",
    "from intrusion_detection_systems.models import cnn_model, mlp_model, rnn_model\n",
    "from intrusion_detection_systems import train_dl_model, evaluate_dl_model\n",
    "from agent.DQN_ML_Pool import DQNModelSelector\n",
    "from agent.MAB_ML_Pool import MultiArmedBanditThompsonSampling\n",
    "\n",
    "from art.estimators.classification.scikitlearn import ScikitlearnClassifier\n",
    "from art.utils import to_categorical\n",
    "from art.attacks.evasion import HopSkipJump\n",
    "from art.estimators.classification import SklearnClassifier\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4627c6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded\n",
      "Loading new data\n",
      "labels: {'DDoS'}\n",
      "Dataset preprocessed\n",
      "Train full shape: (158021, 68), labels distribution: (array(['0', '1'], dtype=object), array([68402, 89619], dtype=int64))\n",
      "Test full shape: (67724, 68), labels distribution: (array(['0', '1'], dtype=object), array([29316, 38408], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "name = \"CIC-IDS_2017_2\"\n",
    "df = load_data(\n",
    "            [\n",
    "                \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Friday-WorkingHours-Morning.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Monday-WorkingHours.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\"\n",
    "                # \"./shared/data/CIC_2017/Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\",\n",
    "                # \"./shared/data/CIC_2017/Tuesday-WorkingHours.pcap_ISCX.csv\"\n",
    "            ],\n",
    "            42\n",
    "        )\n",
    "print(\"Dataset loaded\")\n",
    "df_preprocessed = preprocess_dataset(\n",
    "    df, save=True, dataset_type=\"CIC_2017\", seed=42, load=False, name_save=name, name_load=name)\n",
    "print(\"Dataset preprocessed\")\n",
    "\n",
    "X_train_full, y_train_full = df_preprocessed.x_train, df_preprocessed.y_train\n",
    "X_test_full, y_test_full = df_preprocessed.x_test, df_preprocessed.y_test\n",
    "print(f\"Train full shape: {X_train_full.shape}, labels distribution: {np.unique(y_train_full, return_counts=True)}\")\n",
    "print(f\"Test full shape: {X_test_full.shape}, labels distribution: {np.unique(y_test_full, return_counts=True)}\")\n",
    "y_train_full = np.array([int(str(x).strip()) for x in y_train_full])\n",
    "y_test_full = np.array([int(str(x).strip()) for x in y_test_full])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879586db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a NB Classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_full, y_train_full)\n",
    "# Train a RF Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_full, y_train_full)\n",
    "# Train a DT Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_full, y_train_full)\n",
    "# Train a LR Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3be17b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- MLP Model ---\n",
      "MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "--- CNN Model ---\n",
      "CNNModel(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1792, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "--- RNN Model (LSTM) ---\n",
      "RNNModel(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Criterion: CrossEntropyLoss()\n",
      "Optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.001\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train_full.shape[1]\n",
    "#MLP Model\n",
    "mlp_model_pt = mlp_model(input_dim)\n",
    "criterion_mlp_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_pt = optim.Adam(mlp_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- MLP Model ---\")\n",
    "print(mlp_model_pt)\n",
    "print(f\"Criterion: {criterion_mlp_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_mlp_model_pt}\")\n",
    "# CNN Model\n",
    "cnn_model_pt = cnn_model(input_dim)\n",
    "criterion_cnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_pt = optim.Adam(cnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- CNN Model ---\")\n",
    "print(cnn_model_pt)\n",
    "print(f\"Criterion: {criterion_cnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_cnn_model_pt}\")\n",
    "# RNN Model\n",
    "rnn_model_pt = rnn_model(input_dim) \n",
    "criterion_rnn_model_pt = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_pt = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "print(\"--- RNN Model (LSTM) ---\")\n",
    "print(rnn_model_pt)\n",
    "print(f\"Criterion: {criterion_rnn_model_pt}\")\n",
    "print(f\"Optimizer: {optimizer_rnn_model_pt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68967f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train DL models for attack\n",
    "# Chia t·∫≠p train -> train v√† validation\n",
    "X_small = X_train_full[:1000]\n",
    "y_small = y_train_full[:1000]\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_small, y_small, test_size=0.2, random_state=42, stratify=y_small\n",
    ")\n",
    "\n",
    "# Chuy·ªÉn sang tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_full[:1000], dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_full[:1000], dtype=torch.long)\n",
    "\n",
    "# Dataloader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e7fe4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training MLPModel ---\n",
      "Epoch [1/50], Train Loss: 0.6900, Train Acc: 0.5650, Val Loss: 0.6784, Val Acc: 0.6550\n",
      "Epoch [2/50], Train Loss: 0.6734, Train Acc: 0.6000, Val Loss: 0.6606, Val Acc: 0.5750\n",
      "Epoch [3/50], Train Loss: 0.6558, Train Acc: 0.6012, Val Loss: 0.6393, Val Acc: 0.6550\n",
      "Epoch [4/50], Train Loss: 0.6361, Train Acc: 0.6500, Val Loss: 0.6120, Val Acc: 0.7200\n",
      "Epoch [5/50], Train Loss: 0.6091, Train Acc: 0.7025, Val Loss: 0.5778, Val Acc: 0.7400\n",
      "Epoch [6/50], Train Loss: 0.5783, Train Acc: 0.7188, Val Loss: 0.5395, Val Acc: 0.7700\n",
      "Epoch [7/50], Train Loss: 0.5413, Train Acc: 0.7312, Val Loss: 0.4954, Val Acc: 0.7700\n",
      "Epoch [8/50], Train Loss: 0.4983, Train Acc: 0.7475, Val Loss: 0.4458, Val Acc: 0.7850\n",
      "Epoch [9/50], Train Loss: 0.4504, Train Acc: 0.7650, Val Loss: 0.3923, Val Acc: 0.8250\n",
      "Epoch [10/50], Train Loss: 0.3982, Train Acc: 0.7875, Val Loss: 0.3356, Val Acc: 0.8550\n",
      "Epoch [11/50], Train Loss: 0.3430, Train Acc: 0.8812, Val Loss: 0.2768, Val Acc: 0.9450\n",
      "Epoch [12/50], Train Loss: 0.2900, Train Acc: 0.9463, Val Loss: 0.2294, Val Acc: 0.9750\n",
      "Epoch [13/50], Train Loss: 0.2423, Train Acc: 0.9563, Val Loss: 0.1835, Val Acc: 0.9750\n",
      "Epoch [14/50], Train Loss: 0.2014, Train Acc: 0.9563, Val Loss: 0.1475, Val Acc: 0.9800\n",
      "Epoch [15/50], Train Loss: 0.1705, Train Acc: 0.9625, Val Loss: 0.1210, Val Acc: 0.9800\n",
      "Epoch [16/50], Train Loss: 0.1506, Train Acc: 0.9563, Val Loss: 0.0990, Val Acc: 0.9800\n",
      "Epoch [17/50], Train Loss: 0.1301, Train Acc: 0.9650, Val Loss: 0.0900, Val Acc: 0.9850\n",
      "Epoch [18/50], Train Loss: 0.1189, Train Acc: 0.9637, Val Loss: 0.0749, Val Acc: 0.9900\n",
      "Epoch [19/50], Train Loss: 0.1120, Train Acc: 0.9625, Val Loss: 0.0688, Val Acc: 0.9900\n",
      "Epoch [20/50], Train Loss: 0.1049, Train Acc: 0.9675, Val Loss: 0.0717, Val Acc: 0.9900\n",
      "Epoch [21/50], Train Loss: 0.0993, Train Acc: 0.9688, Val Loss: 0.0614, Val Acc: 0.9900\n",
      "Epoch [22/50], Train Loss: 0.0972, Train Acc: 0.9650, Val Loss: 0.0571, Val Acc: 0.9900\n",
      "Epoch [23/50], Train Loss: 0.0916, Train Acc: 0.9675, Val Loss: 0.0583, Val Acc: 0.9900\n",
      "Epoch [24/50], Train Loss: 0.0890, Train Acc: 0.9700, Val Loss: 0.0542, Val Acc: 0.9900\n",
      "Epoch [25/50], Train Loss: 0.0877, Train Acc: 0.9688, Val Loss: 0.0510, Val Acc: 0.9900\n",
      "Epoch [26/50], Train Loss: 0.0857, Train Acc: 0.9700, Val Loss: 0.0515, Val Acc: 0.9900\n",
      "Epoch [27/50], Train Loss: 0.0808, Train Acc: 0.9712, Val Loss: 0.0492, Val Acc: 0.9900\n",
      "Epoch [28/50], Train Loss: 0.0794, Train Acc: 0.9700, Val Loss: 0.0472, Val Acc: 0.9900\n",
      "Epoch [29/50], Train Loss: 0.0784, Train Acc: 0.9700, Val Loss: 0.0468, Val Acc: 0.9900\n",
      "Epoch [30/50], Train Loss: 0.0758, Train Acc: 0.9712, Val Loss: 0.0465, Val Acc: 0.9900\n",
      "Epoch [31/50], Train Loss: 0.0754, Train Acc: 0.9725, Val Loss: 0.0462, Val Acc: 0.9900\n",
      "Epoch [32/50], Train Loss: 0.0737, Train Acc: 0.9712, Val Loss: 0.0437, Val Acc: 0.9900\n",
      "Epoch [33/50], Train Loss: 0.0722, Train Acc: 0.9712, Val Loss: 0.0455, Val Acc: 0.9900\n",
      "Epoch [34/50], Train Loss: 0.0716, Train Acc: 0.9712, Val Loss: 0.0434, Val Acc: 0.9900\n",
      "Epoch [35/50], Train Loss: 0.0739, Train Acc: 0.9725, Val Loss: 0.0456, Val Acc: 0.9900\n",
      "Epoch [36/50], Train Loss: 0.0695, Train Acc: 0.9712, Val Loss: 0.0435, Val Acc: 0.9900\n",
      "Epoch [37/50], Train Loss: 0.0687, Train Acc: 0.9712, Val Loss: 0.0441, Val Acc: 0.9900\n",
      "Epoch [38/50], Train Loss: 0.0675, Train Acc: 0.9725, Val Loss: 0.0444, Val Acc: 0.9900\n",
      "Epoch [39/50], Train Loss: 0.0666, Train Acc: 0.9725, Val Loss: 0.0440, Val Acc: 0.9900\n",
      "Epoch [40/50], Train Loss: 0.0667, Train Acc: 0.9712, Val Loss: 0.0422, Val Acc: 0.9900\n",
      "Epoch [41/50], Train Loss: 0.0652, Train Acc: 0.9725, Val Loss: 0.0427, Val Acc: 0.9900\n",
      "Epoch [42/50], Train Loss: 0.0637, Train Acc: 0.9725, Val Loss: 0.0443, Val Acc: 0.9900\n",
      "Epoch [43/50], Train Loss: 0.0640, Train Acc: 0.9738, Val Loss: 0.0465, Val Acc: 0.9900\n",
      "Epoch [44/50], Train Loss: 0.0630, Train Acc: 0.9738, Val Loss: 0.0445, Val Acc: 0.9900\n",
      "Epoch [45/50], Train Loss: 0.0639, Train Acc: 0.9750, Val Loss: 0.0422, Val Acc: 0.9900\n",
      "Epoch [46/50], Train Loss: 0.0625, Train Acc: 0.9750, Val Loss: 0.0413, Val Acc: 0.9900\n",
      "Epoch [47/50], Train Loss: 0.0621, Train Acc: 0.9738, Val Loss: 0.0400, Val Acc: 0.9900\n",
      "Epoch [48/50], Train Loss: 0.0629, Train Acc: 0.9725, Val Loss: 0.0386, Val Acc: 0.9900\n",
      "Epoch [49/50], Train Loss: 0.0640, Train Acc: 0.9738, Val Loss: 0.0421, Val Acc: 0.9900\n",
      "Epoch [50/50], Train Loss: 0.0616, Train Acc: 0.9750, Val Loss: 0.0423, Val Acc: 0.9900\n",
      "Finished Training MLPModel\n",
      "\n",
      "---------- Test data (MLPModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       428\n",
      "           1       0.94      1.00      0.97       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.97      0.96      0.96      1000\n",
      "weighted avg       0.97      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.965\n",
      "Detection Rate (Recall):  1.0\n",
      "F1 Score:  0.9703138252756573\n",
      "ROC AUC Score:  0.9591121495327103\n",
      "\n",
      "--- Training CNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6760, Train Acc: 0.5775, Val Loss: 0.6582, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6530, Train Acc: 0.6125, Val Loss: 0.6294, Val Acc: 0.6650\n",
      "Epoch [3/50], Train Loss: 0.6291, Train Acc: 0.6725, Val Loss: 0.5972, Val Acc: 0.7500\n",
      "Epoch [4/50], Train Loss: 0.5997, Train Acc: 0.7113, Val Loss: 0.5628, Val Acc: 0.7400\n",
      "Epoch [5/50], Train Loss: 0.5627, Train Acc: 0.7238, Val Loss: 0.5284, Val Acc: 0.7400\n",
      "Epoch [6/50], Train Loss: 0.5360, Train Acc: 0.7250, Val Loss: 0.5048, Val Acc: 0.7400\n",
      "Epoch [7/50], Train Loss: 0.5146, Train Acc: 0.7288, Val Loss: 0.4869, Val Acc: 0.7350\n",
      "Epoch [8/50], Train Loss: 0.4971, Train Acc: 0.7275, Val Loss: 0.4798, Val Acc: 0.8200\n",
      "Epoch [9/50], Train Loss: 0.4922, Train Acc: 0.8300, Val Loss: 0.4568, Val Acc: 0.7400\n",
      "Epoch [10/50], Train Loss: 0.4571, Train Acc: 0.7288, Val Loss: 0.4274, Val Acc: 0.8350\n",
      "Epoch [11/50], Train Loss: 0.4248, Train Acc: 0.8875, Val Loss: 0.4001, Val Acc: 0.7600\n",
      "Epoch [12/50], Train Loss: 0.4063, Train Acc: 0.7412, Val Loss: 0.3695, Val Acc: 0.8750\n",
      "Epoch [13/50], Train Loss: 0.3765, Train Acc: 0.8988, Val Loss: 0.3435, Val Acc: 0.8750\n",
      "Epoch [14/50], Train Loss: 0.3428, Train Acc: 0.9100, Val Loss: 0.3162, Val Acc: 0.8850\n",
      "Epoch [15/50], Train Loss: 0.3181, Train Acc: 0.8925, Val Loss: 0.2844, Val Acc: 0.9200\n",
      "Epoch [16/50], Train Loss: 0.2843, Train Acc: 0.9200, Val Loss: 0.2560, Val Acc: 0.9200\n",
      "Epoch [17/50], Train Loss: 0.2584, Train Acc: 0.9363, Val Loss: 0.2306, Val Acc: 0.9250\n",
      "Epoch [18/50], Train Loss: 0.2365, Train Acc: 0.9387, Val Loss: 0.2094, Val Acc: 0.9250\n",
      "Epoch [19/50], Train Loss: 0.2203, Train Acc: 0.9387, Val Loss: 0.1974, Val Acc: 0.9450\n",
      "Epoch [20/50], Train Loss: 0.2105, Train Acc: 0.9487, Val Loss: 0.1807, Val Acc: 0.9300\n",
      "Epoch [21/50], Train Loss: 0.1970, Train Acc: 0.9437, Val Loss: 0.1603, Val Acc: 0.9600\n",
      "Epoch [22/50], Train Loss: 0.1782, Train Acc: 0.9513, Val Loss: 0.1459, Val Acc: 0.9400\n",
      "Epoch [23/50], Train Loss: 0.1713, Train Acc: 0.9463, Val Loss: 0.1347, Val Acc: 0.9600\n",
      "Epoch [24/50], Train Loss: 0.1566, Train Acc: 0.9525, Val Loss: 0.1264, Val Acc: 0.9600\n",
      "Epoch [25/50], Train Loss: 0.1488, Train Acc: 0.9525, Val Loss: 0.1212, Val Acc: 0.9600\n",
      "Epoch [26/50], Train Loss: 0.1419, Train Acc: 0.9563, Val Loss: 0.1174, Val Acc: 0.9650\n",
      "Epoch [27/50], Train Loss: 0.1394, Train Acc: 0.9600, Val Loss: 0.1145, Val Acc: 0.9600\n",
      "Epoch [28/50], Train Loss: 0.1326, Train Acc: 0.9550, Val Loss: 0.1130, Val Acc: 0.9650\n",
      "Epoch [29/50], Train Loss: 0.1294, Train Acc: 0.9587, Val Loss: 0.1079, Val Acc: 0.9600\n",
      "Epoch [30/50], Train Loss: 0.1257, Train Acc: 0.9613, Val Loss: 0.1039, Val Acc: 0.9650\n",
      "Epoch [31/50], Train Loss: 0.1343, Train Acc: 0.9537, Val Loss: 0.1050, Val Acc: 0.9650\n",
      "Epoch [32/50], Train Loss: 0.1168, Train Acc: 0.9625, Val Loss: 0.1002, Val Acc: 0.9750\n",
      "Epoch [33/50], Train Loss: 0.1153, Train Acc: 0.9637, Val Loss: 0.0928, Val Acc: 0.9650\n",
      "Epoch [34/50], Train Loss: 0.1137, Train Acc: 0.9625, Val Loss: 0.0923, Val Acc: 0.9700\n",
      "Epoch [35/50], Train Loss: 0.1117, Train Acc: 0.9637, Val Loss: 0.0889, Val Acc: 0.9650\n",
      "Epoch [36/50], Train Loss: 0.1184, Train Acc: 0.9600, Val Loss: 0.0876, Val Acc: 0.9650\n",
      "Epoch [37/50], Train Loss: 0.1113, Train Acc: 0.9650, Val Loss: 0.0900, Val Acc: 0.9750\n",
      "Epoch [38/50], Train Loss: 0.1067, Train Acc: 0.9625, Val Loss: 0.0884, Val Acc: 0.9600\n",
      "Epoch [39/50], Train Loss: 0.1065, Train Acc: 0.9587, Val Loss: 0.0872, Val Acc: 0.9750\n",
      "Epoch [40/50], Train Loss: 0.1037, Train Acc: 0.9663, Val Loss: 0.0855, Val Acc: 0.9700\n",
      "Epoch [41/50], Train Loss: 0.1046, Train Acc: 0.9625, Val Loss: 0.0836, Val Acc: 0.9650\n",
      "Epoch [42/50], Train Loss: 0.1018, Train Acc: 0.9613, Val Loss: 0.0882, Val Acc: 0.9750\n",
      "Epoch [43/50], Train Loss: 0.0999, Train Acc: 0.9637, Val Loss: 0.0843, Val Acc: 0.9700\n",
      "Epoch [44/50], Train Loss: 0.1021, Train Acc: 0.9600, Val Loss: 0.0813, Val Acc: 0.9750\n",
      "Epoch [45/50], Train Loss: 0.0982, Train Acc: 0.9650, Val Loss: 0.0774, Val Acc: 0.9750\n",
      "Epoch [46/50], Train Loss: 0.0964, Train Acc: 0.9637, Val Loss: 0.0783, Val Acc: 0.9750\n",
      "Epoch [47/50], Train Loss: 0.0980, Train Acc: 0.9675, Val Loss: 0.0769, Val Acc: 0.9750\n",
      "Epoch [48/50], Train Loss: 0.0953, Train Acc: 0.9625, Val Loss: 0.0762, Val Acc: 0.9750\n",
      "Epoch [49/50], Train Loss: 0.0941, Train Acc: 0.9637, Val Loss: 0.0722, Val Acc: 0.9750\n",
      "Epoch [50/50], Train Loss: 0.0947, Train Acc: 0.9663, Val Loss: 0.0702, Val Acc: 0.9750\n",
      "Finished Training CNNModel\n",
      "\n",
      "---------- Test data (CNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95       428\n",
      "           1       0.93      0.99      0.96       572\n",
      "\n",
      "    accuracy                           0.96      1000\n",
      "   macro avg       0.96      0.95      0.96      1000\n",
      "weighted avg       0.96      0.96      0.96      1000\n",
      "\n",
      "Accuracy:  0.957\n",
      "Detection Rate (Recall):  0.9947552447552448\n",
      "F1 Score:  0.9635901778154107\n",
      "ROC AUC Score:  0.9506486504150056\n",
      "\n",
      "--- Training RNNModel ---\n",
      "Epoch [1/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [2/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [3/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [4/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [5/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [6/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [7/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [8/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [9/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [10/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [11/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [12/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [13/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [14/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [15/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [16/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [17/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [18/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [19/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [20/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [21/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [22/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [23/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [24/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [25/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [26/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [27/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [28/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [29/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [30/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [31/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [32/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [33/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [34/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [35/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [36/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [37/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [38/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [39/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [40/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [41/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [42/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [43/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [44/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [45/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [46/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [47/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [48/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [49/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Epoch [50/50], Train Loss: 0.6831, Train Acc: 0.5775, Val Loss: 0.6836, Val Acc: 0.5750\n",
      "Finished Training RNNModel\n",
      "\n",
      "---------- Test data (RNNModel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       428\n",
      "           1       0.57      1.00      0.73       572\n",
      "\n",
      "    accuracy                           0.57      1000\n",
      "   macro avg       0.29      0.50      0.36      1000\n",
      "weighted avg       0.33      0.57      0.42      1000\n",
      "\n",
      "Accuracy:  0.572\n",
      "Detection Rate (Recall):  1.0\n",
      "F1 Score:  0.727735368956743\n",
      "ROC AUC Score:  0.5\n"
     ]
    }
   ],
   "source": [
    "#MLP Target Model \n",
    "mlp_model_target = mlp_model(input_dim)\n",
    "criterion_mlp_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_mlp_model_target = optim.Adam(mlp_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# CNN Target Model\n",
    "cnn_model_target = cnn_model(input_dim)\n",
    "criterion_cnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_cnn_model_target = optim.Adam(cnn_model_target.parameters(), lr=0.001)\n",
    "\n",
    "# RNN Target Model\n",
    "rnn_model_target = rnn_model(input_dim) \n",
    "criterion_rnn_model_target = nn.CrossEntropyLoss()\n",
    "optimizer_rnn_model_target = optim.Adam(rnn_model_pt.parameters(), lr=0.001)\n",
    "\n",
    "# ----- MLP -----\n",
    "mlp_target = train_dl_model(mlp_model_target, train_loader, val_loader, criterion_mlp_model_target, optimizer_mlp_model_target, device, num_epochs=50)\n",
    "evaluate_dl_model(mlp_target, test_loader, device,model_type='mlp', name=\"Test\")\n",
    "\n",
    "# ----- CNN -----\n",
    "cnn_target = train_dl_model(cnn_model_target, train_loader, val_loader, criterion_cnn_model_target, optimizer_cnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(cnn_target, test_loader, device,model_type='cnn', name=\"Test\")\n",
    "\n",
    "# ----- RNN -----\n",
    "rnn_target = train_dl_model(rnn_model_target, train_loader, val_loader, criterion_rnn_model_target, optimizer_rnn_model_target, device,num_epochs=50)\n",
    "evaluate_dl_model(rnn_target, test_loader, device,model_type='rnn', name=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23575f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train): (array([0, 1]), array([423, 577], dtype=int64))\n",
      "üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test): (array([0, 1]), array([ 855, 1145], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "SUB_TRAIN = min(1000, len(X_train_full))\n",
    "SUB_TEST = min(2000, len(X_test_full))\n",
    "# S·ª≠ d·ª•ng m·∫´u nh·ªè ho·∫∑c to√†n b·ªô d·ªØ li·ªáu\n",
    "X_train, y_train = X_train_full[:SUB_TRAIN], y_train_full[:SUB_TRAIN]\n",
    "X_test, y_test = X_test_full[:SUB_TEST], y_test_full[:SUB_TEST]\n",
    "# N·∫øu mu·ªën d√πng to√†n b·ªô d·ªØ li·ªáu, b·ªè d√≤ng tr√™n v√† d√πng:\n",
    "# X_train, y_train = X_train_full, y_train_full\n",
    "# X_test, y_test = X_test_full, y_test_full\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p hu·∫•n luy·ªán (y_train):\", np.unique(y_train, return_counts=True))\n",
    "print(\"üìå Nh√£n c·ªßa t·∫≠p ki·ªÉm th·ª≠ (y_test):\", np.unique(y_test, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "097c39bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN-based selector with cluster-specific DQNs...\n",
      "\n",
      " Training models for cluster 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Epoch 1/30, Avg Reward: 0.9908\n",
      "Cluster 0, Epoch 2/30, Avg Reward: 0.9922\n",
      "Cluster 0, Epoch 3/30, Avg Reward: 0.9905\n",
      "Cluster 0, Epoch 4/30, Avg Reward: 0.9988\n",
      "Cluster 0, Epoch 5/30, Avg Reward: 0.9946\n",
      "Cluster 0, Epoch 6/30, Avg Reward: 1.0039\n",
      "Cluster 0, Epoch 7/30, Avg Reward: 0.9990\n",
      "Cluster 0, Epoch 8/30, Avg Reward: 0.9968\n",
      "Cluster 0, Epoch 9/30, Avg Reward: 1.0003\n",
      "Cluster 0, Epoch 10/30, Avg Reward: 0.9982\n",
      "Cluster 0, Epoch 11/30, Avg Reward: 1.0069\n",
      "Cluster 0, Epoch 12/30, Avg Reward: 1.0057\n",
      "Cluster 0, Epoch 13/30, Avg Reward: 0.9780\n",
      "Cluster 0, Epoch 14/30, Avg Reward: 0.9990\n",
      "Cluster 0, Epoch 15/30, Avg Reward: 1.0009\n",
      "Cluster 0, Epoch 16/30, Avg Reward: 1.0019\n",
      "Cluster 0, Epoch 17/30, Avg Reward: 1.0012\n",
      "Cluster 0, Epoch 18/30, Avg Reward: 1.0138\n",
      "Cluster 0, Epoch 19/30, Avg Reward: 1.0005\n",
      "Cluster 0, Epoch 20/30, Avg Reward: 0.9971\n",
      "Cluster 0, Epoch 21/30, Avg Reward: 1.0039\n",
      "Cluster 0, Epoch 22/30, Avg Reward: 0.9982\n",
      "Cluster 0, Epoch 23/30, Avg Reward: 1.0036\n",
      "Cluster 0, Epoch 24/30, Avg Reward: 0.9916\n",
      "Cluster 0, Epoch 25/30, Avg Reward: 1.0037\n",
      "Cluster 0, Epoch 26/30, Avg Reward: 0.9941\n",
      "Cluster 0, Epoch 27/30, Avg Reward: 0.9973\n",
      "Cluster 0, Epoch 28/30, Avg Reward: 1.0023\n",
      "Cluster 0, Epoch 29/30, Avg Reward: 1.0020\n",
      "Cluster 0, Epoch 30/30, Avg Reward: 1.0015\n",
      "\n",
      " Training models for cluster 1\n",
      "Cluster 1, Epoch 1/30, Avg Reward: 0.9795\n",
      "Cluster 1, Epoch 2/30, Avg Reward: 0.9934\n",
      "Cluster 1, Epoch 3/30, Avg Reward: 0.9897\n",
      "Cluster 1, Epoch 4/30, Avg Reward: 0.9875\n",
      "Cluster 1, Epoch 5/30, Avg Reward: 0.9780\n",
      "Cluster 1, Epoch 6/30, Avg Reward: 0.9815\n",
      "Cluster 1, Epoch 7/30, Avg Reward: 0.9747\n",
      "Cluster 1, Epoch 8/30, Avg Reward: 0.9832\n",
      "Cluster 1, Epoch 9/30, Avg Reward: 0.9920\n",
      "Cluster 1, Epoch 10/30, Avg Reward: 0.9927\n",
      "Cluster 1, Epoch 11/30, Avg Reward: 0.9770\n",
      "Cluster 1, Epoch 12/30, Avg Reward: 0.9883\n",
      "Cluster 1, Epoch 13/30, Avg Reward: 0.9905\n",
      "Cluster 1, Epoch 14/30, Avg Reward: 0.9908\n",
      "Cluster 1, Epoch 15/30, Avg Reward: 1.0064\n",
      "Cluster 1, Epoch 16/30, Avg Reward: 0.9819\n",
      "Cluster 1, Epoch 17/30, Avg Reward: 0.9799\n",
      "Cluster 1, Epoch 18/30, Avg Reward: 0.9866\n",
      "Cluster 1, Epoch 19/30, Avg Reward: 0.9750\n",
      "Cluster 1, Epoch 20/30, Avg Reward: 0.9830\n",
      "Cluster 1, Epoch 21/30, Avg Reward: 0.9837\n",
      "Cluster 1, Epoch 22/30, Avg Reward: 0.9890\n",
      "Cluster 1, Epoch 23/30, Avg Reward: 0.9791\n",
      "Cluster 1, Epoch 24/30, Avg Reward: 0.9836\n",
      "Cluster 1, Epoch 25/30, Avg Reward: 0.9785\n",
      "Cluster 1, Epoch 26/30, Avg Reward: 0.9752\n",
      "Cluster 1, Epoch 27/30, Avg Reward: 0.9905\n",
      "Cluster 1, Epoch 28/30, Avg Reward: 0.9885\n",
      "Cluster 1, Epoch 29/30, Avg Reward: 0.9819\n",
      "Cluster 1, Epoch 30/30, Avg Reward: 0.9913\n",
      "\n",
      " Training models for cluster 2\n",
      "Cluster 2, Epoch 1/30, Avg Reward: 0.9974\n",
      "Cluster 2, Epoch 2/30, Avg Reward: 1.0000\n",
      "Cluster 2, Epoch 3/30, Avg Reward: 1.0080\n",
      "Cluster 2, Epoch 4/30, Avg Reward: 1.0036\n",
      "Cluster 2, Epoch 5/30, Avg Reward: 1.0009\n",
      "Cluster 2, Epoch 6/30, Avg Reward: 0.9951\n",
      "Cluster 2, Epoch 7/30, Avg Reward: 1.0016\n",
      "Cluster 2, Epoch 8/30, Avg Reward: 0.9873\n",
      "Cluster 2, Epoch 9/30, Avg Reward: 0.9946\n",
      "Cluster 2, Epoch 10/30, Avg Reward: 0.9942\n",
      "Cluster 2, Epoch 11/30, Avg Reward: 0.9965\n",
      "Cluster 2, Epoch 12/30, Avg Reward: 0.9977\n",
      "Cluster 2, Epoch 13/30, Avg Reward: 1.0055\n",
      "Cluster 2, Epoch 14/30, Avg Reward: 1.0012\n",
      "Cluster 2, Epoch 15/30, Avg Reward: 0.9974\n",
      "Cluster 2, Epoch 16/30, Avg Reward: 0.9971\n",
      "Cluster 2, Epoch 17/30, Avg Reward: 0.9982\n",
      "Cluster 2, Epoch 18/30, Avg Reward: 0.9930\n",
      "Cluster 2, Epoch 19/30, Avg Reward: 0.9982\n",
      "Cluster 2, Epoch 20/30, Avg Reward: 1.0028\n",
      "Cluster 2, Epoch 21/30, Avg Reward: 0.9883\n",
      "Cluster 2, Epoch 22/30, Avg Reward: 1.0016\n",
      "Cluster 2, Epoch 23/30, Avg Reward: 1.0141\n",
      "Cluster 2, Epoch 24/30, Avg Reward: 0.9997\n",
      "Cluster 2, Epoch 25/30, Avg Reward: 0.9985\n",
      "Cluster 2, Epoch 26/30, Avg Reward: 1.0029\n",
      "Cluster 2, Epoch 27/30, Avg Reward: 0.9984\n",
      "Cluster 2, Epoch 28/30, Avg Reward: 0.9940\n",
      "Cluster 2, Epoch 29/30, Avg Reward: 0.9982\n",
      "Cluster 2, Epoch 30/30, Avg Reward: 1.0081\n",
      "Predicting on test set...\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 625 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 999 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 376 l·∫ßn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       855\n",
      "           1       1.00      1.00      1.00      1145\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Accuracy: 0.9985\n",
      "Recall (macro): 0.9982456140350877\n",
      "F1 Score (macro): 0.9984671005283138\n",
      "ROC AUC: 0.9982456140350877\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# DQN Training and Evaluation\n",
    "# =====================\n",
    "models = [\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "dqn = DQNModelSelector(models, n_clusters=3)\n",
    "\n",
    "print(\"Training DQN-based selector with cluster-specific DQNs...\")\n",
    "dqn.train(X_train, y_train)\n",
    "\n",
    "print(\"Predicting on test set...\")\n",
    "y_pred_dqn, arms = dqn.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_dqn = np.array([int(x) for x in y_pred_dqn])\n",
    "\n",
    "print(classification_report(y_test, y_pred_dqn))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dqn))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_dqn, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_dqn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26381ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\py39DQN\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: 96 samples\n",
      "Training arm 0 on cluster 0\n",
      "cluster_X_train shape: (96, 68)\n",
      "cluster_y_train shape: (96,)\n",
      "arm_mask shape: (96,)\n",
      "Training arm 1 on cluster 0\n",
      "cluster_X_train shape: (96, 68)\n",
      "cluster_y_train shape: (96,)\n",
      "arm_mask shape: (96,)\n",
      "Training arm 2 on cluster 0\n",
      "cluster_X_train shape: (96, 68)\n",
      "cluster_y_train shape: (96,)\n",
      "arm_mask shape: (96,)\n",
      "Cluster 1: 904 samples\n",
      "Training arm 0 on cluster 1\n",
      "cluster_X_train shape: (904, 68)\n",
      "cluster_y_train shape: (904,)\n",
      "arm_mask shape: (904,)\n",
      "Training arm 1 on cluster 1\n",
      "cluster_X_train shape: (904, 68)\n",
      "cluster_y_train shape: (904,)\n",
      "arm_mask shape: (904,)\n",
      "Training arm 2 on cluster 1\n",
      "cluster_X_train shape: (904, 68)\n",
      "cluster_y_train shape: (904,)\n",
      "arm_mask shape: (904,)\n",
      "Setting reward_sums arm 0 on cluster 0\n",
      "Setting reward_sums arm 1 on cluster 0\n",
      "Setting reward_sums arm 2 on cluster 0\n",
      "Setting reward_sums arm 0 on cluster 1\n",
      "Setting reward_sums arm 1 on cluster 1\n",
      "Setting reward_sums arm 2 on cluster 1\n"
     ]
    }
   ],
   "source": [
    "# Train the MAB\n",
    "mab = MultiArmedBanditThompsonSampling(n_arms=3, n_clusters=2)\n",
    "mab.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebd7bffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       855\n",
      "           1       1.00      0.99      1.00      1145\n",
      "\n",
      "    accuracy                           0.99      2000\n",
      "   macro avg       0.99      0.99      0.99      2000\n",
      "weighted avg       0.99      0.99      0.99      2000\n",
      "\n",
      "Accuracy: 0.9945\n",
      "Recall (macro): 0.9947521642534283\n",
      "F1 Score (macro): 0.994386000727268\n",
      "ROC AUC: 0.9947521642534283\n"
     ]
    }
   ],
   "source": [
    "y_pred_mab, selected_arms = mab.predict(X_test)\n",
    "\n",
    "if isinstance(y_test, pd.DataFrame):\n",
    "    if \"Label\" in y_test.columns:\n",
    "        y_test = y_test[\"Label\"].values\n",
    "    else:\n",
    "        y_test = y_test.iloc[:, 0].values\n",
    "elif isinstance(y_test, pd.Series):\n",
    "    y_test = y_test.values\n",
    "\n",
    "y_test = np.array([int(str(x).strip()) for x in y_test])\n",
    "y_pred_mab = np.array([int(x) for x in y_pred_mab])\n",
    "\n",
    "print(classification_report(y_test, y_pred_mab))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_mab))\n",
    "print(\"Recall (macro):\", recall_score(y_test, y_pred_mab, average='macro'))\n",
    "print(\"F1 Score (macro):\", f1_score(y_test, y_pred_mab, average='macro'))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_mab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a9f3812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38408, 68) (29316, 68)\n",
      "19\n",
      "[0, 1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66] 56\n",
      "[3, 7, 13, 32, 48, 49, 50, 52, 53, 57, 59] 11\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "attacks_data = X_test_full[y_test_full == 1]\n",
    "normal_data = X_test_full[y_test_full == 0]\n",
    "print(attacks_data.shape, normal_data.shape)\n",
    "\n",
    "FUNCTIONAL_FEATURES = [\n",
    " ' min_seg_size_forward',' Bwd Header Length',' Destination Port'\n",
    " 'Init_Win_bytes_forward',' Init_Win_bytes_backward',' Bwd Packets/s'\n",
    " 'Total Length of Fwd Packets',' Subflow Fwd Bytes',' Max Packet Length'\n",
    " 'Bwd Packet Length Max',' Avg Bwd Segment Size',' Bwd Packet Length Mean'\n",
    " ' Fwd Packet Length Max',' Average Packet Size',' Packet Length Std'\n",
    " ' Packet Length Mean',' Bwd Packet Length Std',' Bwd Packet Length Min'\n",
    " ' Fwd Packet Length Std',' Fwd Packet Length Min',' Min Packet Length'\n",
    " ' Fwd Packet Length Mean',' Avg Fwd Segment Size',' act_data_pkt_fwd'\n",
    " ' Total Fwd Packets','Subflow Fwd Packets',' Total Backward Packets']\n",
    "print(len(FUNCTIONAL_FEATURES))\n",
    "FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c not in FUNCTIONAL_FEATURES][:-1]\n",
    "print(FUNCTIONAL_FEATURES_IDEXES, len(FUNCTIONAL_FEATURES_IDEXES))\n",
    "NON_FUNCTIONAL_FEATURES_IDEXES = [df.columns.get_loc(c) for c in df.columns if c in FUNCTIONAL_FEATURES]\n",
    "print(NON_FUNCTIONAL_FEATURES_IDEXES, len(NON_FUNCTIONAL_FEATURES_IDEXES))\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f091fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ART classifier\n",
    "class Classifier(ScikitlearnClassifier):\n",
    "    \n",
    "    def __init__(self, model, clip_values=None, preprocessing=(0, 1), attacks=[]):\n",
    "        super(Classifier, self).__init__(model=model, clip_values=clip_values, preprocessing=preprocessing)\n",
    "        self._attacks = attacks\n",
    "\n",
    "    def predict(self, x, **kwargs):\n",
    "        # Set attacks features to X\n",
    "        for i in FUNCTIONAL_FEATURES_IDEXES:\n",
    "            for j in range(len(x)):\n",
    "                x[j][i] = self._attacks[j][i]\n",
    "        predictions = self._model.predict(x)\n",
    "        return to_categorical(predictions, nb_classes=self._get_nb_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe9575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:12<00:00, 38.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  GaussianNB()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 330 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 347 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 323 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.997\n",
      "Detection Rate:  0.998\n",
      "F1 Score:  0.997002997002997\n",
      "ROC AUC Score:  0.997\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       500\n",
      "           1       1.00      0.97      0.98       500\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n",
      "Accuracy:  0.982\n",
      "Detection Rate:  0.966\n",
      "F1 Score:  0.9817073170731708\n",
      "ROC AUC Score:  0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:08<00:00, 57.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  DecisionTreeClassifier()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 379 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 345 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 276 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       500\n",
      "           1       1.00      0.99      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.993\n",
      "Detection Rate:  0.99\n",
      "F1 Score:  0.9929789368104314\n",
      "ROC AUC Score:  0.993\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       500\n",
      "           1       1.00      0.98      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.992\n",
      "Detection Rate:  0.984\n",
      "F1 Score:  0.9919354838709677\n",
      "ROC AUC Score:  0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:09<00:00, 53.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  LogisticRegression()\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 395 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 266 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 339 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       500\n",
      "           1       0.99      0.57      0.73       500\n",
      "\n",
      "    accuracy                           0.78      1000\n",
      "   macro avg       0.85      0.78      0.77      1000\n",
      "weighted avg       0.85      0.78      0.77      1000\n",
      "\n",
      "Accuracy:  0.784\n",
      "Detection Rate:  0.572\n",
      "F1 Score:  0.7258883248730965\n",
      "ROC AUC Score:  0.784\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71       500\n",
      "           1       0.99      0.17      0.29       500\n",
      "\n",
      "    accuracy                           0.58      1000\n",
      "   macro avg       0.77      0.58      0.50      1000\n",
      "weighted avg       0.77      0.58      0.50      1000\n",
      "\n",
      "Accuracy:  0.583\n",
      "Detection Rate:  0.168\n",
      "F1 Score:  0.2871794871794872\n",
      "ROC AUC Score:  0.583\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.9246666666666666\n",
      "Detection Rate:  0.8533333333333334\n",
      "F1 Score:  0.9052900862288417\n",
      "ROC AUC Score:  0.9246666666666666\n",
      "=== MAB ===\n",
      "Accuracy:  0.8523333333333333\n",
      "Detection Rate:  0.706\n",
      "F1 Score:  0.7536074293745418\n",
      "ROC AUC Score:  0.8523333333333333\n"
     ]
    }
   ],
   "source": [
    "models = [nb, dt, lr, rf]\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "\n",
    "for model in models:\n",
    "    classifier = SklearnClassifier(model=model, clip_values=(0, 1))\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=10,  max_eval=1000, init_eval=10, init_size=20)\n",
    "    \n",
    "    x_test_adv = attack.generate(attacks_data[:500], np.zeros((attacks_data[:500].shape[0], 1)))\n",
    "\n",
    "    non_adv_x_test = np.concatenate((attacks_data[:500], normal_data[:500]))\n",
    "    non_adv_y_test = np.concatenate((np.ones((attacks_data[:500].shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data[:500]))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data[:500].shape[0], 1))))\n",
    "\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    y_pred_dqn = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn)\n",
    "    recall = recall_score(y_true, y_pred_dqn)\n",
    "    f1 = f1_score(y_true, y_pred_dqn)\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn)\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28efb127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======> Attacking model: MLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:06<00:00, 79.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  MLPModel(\n",
      "  (fc1): Linear(in_features=68, out_features=128, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (fc3): Linear(in_features=64, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 341 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 496 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 163 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       500\n",
      "           1       0.99      0.99      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.99      0.99      0.99      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.993\n",
      "Detection Rate:  0.992\n",
      "F1 Score:  0.9929929929929929\n",
      "ROC AUC Score:  0.993\n",
      "\n",
      "======> Attacking model: CNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [01:19<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  CNNModel(\n",
      "  (conv1): Conv1d(1, 64, kernel_size=(5,), stride=(1,))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(64, 128, kernel_size=(5,), stride=(1,))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=1792, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 402 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 256 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 342 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       500\n",
      "           1       0.99      0.67      0.80       500\n",
      "\n",
      "    accuracy                           0.83      1000\n",
      "   macro avg       0.87      0.83      0.83      1000\n",
      "weighted avg       0.87      0.83      0.83      1000\n",
      "\n",
      "Accuracy:  0.834\n",
      "Detection Rate:  0.672\n",
      "F1 Score:  0.8019093078758951\n",
      "ROC AUC Score:  0.8340000000000001\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74       500\n",
      "           1       1.00      0.29      0.45       500\n",
      "\n",
      "    accuracy                           0.64      1000\n",
      "   macro avg       0.79      0.64      0.59      1000\n",
      "weighted avg       0.79      0.64      0.59      1000\n",
      "\n",
      "Accuracy:  0.644\n",
      "Detection Rate:  0.288\n",
      "F1 Score:  0.44720496894409933\n",
      "ROC AUC Score:  0.644\n",
      "\n",
      "======> Attacking model: RNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HopSkipJump: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:13<00:00, 36.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================> Model:  RNNModel(\n",
      "  (lstm): LSTM(1, 64, batch_first=True)\n",
      "  (fc1): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "---------- Adversarial data\n",
      "\n",
      "[üîç] Th·ªëng k√™ s·ªë l·∫ßn m·ªói ARM (m√¥ h√¨nh) ƒë∆∞·ª£c ch·ªçn:\n",
      "  ‚Üí M√¥ h√¨nh 0: 341 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 1: 496 l·∫ßn\n",
      "  ‚Üí M√¥ h√¨nh 2: 163 l·∫ßn\n",
      "===> DQN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       500\n",
      "           1       1.00      1.00      1.00       500\n",
      "\n",
      "    accuracy                           1.00      1000\n",
      "   macro avg       1.00      1.00      1.00      1000\n",
      "weighted avg       1.00      1.00      1.00      1000\n",
      "\n",
      "Accuracy:  0.998\n",
      "Detection Rate:  1.0\n",
      "F1 Score:  0.998003992015968\n",
      "ROC AUC Score:  0.998\n",
      "===> MAB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       500\n",
      "           1       1.00      0.99      0.99       500\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       1.00      0.99      0.99      1000\n",
      "weighted avg       1.00      0.99      0.99      1000\n",
      "\n",
      "Accuracy:  0.995\n",
      "Detection Rate:  0.992\n",
      "F1 Score:  0.9949849548645938\n",
      "ROC AUC Score:  0.995\n",
      "=====================================\n",
      "=== DQN ===\n",
      "Accuracy:  0.9433333333333334\n",
      "Detection Rate:  0.8906666666666667\n",
      "F1 Score:  0.9326390973026104\n",
      "ROC AUC Score:  0.9433333333333334\n",
      "=== MAB ===\n",
      "Accuracy:  0.8773333333333334\n",
      "Detection Rate:  0.7573333333333334\n",
      "F1 Score:  0.8117276389338953\n",
      "ROC AUC Score:  0.8773333333333334\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with multiple models\n",
    "models = [mlp_target, cnn_target, rnn_target]\n",
    "criterions = [criterion_mlp_model_target, criterion_cnn_model_target, criterion_rnn_model_target]\n",
    "optimizers = [optimizer_mlp_model_target, optimizer_cnn_model_target, optimizer_rnn_model_target]\n",
    "input_shapes = [(input_dim,), (input_dim, 1), (input_dim, 1)]\n",
    "model_types = ['mlp', 'cnn', 'rnn']\n",
    "accuracys, drs, f1s, rocs = [], [], [], []\n",
    "mab_accuracys, mab_drs, mab_f1s, mab_rocs = [], [], [], []\n",
    "attacks_data = attacks_data.astype(np.float32)\n",
    "normal_data = normal_data.astype(np.float32)\n",
    "for i, model in enumerate(models):\n",
    "    classifier = PyTorchClassifier(\n",
    "        model=model,\n",
    "        clip_values=(0.0, 1.0),\n",
    "        loss=criterions[i],\n",
    "        optimizer=optimizers[i],\n",
    "        input_shape=input_shapes[i],\n",
    "        nb_classes=2,\n",
    "    )\n",
    "\n",
    "    print(f\"\\n======> Attacking model: {model_types[i].upper()}\")\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=5,  max_eval=500, init_eval=10, init_size=20)\n",
    "    # Reshape d·ªØ li·ªáu theo lo·∫°i model\n",
    "    if model_types[i] == 'cnn':\n",
    "        x_input = attacks_data[:500].reshape((500, input_dim, 1))\n",
    "        normal_data_reshaped = normal_data[:500].reshape((500, input_dim, 1))\n",
    "    elif model_types[i] == 'rnn':\n",
    "        x_input = attacks_data[:500].reshape((500, input_dim, 1))\n",
    "        normal_data_reshaped = normal_data[:500].reshape((500, input_dim, 1))\n",
    "    else:\n",
    "        x_input = attacks_data[:500]\n",
    "        normal_data_reshaped = normal_data[:500]\n",
    "\n",
    "    # Sinh m·∫´u t·∫•n c√¥ng\n",
    "    attack = HopSkipJump(classifier=classifier, targeted=False, max_iter=10, max_eval=1000, init_eval=10, init_size=20)\n",
    "    x_test_adv = attack.generate(x_input, np.zeros((x_input.shape[0], 1)))\n",
    "\n",
    "    # G·ªôp v·ªõi d·ªØ li·ªáu b√¨nh th∆∞·ªùng\n",
    "    adv_x_test = np.concatenate((x_test_adv, normal_data_reshaped))\n",
    "    adv_y_test = np.concatenate((np.ones((x_test_adv.shape[0], 1)), np.zeros((normal_data_reshaped.shape[0], 1))))\n",
    "    adv_x_test = adv_x_test.astype(np.float64)\n",
    "    y_true = adv_y_test.astype(int).ravel()\n",
    "    if adv_x_test.ndim == 3:\n",
    "        adv_x_test = adv_x_test.reshape((adv_x_test.shape[0], -1))\n",
    "    print(\"====================> Model: \", model)\n",
    "    print(\"---------- Adversarial data\")\n",
    "\n",
    "    # Predict cho dqn\n",
    "    y_pred_dqn  = dqn.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred_dqn )\n",
    "    recall = recall_score(y_true, y_pred_dqn )\n",
    "    f1 = f1_score(y_true, y_pred_dqn )\n",
    "    roc = roc_auc_score(y_true, y_pred_dqn )\n",
    "\n",
    "    accuracys.append(accuracy)\n",
    "    drs.append(recall)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "    print(\"===> DQN:\")\n",
    "    print(classification_report(y_true, y_pred_dqn))\n",
    "    print(\"Accuracy: \", accuracy)\n",
    "    print(\"Detection Rate: \", recall)\n",
    "    print(\"F1 Score: \", f1)\n",
    "    print(\"ROC AUC Score: \", roc)\n",
    "\n",
    "    # Predict cho mab\n",
    "    y_pred_mab = mab.predict(adv_x_test)[0].astype(int).ravel()\n",
    "\n",
    "    mab_accuracy = accuracy_score(y_true, y_pred_mab)\n",
    "    mab_recall = recall_score(y_true, y_pred_mab)\n",
    "    mab_f1 = f1_score(y_true, y_pred_mab)\n",
    "    mab_roc = roc_auc_score(y_true, y_pred_mab)\n",
    "\n",
    "    mab_accuracys.append(mab_accuracy)\n",
    "    mab_drs.append(mab_recall)\n",
    "    mab_f1s.append(mab_f1)\n",
    "    mab_rocs.append(mab_roc)\n",
    "\n",
    "    print(\"===> MAB:\")\n",
    "    print(classification_report(y_true, y_pred_mab))\n",
    "    print(\"Accuracy: \", mab_accuracy)\n",
    "    print(\"Detection Rate: \", mab_recall)\n",
    "    print(\"F1 Score: \", mab_f1)\n",
    "    print(\"ROC AUC Score: \", mab_roc)\n",
    "\n",
    "# T·ªïng k·∫øt k·∫øt qu·∫£\n",
    "print(\"=====================================\")\n",
    "print(\"=== DQN ===\")\n",
    "print(\"Accuracy: \", sum(accuracys) / len(accuracys))\n",
    "print(\"Detection Rate: \", sum(drs) / len(drs))\n",
    "print(\"F1 Score: \", sum(f1s) / len(f1s))\n",
    "print(\"ROC AUC Score: \", sum(rocs) / len(rocs))\n",
    "\n",
    "print(\"=== MAB ===\")\n",
    "print(\"Accuracy: \", sum(mab_accuracys) / len(mab_accuracys))\n",
    "print(\"Detection Rate: \", sum(mab_drs) / len(mab_drs))\n",
    "print(\"F1 Score: \", sum(mab_f1s) / len(mab_f1s))\n",
    "print(\"ROC AUC Score: \", sum(mab_rocs) / len(mab_rocs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39DQN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
